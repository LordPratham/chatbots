{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T16:54:30.118814Z",
     "iopub.status.busy": "2024-10-14T16:54:30.118436Z",
     "iopub.status.idle": "2024-10-14T16:55:33.445097Z",
     "shell.execute_reply": "2024-10-14T16:55:33.443798Z",
     "shell.execute_reply.started": "2024-10-14T16:54:30.118776Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T16:55:58.649332Z",
     "iopub.status.busy": "2024-10-14T16:55:58.648903Z",
     "iopub.status.idle": "2024-10-14T16:55:58.655229Z",
     "shell.execute_reply": "2024-10-14T16:55:58.654133Z",
     "shell.execute_reply.started": "2024-10-14T16:55:58.649290Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requirements done\n"
     ]
    }
   ],
   "source": [
    "print(\"requirements done\")\n",
    "# %pip install flask-cors\n",
    "\n",
    "# %pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-14T17:05:16.125144Z",
     "iopub.status.busy": "2024-10-14T17:05:16.124196Z",
     "iopub.status.idle": "2024-10-14T17:05:16.143480Z",
     "shell.execute_reply": "2024-10-14T17:05:16.142608Z",
     "shell.execute_reply.started": "2024-10-14T17:05:16.125098Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# Load environment variables from .env\n",
    "load_dotenv(\".env\")\n",
    "# print(os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T16:56:03.719311Z",
     "iopub.status.busy": "2024-10-14T16:56:03.718329Z",
     "iopub.status.idle": "2024-10-14T16:56:03.723770Z",
     "shell.execute_reply": "2024-10-14T16:56:03.722735Z",
     "shell.execute_reply.started": "2024-10-14T16:56:03.719272Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# current_dir = \n",
    "file_path = \"./cleaned_txt/Wheat-Growers-Guide_cleaned.txt\"\n",
    "db_dir = os.path.join(\"./\", \"db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T16:56:06.268178Z",
     "iopub.status.busy": "2024-10-14T16:56:06.267797Z",
     "iopub.status.idle": "2024-10-14T16:56:06.280118Z",
     "shell.execute_reply": "2024-10-14T16:56:06.279222Z",
     "shell.execute_reply.started": "2024-10-14T16:56:06.268139Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wheat growers guide contents soils and climate 2 varietal choice 2 land preparation and soil conditioning 2 soil conditioning 3 tillage procedures 3 time of planting 3 seeding rates 4 irrigation requirements and scheduling 4 fertilisation 5 weed control 6 pests and diseases 6 whe at production general tips 7 centre pivot irrigation scheduling a general guide 9 chemigationfertigation calibrations guide 9 harvesting 10 2 soils and climate wheat is a temperate crop and is best grown in winter under\n",
      "18652\n"
     ]
    }
   ],
   "source": [
    "with open(file_path,\"r\") as f:\n",
    "    text=f.read()\n",
    "    print(text[:500])\n",
    "    print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T16:56:09.722988Z",
     "iopub.status.busy": "2024-10-14T16:56:09.722597Z",
     "iopub.status.idle": "2024-10-14T16:56:09.738656Z",
     "shell.execute_reply": "2024-10-14T16:56:09.737652Z",
     "shell.execute_reply.started": "2024-10-14T16:56:09.722937Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Document Chunks Information ---\n",
      "Number of document chunks: 1\n",
      "Sample chunk:\n",
      "wheat growers guide contents soils and climate 2 varietal choice 2 land preparation and soil conditioning 2 soil conditioning 3 tillage procedures 3 time of planting 3 seeding rates 4 irrigation requirements and scheduling 4 fertilisation 5 weed control 6 pests and diseases 6 whe at production general tips 7 centre pivot irrigation scheduling a general guide 9 chemigationfertigation calibrations guide 9 harvesting 10 2 soils and climate wheat is a temperate crop and is best grown in winter under irrigation with optimum day temperatures of between 15 20oc and cooler nights giving the best yields there are some varieties that may be grown in summer such as sahai but generally there is high disea se and weed pressure in summer accompanied by warmer temperatures that result in depressed yields 3tha therefore winter is the best time for growing wheat the crop is adapted to a wide range of soils the soils must be well drained with an optimum ph range of 55 65 on a calcium chloride scale wheat yields are greater in the highveld 1200 masl metres above sea level and middleveld 900 1250 masl with yield potential of 8 to 12 tha compared to the lowveld 900 masl where yields average of 45 7 tha under good management varietal choice new varieties are continuously produced for wheat production because of the threat of disease especially leaf rust and powdery mildew the varieties from seed co ideal for bread making are short sta tured disease resistant and well adapted to winter production current varieties include sc nduna white seeded sc sc sekuru red seeded sc smart red seeded and sc stallion red seeded sky red seeded select white seeded serena white seeded sc sahai is a summer variety which can be planted in mid summer around january land preparation and soil conditioning the most suitable soil for wheat is one with a good effective depth with a fine tilth to ensure seed soil contact good seed soil contact ensure good crop emergence and stand which are the basis for good yields favourable physical properties good internal drainage an optimal moisture regime chemical properties sufficient and balanced quantities of nutrients npk and other micro nutrientstrace nutrients biological properties good level of organic matter and with beneficial micro organisms the objective of soil tillage is to maintain the existing structure of soil or to improve the structure of poorly structured soils as well as addressing the three properties as mentioned above physical chemical and biological 3 soil conditioning lime can be applied if required to sweeten acidic soils to the ph optimum range lime application should be based on soil analysis prescriptions gypsum improves soil physical structure ie removes hard setting clodiness removes surface crusting and poor workability as well as supplying the soil with complimentary calcium and sulphur for good crop standing and growth tillage procedures there are several options of tillage which fall under two broad categories conservational and conventional tillage which can be adopted in wheat production the conventional tillage procedure follows the following steps deep ploughing ripping or chisel plough l iming and basal fertilizer application discing and then followed by rolling a roller can be pulled concurrently behind a disc harrow conservational tillage also known as zerominimum tillage is another cheaper and more sustainable option which farmers c an adopt time of planting the optimum time for planting winter wheat is between mid april and the last week of may and even earlier in the lowvelds sometimes planting time can be extended to mid june but not normally recommended delayed planting resul ts in a loss of about 50kghaday after may the first two weeks of may tend to give the best yields in the highveld areas adhering to the optimum planting time has some agronomic explanations and rationales early summer rain escape rains which come aft er the wheat has reached physiological maturity causes sprouting grain germination in the ear and result in down grading of the wheat due to a decline in baking qualities disease escape disease pressure especially for rust diseases normally rises when temperatures start to warm up around august and an early planted crop would have gotten a good head start without disease pressure pest escape likewise pest pressure such as aphids start to rise when temperatures start to rise an early planted crop w ill have a good head start ahead of pest pressure 4 early planting will result in early harvesting around september one of the key considerations for the adoption of double cropping is early planting and early harvesting for both summer and winter crops t he farmer will come in with his summer crop on time when wheat is planted and harvested early generally wheat takes about 125 140 days to physiological maturity depending on variety altitude and weather conditions the higher the altitude the longer the time from planting to maturity wheat critical stages such as crop establishment tillering flowering and grain filling will concide with the optimum growth conditions when the crop is early planted for instance for robust tillering ie for the pla nt to produce secondary stems 4 5 weeks after crop emergence requires very cool conditions that normally occurs in may and june while flowering 60 90 days and grain filling 90 days must not coincide with frosty conditions to avoid crop sterili ty seeding rates the optimum plant population for wheat is 220 250 plants per m2 seed rate depends on the seed size germination percentage planting conditions and planting method to achieve optimum population density a seeding rate of about 110 125 kgha when drilling and 125 135 kgha when broadcasting with a vicon spreader is recommended to ensure good crop standability and yield farmers should adhere to these optimum population densities diseases such as powdery mildew are also minimized wit h good agronomic practices irrigation requirements and scheduling since there is very little or no rainfall during winter in zimbabwe irrigation is required to achieve a high yielding wheat crop the total gross amount of water required is between 450 and 600 mm per ha ie 45 6 mega litres per ha depending on method of irrigation overhead irrigation with sprinkler or use of centre pivots and must be applied as the crop requires it the key points are the soil must be brought to field capacity to the full potential rooting depth about 12 m at planting to emerge the crop a light irrigation must be applied at the 4th or 5th day after sowing to break the crust to ensure good crop emergence 5 a light irrigation must be applied at 14 to 17 days af ter emergence to stimulate crown root development and tillering and irrigation thereafter must be applied to match crop water use on sandy soils with low water holding capacities irrigate frequently 7 to 9 day cycles with 30 35mm net on clays and sa ndy clays with good water holding capacities irrigation may be less frequent with larger amounts 10 to 14 day cycles with 40 45 mm net this is a general irrigation scheduling guide for an informed irrigation scheduling the use of a soil auger to eva luate the soil water content ahead and behind the irrigation line is a good aid to irrigation management irrigation is terminated when the neck of the earsspikeshead peduncle turn yellow ie physiological maturity crop hardening after the crop has e merged the hardening stage begins this induces crown root development as well as tillering the recommended hardening period irrigation is temporarily terminated during this stage is 10 and 14 days in light and heavy soils respectively top dressing f ertilizer and herbicide application is done after a light irrigation which follows the hardening period normally about 21 days after emergence fertilisation the fertiliser regime management in wheat like any other crop must be tailored to the soil fertility status the yield potential and the grain quality requirements as a general guide wheat requires a basal application of 300 to 500 kgha of a compound fertiliser such as 7 147 and a top dressing of 350 to 500 kg of urea or ammonium nitrate per h a both fertilizer dressings are broadcast by a vicon generally 160 190kgha of nitrogen units n 50 70 units of phosphorous p and 30 50 units of potassium k are adequate for optimum plant growth basal fertilizer need incorporation into the soil by discing and should be applied after primary tillage the top dressing is usually applied in one application between 14 21 days after emergence on heavy soils and in two applications of equal amounts at 14 and 35 days after emergence on sandy s oils top dressing should be applied after the hardening stage top dressing is essential for good leaf and general plant growth and ultimately the yield but also importantly for attaining good protein 6 levels the minimum protein level requirement for pre mium good quality wheat is 11 it is one of the considerations for grading and pricing of wheat attainment of good protein levels is also determined by varietal choice and general management application of nitrogen after flowering can also boost the grain protein content of wheat all fertility management practices must be based on proper full soil analysis recommendations by approved laboratories weed control farmers are advised to use some wheat specific post emergence herbicide which should be applied after a light irrigation which follows the hardening period 2 wace weeks after crop emergence we also recommend farmers to apply specific herbicides against volunteer crops puma super is normally sprayed when wheat is planted after a maize crop against maize volunteer plants for soya volunteers a herbicide called ally is recommended banvel and mcpa combination covers a wide spectrum of broad leaf weeds and is recommended it is important for farmers to read labels whenever they are applying herbicides pests and diseases aphids and stalk borers can attack wheat with aphids coming in earlier soon after tillering while borers can attack the plant from flowering onwards farmers must also be on the look out for fall armyworm given that wheat is one of the host crops to th e pest these pests can be controlled with appropriate pesticide sprays after scouting during the late grain filling period quelea birds may consume much grain and reduce yields significantly if not attended to a pesticide molecule called 910 anthraq uinone 50 wp bird shield has been developed which can be used as a seed dressing or as a foliar spray at soft dough stage efficacy of this pesticide molecule can be enhanced by applying with a sticker and also a rainfast period of 4 hours or more thi s pesticide molecule will act as a bird repellent this is the best and the most efficient option the other option is bird scaring using bells tins whistles discsreflectors etc by bird scaring gangs 7 diseases such as leaf rust stem rust powdery mildew fusarium head blight and take all may cause yield reduction farmers must seek professional advice on how to control these diseases the best bet is for farmers to grow resistant varieties and seed co wheat varieties such as sc select are resistant to these diseases generally two preventative fungicide sprays are recommended if farmers are located in disease prone areas and gives some form of insurance against climate change that can result in new disease pathotypes nb farmers are encouraged to scout their wheat crop for diseases pests and deficiencies and make spraying decisions early when pestdisease reaches economic threshold levels consult agrochemical companies for more information on chemicals always read chemical labels carefully use safe practices and adequate protective gear during application wheat production general tips 1 plan ahead evaluate available water resources in order to calculate wheat area based on proposed gross application irrigation equipment and infrastructure must be ready with checks made on pumping unit conveyance system pivot sprinkler condition and nozzle wear 2 soil condition and fertilisation soil sampling is always the starting point in determining the rates and types of soil conditioners and fertilisers to be used 3 start at field capacity crop emergence requires a soil profile that is at field capacity down to the full potential of the rooting depth this should be achieved by the 3 4 leaf stage at the latest this is important because wh eat roots grow downwards at a rate of 20 30 mmday and any dry layers within the profile will impede root growth and proliferation 4 establishment irrigation seed germinates happily in the presence of good soil moisture establishment irrigations need to be geared to achieve a uniform and adequate stand and this depends on planting method and uniformity of irrigation drilled seed normally requires one good irrigation to cause germination because of good soil seed contact broadcasted seed or zero tillag e fields require frequent 2 3 day intervals light irrigations 25mm to effect establishment a light irrigation is essential 4 7 days after 8 the first irrigation in soils that are prone to crusting to assist with emergence 5 ensure crown root devel opment and tillering at 3 4 leaf stage 14 17 days after the first germination irrigation crown roots and the ear begin to develop and tillers start growing water deficit adversely affect these processes yet they play an important role in yield for mation at this stage usually the top 100 150mm of the soil is dry and crown roots will not grow into dry soil it is necessary to apply a light irrigation to stimulate crown roots and tillering it is also an appropriate time to top dress the wheat wit h nitrogen fertilizer 6 initiate an irrigation schedule early and monitor the soil and crop through to maturity scheduling assist the manager to monitor crop progress and thereby ensure the best treatment possible is given to the crop assess soil and crop conditions before and after each irrigation cycle to evaluate whether or not the irrigation is recharging the soil profile to the satisfaction of the plant needs a soil auger is extremely useful in this regard an auger test ahead of the line will show h ow deep the plant is drawing water while an auger test two positions behind the line will show how effective the irrigation application is in replenishing the soil well irrigated wheat has a dark green colour soft large leaves and many tillers whilst s tressedwheat has a bluish colour hard spikey leaves which may also roll up in some varieties and a few tillers with small ears 7 crop maintenance weed disease and pest control are important in achieving a good crop 8 timing of the last irrigation ther e is no point in irrigating a yellowing crop and grains are fully formed and after hard dough stage full maturity is reached when the peduncle neck area below the earspike turns yellow irrigation applied during later grain fill or during grain dry do wn is of no value to the crop and may even reduce the quality of the grain water after ripening may cause pre harvesting sprouting germination in the ear leading to down grading of wheat due to reduced grain quality 9 keeping irrigation records it helps to plan future irrigation practices useful records include a water usage with a flow meter b energy use either electricity units or diesel litres c dates and amounts of irrigation applied 9 d evaporation and air temperature e labour centre pivot irrigation scheduling a general guide generally center pivot irrigation is the simplest method of irrigating any crop for efficiency there are factors to consider when using center pivots it is proven that a farmer gets more effective water application on a fixed center pivot as compared to a towable pivot this is largely due to the fact that there is run down time loss due to towing from one center to the other it is advisable that when using a fixed center pivot anything between a 10mm and 12 mm spray package is recommended however if it is a towable center pivot and a farmer intends to do two circles with one pivot a bigger spray package is more ideal for the pivot and this can be from 14 mm to 20 mm spray package depending on specific requirements a bigger spray package is recommended for towable center pivots to reduce the turnaround time of the center pivot to avoid moisture stress in the other circle for easy water application a farmer is advised to run their pivot in wet mode the wet mode allows the operator to program the pivot to apply the exact amount of mm required at the particular stage of growth of the crop in instances where the pivot is run in dry mode the operator will be required to calculate the percentage on the timer which corresponds with the amount of water mm that need to be applied and in most cases errors on calculation are sometimes common and a farmer will not achieve the intended spray volumes it is advisable then that farmers should ask their centre pivot service provider to program the machine to work in the wet mode chemigationfertigation calibrations guide calibration factors that need to be considered when using a centre pivot for chemigation and fertigation include the sizing of the dosing pump and its pumping rate a lways ensure you discuss with your pumps specialist before purchasing a dosing pump for correct dosing pump sizing for your applications as applications vary from case to case it is also important that your fertigation or chemigation unit is as close as p ossible to the centre pivot inlet as possible 10 generally not more than six metres below are critical factors to be considered when using a pivot for both chemigation and fertigation 1 length of the pivot to the edge of the effective wetted area 2 length of the pivot to the last tower 3 last tower travel distance in a given amount of time running at present application this point has to be verified physically by the farmer with the pivot running in wet mode at the present application rate do not rely on liter ature or your pivot control panel as other factors such as terrain eg slopegradient can affect your last tower run speed so this must to be verified 4 targeted product application rate in kgslitres per hectare 5 product concentration in kgslitres per m3 of active ingredient 6 percentage of a full circle centre pivot that will be used during the application harvesting on a large scale wheat is usually harvested by combine but it is possible to hand harvest and thresh small areas of wheat combine harve sters must be set carefully and operated according to service manuals in order to keep harvest losses to a minimum\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "\n",
    "# Check if the text file exists\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"The file {file_path} does not exist. Please check the path.\"\n",
    "    )\n",
    "\n",
    "# Read the text content from the file\n",
    "loader = TextLoader(file_path)\n",
    "documents = loader.load()\n",
    "\n",
    "# Split the document into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Display information about the split documents\n",
    "print(\"\\n--- Document Chunks Information ---\")\n",
    "print(f\"Number of document chunks: {len(docs)}\")\n",
    "print(f\"Sample chunk:\\n{docs[0].page_content}\\n\")\n",
    "\n",
    "\n",
    "# Function to create and persist vector store\n",
    "def create_vector_store(docs, embeddings, store_name):\n",
    "    persistent_directory = os.path.join(db_dir, store_name)\n",
    "    if not os.path.exists(persistent_directory):\n",
    "        print(f\"\\n--- Creating vector store {store_name} ---\")\n",
    "        Chroma.from_documents(\n",
    "            docs, embeddings, persist_directory=persistent_directory)\n",
    "        print(f\"--- Finished creating vector store {store_name} ---\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"Vector store {store_name} already exists. No need to initialize.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T16:56:14.275884Z",
     "iopub.status.busy": "2024-10-14T16:56:14.275503Z",
     "iopub.status.idle": "2024-10-14T16:56:39.380177Z",
     "shell.execute_reply": "2024-10-14T16:56:39.379060Z",
     "shell.execute_reply.started": "2024-10-14T16:56:14.275847Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using Hugging Face Transformers ---\n",
      "Vector store chroma_db_huggingface already exists. No need to initialize.\n",
      "Embedding demonstrations for OpenAI and Hugging Face completed.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "print(\"\\n--- Using Hugging Face Transformers ---\")\n",
    "# huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "#     model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    "# )\n",
    "huggingface_embeddings= pickle.load(open(\"huggingface_embeddings.pkl\",\"rb\"))\n",
    "create_vector_store(docs, huggingface_embeddings, \"chroma_db_huggingface\")\n",
    "\n",
    "print(\"Embedding demonstrations for OpenAI and Hugging Face completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T16:56:39.382667Z",
     "iopub.status.busy": "2024-10-14T16:56:39.381935Z",
     "iopub.status.idle": "2024-10-14T16:56:39.389801Z",
     "shell.execute_reply": "2024-10-14T16:56:39.388672Z",
     "shell.execute_reply.started": "2024-10-14T16:56:39.382631Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def query_vector_store(store_name, query, embedding_function):\n",
    "    persistent_directory = os.path.join(db_dir, store_name)\n",
    "    if os.path.exists(persistent_directory):\n",
    "        print(f\"\\n--- Querying the Vector Store {store_name} ---\")\n",
    "        db = Chroma(\n",
    "            persist_directory=persistent_directory,\n",
    "            embedding_function=embedding_function,\n",
    "        )\n",
    "        retriever = db.as_retriever(\n",
    "            search_type=\"similarity_score_threshold\",\n",
    "            search_kwargs={\"k\": 5, \"score_threshold\": 0.1},\n",
    "        )\n",
    "        relevant_docs = retriever.invoke(query)\n",
    "        # Display the relevant results with metadata\n",
    "        print(f\"\\n--- Relevant Documents for {store_name} ---\")\n",
    "        for i, doc in enumerate(relevant_docs, 1):\n",
    "            print(f\"Document {i}:\\n{doc.page_content}\\n\")\n",
    "            if doc.metadata:\n",
    "                print(f\"Source: {doc.metadata.get('source', 'Unknown')}\\n\")\n",
    "    else:\n",
    "        print(f\"Vector store {store_name} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T16:56:54.741021Z",
     "iopub.status.busy": "2024-10-14T16:56:54.739780Z",
     "iopub.status.idle": "2024-10-14T16:56:54.829227Z",
     "shell.execute_reply": "2024-10-14T16:56:54.828097Z",
     "shell.execute_reply.started": "2024-10-14T16:56:54.740955Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Querying the Vector Store chroma_db_huggingface ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 5 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Relevant Documents for chroma_db_huggingface ---\n",
      "Document 1:\n",
      "wheat growers guide contents soils and climate 2 varietal choice 2 land preparation and soil conditioning 2 soil conditioning 3 tillage procedures 3 time of planting 3 seeding rates 4 irrigation requirements and scheduling 4 fertilisation 5 weed control 6 pests and diseases 6 whe at production general tips 7 centre pivot irrigation scheduling a general guide 9 chemigationfertigation calibrations guide 9 harvesting 10 2 soils and climate wheat is a temperate crop and is best grown in winter under irrigation with optimum day temperatures of between 15 20oc and cooler nights giving the best yields there are some varieties that may be grown in summer such as sahai but generally there is high disea se and weed pressure in summer accompanied by warmer temperatures that result in depressed yields 3tha therefore winter is the best time for growing wheat the crop is adapted to a wide range of soils the soils must be well drained with an optimum ph range of 55 65 on a calcium chloride scale wheat yields are greater in the highveld 1200 masl metres above sea level and middleveld 900 1250 masl with yield potential of 8 to 12 tha compared to the lowveld 900 masl where yields average of 45 7 tha under good management varietal choice new varieties are continuously produced for wheat production because of the threat of disease especially leaf rust and powdery mildew the varieties from seed co ideal for bread making are short sta tured disease resistant and well adapted to winter production current varieties include sc nduna white seeded sc sc sekuru red seeded sc smart red seeded and sc stallion red seeded sky red seeded select white seeded serena white seeded sc sahai is a summer variety which can be planted in mid summer around january land preparation and soil conditioning the most suitable soil for wheat is one with a good effective depth with a fine tilth to ensure seed soil contact good seed soil contact ensure good crop emergence and stand which are the basis for good yields favourable physical properties good internal drainage an optimal moisture regime chemical properties sufficient and balanced quantities of nutrients npk and other micro nutrientstrace nutrients biological properties good level of organic matter and with beneficial micro organisms the objective of soil tillage is to maintain the existing structure of soil or to improve the structure of poorly structured soils as well as addressing the three properties as mentioned above physical chemical and biological 3 soil conditioning lime can be applied if required to sweeten acidic soils to the ph optimum range lime application should be based on soil analysis prescriptions gypsum improves soil physical structure ie removes hard setting clodiness removes surface crusting and poor workability as well as supplying the soil with complimentary calcium and sulphur for good crop standing and growth tillage procedures there are several options of tillage which fall under two broad categories conservational and conventional tillage which can be adopted in wheat production the conventional tillage procedure follows the following steps deep ploughing ripping or chisel plough l iming and basal fertilizer application discing and then followed by rolling a roller can be pulled concurrently behind a disc harrow conservational tillage also known as zerominimum tillage is another cheaper and more sustainable option which farmers c an adopt time of planting the optimum time for planting winter wheat is between mid april and the last week of may and even earlier in the lowvelds sometimes planting time can be extended to mid june but not normally recommended delayed planting resul ts in a loss of about 50kghaday after may the first two weeks of may tend to give the best yields in the highveld areas adhering to the optimum planting time has some agronomic explanations and rationales early summer rain escape rains which come aft er the wheat has reached physiological maturity causes sprouting grain germination in the ear and result in down grading of the wheat due to a decline in baking qualities disease escape disease pressure especially for rust diseases normally rises when temperatures start to warm up around august and an early planted crop would have gotten a good head start without disease pressure pest escape likewise pest pressure such as aphids start to rise when temperatures start to rise an early planted crop w ill have a good head start ahead of pest pressure 4 early planting will result in early harvesting around september one of the key considerations for the adoption of double cropping is early planting and early harvesting for both summer and winter crops t he farmer will come in with his summer crop on time when wheat is planted and harvested early generally wheat takes about 125 140 days to physiological maturity depending on variety altitude and weather conditions the higher the altitude the longer the time from planting to maturity wheat critical stages such as crop establishment tillering flowering and grain filling will concide with the optimum growth conditions when the crop is early planted for instance for robust tillering ie for the pla nt to produce secondary stems 4 5 weeks after crop emergence requires very cool conditions that normally occurs in may and june while flowering 60 90 days and grain filling 90 days must not coincide with frosty conditions to avoid crop sterili ty seeding rates the optimum plant population for wheat is 220 250 plants per m2 seed rate depends on the seed size germination percentage planting conditions and planting method to achieve optimum population density a seeding rate of about 110 125 kgha when drilling and 125 135 kgha when broadcasting with a vicon spreader is recommended to ensure good crop standability and yield farmers should adhere to these optimum population densities diseases such as powdery mildew are also minimized wit h good agronomic practices irrigation requirements and scheduling since there is very little or no rainfall during winter in zimbabwe irrigation is required to achieve a high yielding wheat crop the total gross amount of water required is between 450 and 600 mm per ha ie 45 6 mega litres per ha depending on method of irrigation overhead irrigation with sprinkler or use of centre pivots and must be applied as the crop requires it the key points are the soil must be brought to field capacity to the full potential rooting depth about 12 m at planting to emerge the crop a light irrigation must be applied at the 4th or 5th day after sowing to break the crust to ensure good crop emergence 5 a light irrigation must be applied at 14 to 17 days af ter emergence to stimulate crown root development and tillering and irrigation thereafter must be applied to match crop water use on sandy soils with low water holding capacities irrigate frequently 7 to 9 day cycles with 30 35mm net on clays and sa ndy clays with good water holding capacities irrigation may be less frequent with larger amounts 10 to 14 day cycles with 40 45 mm net this is a general irrigation scheduling guide for an informed irrigation scheduling the use of a soil auger to eva luate the soil water content ahead and behind the irrigation line is a good aid to irrigation management irrigation is terminated when the neck of the earsspikeshead peduncle turn yellow ie physiological maturity crop hardening after the crop has e merged the hardening stage begins this induces crown root development as well as tillering the recommended hardening period irrigation is temporarily terminated during this stage is 10 and 14 days in light and heavy soils respectively top dressing f ertilizer and herbicide application is done after a light irrigation which follows the hardening period normally about 21 days after emergence fertilisation the fertiliser regime management in wheat like any other crop must be tailored to the soil fertility status the yield potential and the grain quality requirements as a general guide wheat requires a basal application of 300 to 500 kgha of a compound fertiliser such as 7 147 and a top dressing of 350 to 500 kg of urea or ammonium nitrate per h a both fertilizer dressings are broadcast by a vicon generally 160 190kgha of nitrogen units n 50 70 units of phosphorous p and 30 50 units of potassium k are adequate for optimum plant growth basal fertilizer need incorporation into the soil by discing and should be applied after primary tillage the top dressing is usually applied in one application between 14 21 days after emergence on heavy soils and in two applications of equal amounts at 14 and 35 days after emergence on sandy s oils top dressing should be applied after the hardening stage top dressing is essential for good leaf and general plant growth and ultimately the yield but also importantly for attaining good protein 6 levels the minimum protein level requirement for pre mium good quality wheat is 11 it is one of the considerations for grading and pricing of wheat attainment of good protein levels is also determined by varietal choice and general management application of nitrogen after flowering can also boost the grain protein content of wheat all fertility management practices must be based on proper full soil analysis recommendations by approved laboratories weed control farmers are advised to use some wheat specific post emergence herbicide which should be applied after a light irrigation which follows the hardening period 2 wace weeks after crop emergence we also recommend farmers to apply specific herbicides against volunteer crops puma super is normally sprayed when wheat is planted after a maize crop against maize volunteer plants for soya volunteers a herbicide called ally is recommended banvel and mcpa combination covers a wide spectrum of broad leaf weeds and is recommended it is important for farmers to read labels whenever they are applying herbicides pests and diseases aphids and stalk borers can attack wheat with aphids coming in earlier soon after tillering while borers can attack the plant from flowering onwards farmers must also be on the look out for fall armyworm given that wheat is one of the host crops to th e pest these pests can be controlled with appropriate pesticide sprays after scouting during the late grain filling period quelea birds may consume much grain and reduce yields significantly if not attended to a pesticide molecule called 910 anthraq uinone 50 wp bird shield has been developed which can be used as a seed dressing or as a foliar spray at soft dough stage efficacy of this pesticide molecule can be enhanced by applying with a sticker and also a rainfast period of 4 hours or more thi s pesticide molecule will act as a bird repellent this is the best and the most efficient option the other option is bird scaring using bells tins whistles discsreflectors etc by bird scaring gangs 7 diseases such as leaf rust stem rust powdery mildew fusarium head blight and take all may cause yield reduction farmers must seek professional advice on how to control these diseases the best bet is for farmers to grow resistant varieties and seed co wheat varieties such as sc select are resistant to these diseases generally two preventative fungicide sprays are recommended if farmers are located in disease prone areas and gives some form of insurance against climate change that can result in new disease pathotypes nb farmers are encouraged to scout their wheat crop for diseases pests and deficiencies and make spraying decisions early when pestdisease reaches economic threshold levels consult agrochemical companies for more information on chemicals always read chemical labels carefully use safe practices and adequate protective gear during application wheat production general tips 1 plan ahead evaluate available water resources in order to calculate wheat area based on proposed gross application irrigation equipment and infrastructure must be ready with checks made on pumping unit conveyance system pivot sprinkler condition and nozzle wear 2 soil condition and fertilisation soil sampling is always the starting point in determining the rates and types of soil conditioners and fertilisers to be used 3 start at field capacity crop emergence requires a soil profile that is at field capacity down to the full potential of the rooting depth this should be achieved by the 3 4 leaf stage at the latest this is important because wh eat roots grow downwards at a rate of 20 30 mmday and any dry layers within the profile will impede root growth and proliferation 4 establishment irrigation seed germinates happily in the presence of good soil moisture establishment irrigations need to be geared to achieve a uniform and adequate stand and this depends on planting method and uniformity of irrigation drilled seed normally requires one good irrigation to cause germination because of good soil seed contact broadcasted seed or zero tillag e fields require frequent 2 3 day intervals light irrigations 25mm to effect establishment a light irrigation is essential 4 7 days after 8 the first irrigation in soils that are prone to crusting to assist with emergence 5 ensure crown root devel opment and tillering at 3 4 leaf stage 14 17 days after the first germination irrigation crown roots and the ear begin to develop and tillers start growing water deficit adversely affect these processes yet they play an important role in yield for mation at this stage usually the top 100 150mm of the soil is dry and crown roots will not grow into dry soil it is necessary to apply a light irrigation to stimulate crown roots and tillering it is also an appropriate time to top dress the wheat wit h nitrogen fertilizer 6 initiate an irrigation schedule early and monitor the soil and crop through to maturity scheduling assist the manager to monitor crop progress and thereby ensure the best treatment possible is given to the crop assess soil and crop conditions before and after each irrigation cycle to evaluate whether or not the irrigation is recharging the soil profile to the satisfaction of the plant needs a soil auger is extremely useful in this regard an auger test ahead of the line will show h ow deep the plant is drawing water while an auger test two positions behind the line will show how effective the irrigation application is in replenishing the soil well irrigated wheat has a dark green colour soft large leaves and many tillers whilst s tressedwheat has a bluish colour hard spikey leaves which may also roll up in some varieties and a few tillers with small ears 7 crop maintenance weed disease and pest control are important in achieving a good crop 8 timing of the last irrigation ther e is no point in irrigating a yellowing crop and grains are fully formed and after hard dough stage full maturity is reached when the peduncle neck area below the earspike turns yellow irrigation applied during later grain fill or during grain dry do wn is of no value to the crop and may even reduce the quality of the grain water after ripening may cause pre harvesting sprouting germination in the ear leading to down grading of wheat due to reduced grain quality 9 keeping irrigation records it helps to plan future irrigation practices useful records include a water usage with a flow meter b energy use either electricity units or diesel litres c dates and amounts of irrigation applied 9 d evaporation and air temperature e labour centre pivot irrigation scheduling a general guide generally center pivot irrigation is the simplest method of irrigating any crop for efficiency there are factors to consider when using center pivots it is proven that a farmer gets more effective water application on a fixed center pivot as compared to a towable pivot this is largely due to the fact that there is run down time loss due to towing from one center to the other it is advisable that when using a fixed center pivot anything between a 10mm and 12 mm spray package is recommended however if it is a towable center pivot and a farmer intends to do two circles with one pivot a bigger spray package is more ideal for the pivot and this can be from 14 mm to 20 mm spray package depending on specific requirements a bigger spray package is recommended for towable center pivots to reduce the turnaround time of the center pivot to avoid moisture stress in the other circle for easy water application a farmer is advised to run their pivot in wet mode the wet mode allows the operator to program the pivot to apply the exact amount of mm required at the particular stage of growth of the crop in instances where the pivot is run in dry mode the operator will be required to calculate the percentage on the timer which corresponds with the amount of water mm that need to be applied and in most cases errors on calculation are sometimes common and a farmer will not achieve the intended spray volumes it is advisable then that farmers should ask their centre pivot service provider to program the machine to work in the wet mode chemigationfertigation calibrations guide calibration factors that need to be considered when using a centre pivot for chemigation and fertigation include the sizing of the dosing pump and its pumping rate a lways ensure you discuss with your pumps specialist before purchasing a dosing pump for correct dosing pump sizing for your applications as applications vary from case to case it is also important that your fertigation or chemigation unit is as close as p ossible to the centre pivot inlet as possible 10 generally not more than six metres below are critical factors to be considered when using a pivot for both chemigation and fertigation 1 length of the pivot to the edge of the effective wetted area 2 length of the pivot to the last tower 3 last tower travel distance in a given amount of time running at present application this point has to be verified physically by the farmer with the pivot running in wet mode at the present application rate do not rely on liter ature or your pivot control panel as other factors such as terrain eg slopegradient can affect your last tower run speed so this must to be verified 4 targeted product application rate in kgslitres per hectare 5 product concentration in kgslitres per m3 of active ingredient 6 percentage of a full circle centre pivot that will be used during the application harvesting on a large scale wheat is usually harvested by combine but it is possible to hand harvest and thresh small areas of wheat combine harve sters must be set carefully and operated according to service manuals in order to keep harvest losses to a minimum\n",
      "\n",
      "Source: ./cleaned_txt/Wheat-Growers-Guide_cleaned.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# query=\"wheat is good in which soil?\"\n",
    "query=\"what pests can attack wheat?\"\n",
    "\n",
    "query_vector_store(\"chroma_db_huggingface\", query, huggingface_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T18:56:52.257097Z",
     "iopub.status.busy": "2024-10-14T18:56:52.256628Z",
     "iopub.status.idle": "2024-10-14T18:56:52.270926Z",
     "shell.execute_reply": "2024-10-14T18:56:52.269845Z",
     "shell.execute_reply.started": "2024-10-14T18:56:52.257055Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books directory: ./cleaned_txt\n",
      "Persistent directory: ./db\\chroma_db_with_metadata\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Define the directory containing the text files and the persistent directory\n",
    "\n",
    "books_dir = './cleaned_txt'\n",
    "db_dir = os.path.join('./', \"db\")\n",
    "persistent_directory = os.path.join(db_dir, \"chroma_db_with_metadata\")\n",
    "\n",
    "print(f\"Books directory: {books_dir}\")\n",
    "print(f\"Persistent directory: {persistent_directory}\")\n",
    "\n",
    "def create_vector_database(embeddings,persistent_directory):\n",
    "    # Check if the Chroma vector store already exists\n",
    "    if not os.path.exists(persistent_directory):\n",
    "        print(\"Persistent directory does not exist. Initializing vector store...\")\n",
    "\n",
    "        # Ensure the books directory exists\n",
    "        if not os.path.exists(books_dir):\n",
    "            raise FileNotFoundError(\n",
    "                f\"The directory {books_dir} does not exist. Please check the path.\"\n",
    "            )\n",
    "\n",
    "        # List all text files in the directory\n",
    "        book_files = [f for f in os.listdir(books_dir) if f.endswith(\".txt\")]\n",
    "\n",
    "        # Read the text content from each file and store it with metadata\n",
    "        documents = []\n",
    "        for book_file in book_files:\n",
    "            file_path = os.path.join(books_dir, book_file)\n",
    "            loader = TextLoader(file_path)\n",
    "            book_docs = loader.load()\n",
    "            for doc in book_docs:\n",
    "                # Add metadata to each document indicating its source\n",
    "                doc.metadata = {\"source\": book_file}\n",
    "                documents.append(doc)\n",
    "\n",
    "        # Split the documents into chunks\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "\n",
    "        # Display information about the split documents\n",
    "        print(\"\\n--- Document Chunks Information ---\")\n",
    "        print(f\"Number of document chunks: {len(docs)}\")\n",
    "\n",
    "        # Create embeddings\n",
    "        print(\"\\n--- Creating embeddings ---\")\n",
    "        # Update to a valid embedding model if needed\n",
    "        print(\"\\n--- Finished creating embeddings ---\")\n",
    "\n",
    "        # Create the vector store and persist it\n",
    "        print(\"\\n--- Creating and persisting vector store ---\")\n",
    "        db = Chroma.from_documents(\n",
    "            docs, embeddings, persist_directory=persistent_directory)\n",
    "        print(\"\\n--- Finished creating and persisting vector store ---\")\n",
    "\n",
    "    else:\n",
    "        print(\"Vector store already exists. No need to initialize.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the object to a file\n",
    "import pickle\n",
    "with open('huggingface_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(huggingface_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T18:58:05.324023Z",
     "iopub.status.busy": "2024-10-14T18:58:05.323614Z",
     "iopub.status.idle": "2024-10-14T18:58:08.304425Z",
     "shell.execute_reply": "2024-10-14T18:58:08.303495Z",
     "shell.execute_reply.started": "2024-10-14T18:58:05.323984Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store already exists. No need to initialize.\n"
     ]
    }
   ],
   "source": [
    "huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n",
    "create_vector_database(huggingface_embeddings,persistent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T17:54:03.481185Z",
     "iopub.status.busy": "2024-10-14T17:54:03.480499Z",
     "iopub.status.idle": "2024-10-14T17:55:29.021916Z",
     "shell.execute_reply": "2024-10-14T17:55:29.020838Z",
     "shell.execute_reply.started": "2024-10-14T17:54:03.481141Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start chatting with the AI! Type 'exit' to end the conversation.\n",
      "Bye....\n"
     ]
    }
   ],
   "source": [
    "# Define the persistent directory\n",
    "# current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "# persistent_directory = os.path.join(current_dir, \"db\", \"chroma_db_with_metadata\")\n",
    "persistent_directory = \"./db/chroma_db_huggingface\"\n",
    "\n",
    "# Define the embedding model\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n",
    "# Load the existing vector store with the embedding function\n",
    "db = Chroma(persist_directory=persistent_directory, embedding_function=huggingface_embeddings)\n",
    "\n",
    "# Create a retriever for querying the vector store\n",
    "# `search_type` specifies the type of search (e.g., similarity)\n",
    "# `search_kwargs` contains additional arguments for the search (e.g., number of results to return)\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "\n",
    "# Create a google model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# Contextualize question prompt\n",
    "# This system prompt helps the AI understand that it should reformulate the question\n",
    "# based on the chat history to make it a standalone question\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, just \"\n",
    "    \"reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for contextualizing questions\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a history-aware retriever\n",
    "# This uses the LLM to help reformulate the question based on chat history\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "# Answer question prompt\n",
    "# This system prompt helps the AI understand that it should provide concise answers\n",
    "# based on the retrieved context and indicates what to do if the answer is unknown\n",
    "qa_system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. Use \"\n",
    "    \"the following pieces of retrieved context to answer the \"\n",
    "    \"question. If you don't know the answer, just say that you \"\n",
    "    \"don't know. Use optimal number of sentences to answer the question. \"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for answering questions\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a chain to combine documents for question answering\n",
    "# `create_stuff_documents_chain` feeds all retrieved context into the LLM\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "# Create a retrieval chain that combines the history-aware retriever and the question answering chain\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "\n",
    "# Function to simulate a continual chat\n",
    "def continual_chat():\n",
    "    print(\"Start chatting with the AI! Type 'exit' to end the conversation.\")\n",
    "    chat_history = []  # Collect chat history here (a sequence of messages)\n",
    "    while True:\n",
    "        query = input(\"You: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Bye....\")\n",
    "            break\n",
    "        # Process the user's query through the retrieval chain\n",
    "        result = rag_chain.invoke({\"input\": query, \"chat_history\": chat_history})\n",
    "        # Display the AI's response\n",
    "        print(f\"AI: {result['answer']}\")\n",
    "        # Update the chat history\n",
    "#         chat_history.append(HumanMessage(content=query))\n",
    "#         chat_history.append(SystemMessage(content=result[\"answer\"]))\n",
    "        chat_history.append(HumanMessage(content=query))\n",
    "        chat_history.append(AIMessage(content=result[\"answer\"]))\n",
    "#         print(chat_history)\n",
    "\n",
    "\n",
    "# Main function to start the continual chat\n",
    "if __name__ == \"__main__\":\n",
    "    continual_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T19:00:44.981612Z",
     "iopub.status.busy": "2024-10-14T19:00:44.980861Z",
     "iopub.status.idle": "2024-10-14T19:11:08.206980Z",
     "shell.execute_reply": "2024-10-14T19:11:08.205850Z",
     "shell.execute_reply.started": "2024-10-14T19:00:44.981562Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start chatting with the AI! Type 'exit' to end the conversation.\n",
      "Bye....\n"
     ]
    }
   ],
   "source": [
    "# Define the persistent directory\n",
    "# current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "# persistent_directory = os.path.join(current_dir, \"db\", \"chroma_db_with_metadata\")\n",
    "persistent_directory = \".db/chroma_db_with_metadata\"\n",
    "\n",
    "# Define the embedding model\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n",
    "# Load the existing vector store with the embedding function\n",
    "db = Chroma(persist_directory=persistent_directory, embedding_function=huggingface_embeddings)\n",
    "\n",
    "# Create a retriever for querying the vector store\n",
    "# `search_type` specifies the type of search (e.g., similarity)\n",
    "# `search_kwargs` contains additional arguments for the search (e.g., number of results to return)\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "\n",
    "# Create a google model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# Contextualize question prompt\n",
    "# This system prompt helps the AI understand that it should reformulate the question\n",
    "# based on the chat history to make it a standalone question\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, just \"\n",
    "    \"reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for contextualizing questions\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a history-aware retriever\n",
    "# This uses the LLM to help reformulate the question based on chat history\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "# Answer question prompt\n",
    "# This system prompt helps the AI understand that it should provide concise answers\n",
    "# based on the retrieved context and indicates what to do if the answer is unknown\n",
    "qa_system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. Use \"\n",
    "    \"the following pieces of retrieved context to answer the \"\n",
    "    \"question. If you don't know the answer, just say that you \"\n",
    "    \"don't know. Use optimal number of sentences to answer the question. \"\n",
    "    \"Provide the source as well. \"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for answering questions\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a chain to combine documents for question answering\n",
    "# `create_stuff_documents_chain` feeds all retrieved context into the LLM\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "# Create a retrieval chain that combines the history-aware retriever and the question answering chain\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "\n",
    "# Function to simulate a continual chat\n",
    "def continual_chat():\n",
    "    print(\"Start chatting with the AI! Type 'exit' to end the conversation.\")\n",
    "    chat_history = []  # Collect chat history here (a sequence of messages)\n",
    "    while True:\n",
    "        query = input(\"You: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Bye....\")\n",
    "            break\n",
    "        # Process the user's query through the retrieval chain\n",
    "        result = rag_chain.invoke({\"input\": query, \"chat_history\": chat_history})\n",
    "        # Display the AI's response\n",
    "        print(f\"AI: {result['answer']}\")\n",
    "        # Update the chat history\n",
    "#         chat_history.append(HumanMessage(content=query))\n",
    "#         chat_history.append(SystemMessage(content=result[\"answer\"]))\n",
    "        chat_history.append(HumanMessage(content=query))\n",
    "        chat_history.append(AIMessage(content=result[\"answer\"]))\n",
    "#         print(chat_history)\n",
    "\n",
    "\n",
    "# Main function to start the continual chat\n",
    "if __name__ == \"__main__\":\n",
    "    continual_chat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'IndicTransToolkit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     AutoModelForSeq2SeqLM,\n\u001b[0;32m      4\u001b[0m     AutoTokenizer,\n\u001b[0;32m      5\u001b[0m )\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIndicTransToolkit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IndicProcessor\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Define model and tokenizer for Indic to English translation\u001b[39;00m\n\u001b[0;32m      9\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mai4bharat/indictrans2-indic-en-1B\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'IndicTransToolkit'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from IndicTransToolkit import IndicProcessor\n",
    "\n",
    "# Define model and tokenizer for Indic to English translation\n",
    "model_name = \"ai4bharat/indictrans2-indic-en-1B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "# Initialize the IndicProcessor for preprocessing and postprocessing\n",
    "ip = IndicProcessor(inference=True)\n",
    "\n",
    "# Example input sentences in Punjabi (Gurmukhi script)\n",
    "input_sentences = [\n",
    "    \"  ?\",  # How are you?\n",
    "    \"     \",  # We watched a new movie yesterday.\n",
    "    \"      '  \",  # My friend has invited me to his birthday.\n",
    "    \"     \",  # I go to the park every day.\n",
    "]\n",
    "\n",
    "# Define source and target languages\n",
    "src_lang, tgt_lang = \"pan_Guru\", \"eng_Latn\"\n",
    "\n",
    "# Preprocess the input sentences\n",
    "batch = ip.preprocess_batch(\n",
    "    input_sentences,\n",
    "    src_lang=src_lang,\n",
    "    tgt_lang=tgt_lang,\n",
    ")\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Tokenize the sentences and generate input encodings\n",
    "inputs = tokenizer(\n",
    "    batch,\n",
    "    truncation=True,\n",
    "    padding=\"longest\",\n",
    "    return_tensors=\"pt\",\n",
    "    return_attention_mask=True,\n",
    ").to(DEVICE)\n",
    "\n",
    "# Generate translations using the model\n",
    "with torch.no_grad():\n",
    "    generated_tokens = model.generate(\n",
    "        **inputs,\n",
    "        use_cache=True,\n",
    "        min_length=0,\n",
    "        max_length=256,\n",
    "        num_beams=5,\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "\n",
    "# Decode the generated tokens into text\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    generated_tokens = tokenizer.batch_decode(\n",
    "        generated_tokens.detach().cpu().tolist(),\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=True,\n",
    "    )\n",
    "\n",
    "# Postprocess the translations\n",
    "translations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "# Print the input sentences and their translations\n",
    "for input_sentence, translation in zip(input_sentences, translations):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and tokenizer to a directory\n",
    "model.save_pretrained(\"indictrans2-indic-en-1B-saved\")\n",
    "tokenizer.save_pretrained(\"indictrans2-indic-en-1B-saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from IndicTransToolkit import IndicProcessor\n",
    "\n",
    "def translate_punjabi_to_english(punjabi_sentences):\n",
    "    \"\"\"Translates Punjabi sentences to English using the IndicTransToolkit and a pre-trained transformer model.\n",
    "\n",
    "    Args:\n",
    "        punjabi_sentences (list): A list of Punjabi sentences to be translated.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of corresponding English translations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the pre-trained model and tokenizer\n",
    "    model_name = \"ai4bharat/indictrans2-indic-en-1B\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "    # Initialize the IndicProcessor\n",
    "    ip = IndicProcessor(inference=True)\n",
    "\n",
    "    # Define source and target languages\n",
    "    src_lang, tgt_lang = \"pan_Guru\", \"eng_Latn\"\n",
    "\n",
    "    # Preprocess the input sentences\n",
    "    batch = ip.preprocess_batch(\n",
    "        punjabi_sentences,\n",
    "        src_lang=src_lang,\n",
    "        tgt_lang=tgt_lang,\n",
    "    )\n",
    "\n",
    "    # Set the device (GPU or CPU)\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Tokenize the sentences and generate input encodings\n",
    "    inputs = tokenizer(\n",
    "        batch,\n",
    "        truncation=True,\n",
    "        padding=\"longest\",\n",
    "        return_tensors=\"pt\",\n",
    "        return_attention_mask=True,\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # Generate translations using the model\n",
    "    with torch.no_grad():\n",
    "        generated_tokens = model.generate(\n",
    "            **inputs,\n",
    "            use_cache=True,\n",
    "            min_length=0,\n",
    "            max_length=256,\n",
    "            num_beams=5,\n",
    "            num_return_sequences=1,\n",
    "        )\n",
    "\n",
    "    # Decode the generated tokens into text\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        generated_tokens = tokenizer.batch_decode(\n",
    "            generated_tokens.detach().cpu().tolist(),\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True,\n",
    "        )\n",
    "\n",
    "    # Postprocess the translations\n",
    "    translations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punjabi_sentences = [\n",
    "    \"  ?\",  # How are you?\n",
    "    \"    ?\",  # We watched a new movie yesterday.\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_translations = translate_punjabi_to_english(punjabi_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_translations[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## punjabi chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to simulate a continual chat punjabi\n",
    "def continual_chat():\n",
    "    print(\"Start chatting with the AI! Type 'exit' to end the conversation.\")\n",
    "    chat_history = []  # Collect chat history here (a sequence of messages)\n",
    "    punjabi_sentences=[\"  ?\"]\n",
    "    while True:\n",
    "        query = input(\"You: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Bye....\")\n",
    "            break\n",
    "        punjabi_sentences.append(query)\n",
    "        english_translations = translate_punjabi_to_english(punjabi_sentences)\n",
    "        new_query=english_translations[-1]\n",
    "        print(new_query)\n",
    "\n",
    "        # Process the user's query through the retrieval chain\n",
    "        result = rag_chain.invoke({\"input\": new_query, \"chat_history\": chat_history})\n",
    "        # Display the AI's response\n",
    "        print(f\"AI: {result['answer']}\")\n",
    "        # Update the chat history\n",
    "#         chat_history.append(HumanMessage(content=query))\n",
    "#         chat_history.append(SystemMessage(content=result[\"answer\"]))\n",
    "        chat_history.append(HumanMessage(content=query))\n",
    "        chat_history.append(AIMessage(content=result[\"answer\"]))\n",
    "#         print(chat_history)\n",
    "\n",
    "\n",
    "# Main function to start the continual chat\n",
    "if __name__ == \"__main__\":\n",
    "    continual_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from IndicTransToolkit import IndicProcessor\n",
    "\n",
    "def translate_punjabi_to_english(punjabi_sentences):\n",
    "    \"\"\"Translates Punjabi sentences to English using the IndicTransToolkit and a pre-trained transformer model.\n",
    "\n",
    "    Args:\n",
    "        punjabi_sentences (list): A list of Punjabi sentences to be translated.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of corresponding English translations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the pre-trained model and tokenizer\n",
    "    model_name = \"ai4bharat/indictrans2-indic-en-1B\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "    # Initialize the IndicProcessor\n",
    "    ip = IndicProcessor(inference=True)\n",
    "\n",
    "    # Define source and target languages\n",
    "    src_lang, tgt_lang = \"pan_Guru\", \"eng_Latn\"\n",
    "\n",
    "    # Preprocess the input sentences\n",
    "    batch = ip.preprocess_batch(\n",
    "        punjabi_sentences,\n",
    "        src_lang=src_lang,\n",
    "        tgt_lang=tgt_lang,\n",
    "    )\n",
    "\n",
    "    # Set the device (GPU or CPU)\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Tokenize the sentences and generate input encodings\n",
    "    inputs = tokenizer(\n",
    "        batch,\n",
    "        truncation=True,\n",
    "        padding=\"longest\",\n",
    "        return_tensors=\"pt\",\n",
    "        return_attention_mask=True,\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # Generate translations using the model\n",
    "    with torch.no_grad():\n",
    "        generated_tokens = model.generate(\n",
    "            **inputs,\n",
    "            use_cache=True,\n",
    "            min_length=0,\n",
    "            max_length=256,\n",
    "            num_beams=5,\n",
    "            num_return_sequences=1,\n",
    "        )\n",
    "\n",
    "    # Decode the generated tokens into text\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        generated_tokens = tokenizer.batch_decode(\n",
    "            generated_tokens.detach().cpu().tolist(),\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True,\n",
    "        )\n",
    "\n",
    "    # Postprocess the translations\n",
    "    translations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from IndicTransToolkit import IndicProcessor\n",
    "\n",
    "def translate_english_to_punjabi(english_sentences):\n",
    "    \"\"\"Translates English sentences to Punjabi using the provided model and tokenizer.\n",
    "\n",
    "    Args:\n",
    "        english_sentences (list): A list of English sentences to be translated.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of corresponding Punjabi translations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the pre-trained model and tokenizer\n",
    "    model_name = \"ai4bharat/indictrans2-en-indic-1B\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "    # Initialize the IndicProcessor\n",
    "    ip = IndicProcessor(inference=True)\n",
    "\n",
    "    # Define source and target languages\n",
    "    src_lang, tgt_lang = \"eng_Latn\", \"pan_Guru\"\n",
    "\n",
    "    # Preprocess the input sentences\n",
    "    batch = ip.preprocess_batch(\n",
    "        english_sentences,\n",
    "        src_lang=src_lang,\n",
    "        tgt_lang=tgt_lang,\n",
    "    )\n",
    "\n",
    "    # Set the device (GPU or CPU)\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Tokenize the sentences and generate input encodings\n",
    "    inputs = tokenizer(\n",
    "        batch,\n",
    "        truncation=True,\n",
    "        padding=\"longest\",\n",
    "        return_tensors=\"pt\",\n",
    "        return_attention_mask=True,\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # Generate translations using the model\n",
    "    with torch.no_grad():\n",
    "        generated_tokens = model.generate(\n",
    "            **inputs,\n",
    "            use_cache=True,\n",
    "            min_length=0,\n",
    "            max_length=256,\n",
    "            num_beams=5,\n",
    "            num_return_sequences=1,\n",
    "        )\n",
    "\n",
    "    # Decode the generated tokens into text\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        generated_tokens = tokenizer.batch_decode(\n",
    "            generated_tokens.detach().cpu().tolist(),\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True,\n",
    "        )\n",
    "\n",
    "    # Postprocess the translations, including entity replacement\n",
    "    translations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "    return translations\n",
    "\n",
    "# Example usage\n",
    "english_sentences = [\n",
    "    \"I love eating pizza.\",\n",
    "    \"The weather is beautiful today.\",\n",
    "    \"Let's go for a walk in the park.\"\n",
    "]\n",
    "\n",
    "punjabi_translations = translate_english_to_punjabi(english_sentences)\n",
    "\n",
    "# for english_sentence, punjabi_translation in zip(english_sentences, punjabi_translations):\n",
    "#     print(f\"English: {english_sentence}\")\n",
    "#     print(f\"Punjabi: {punjabi_translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and tokenizer to a directory\n",
    "model_name = \"indictrans2-en-indic-1B-saved\"\n",
    "model.save_pretrained(model_name)\n",
    "tokenizer.save_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punjabi_translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## punjabi to punjabi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to simulate a continual chat punjabi to punjabi\n",
    "def continual_chat():\n",
    "    print(\"Start chatting with the AI! Type 'exit' to end the conversation.\")\n",
    "    chat_history = []  # Collect chat history here (a sequence of messages)\n",
    "    punjabi_sentences=[\"  ?\"]\n",
    "    english_sentences=[\"How are you?\"]\n",
    "    while True:\n",
    "        query = input(\"You: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Bye....\")\n",
    "            break\n",
    "        punjabi_sentences.append(query)\n",
    "        english_translations = translate_punjabi_to_english(punjabi_sentences)\n",
    "        new_query=english_translations[-1]\n",
    "        print(new_query)\n",
    "\n",
    "        # Process the user's query through the retrieval chain\n",
    "        result = rag_chain.invoke({\"input\": new_query, \"chat_history\": chat_history})\n",
    "        # Display the AI's response\n",
    "        print(\"AI: for english\", result[\"response\"])\n",
    "        english_sentences.append(str(result['answer']))\n",
    "        punjabi_translations = translate_english_to_punjabi(english_sentences)\n",
    "        punjabi_response=punjabi_translations[-1]\n",
    "        print(f\"AI: {punjabi_response}\")\n",
    "        # Update the chat history\n",
    "#         chat_history.append(HumanMessage(content=query))\n",
    "#         chat_history.append(SystemMessage(content=result[\"answer\"]))\n",
    "        chat_history.append(HumanMessage(content=query))\n",
    "        chat_history.append(AIMessage(content=result[\"answer\"]))\n",
    "#         print(chat_history)\n",
    "\n",
    "\n",
    "# Main function to start the continual chat\n",
    "if __name__ == \"__main__\":\n",
    "    continual_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install deep-translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# Example usage: English to Punjabi\n",
    "english_text = \"Hello, how are you?\"\n",
    "punjabi_translation = GoogleTranslator(source='en', target='pa').translate(english_text)\n",
    "print(\"Punjabi Translation:\", punjabi_translation)\n",
    "\n",
    "# Example usage: Punjabi to English\n",
    "punjabi_text = \"          ,     * * *  * ,                 '     * *    * *     -           * * *   * * ,             * * *    * *            ,     * * *    * *            ,          * * *    * *                     \"\n",
    "english_translation = GoogleTranslator(source='pa', target='en').translate(punjabi_text)\n",
    "print(\"English Translation:\", english_translation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "def english_to_punjabi(english_text):\n",
    "    return GoogleTranslator(source='en', target='pa').translate(english_text)\n",
    "\n",
    "def punjabi_to_english(punjabi_text):\n",
    "    return GoogleTranslator(source='pa', target='en').translate(punjabi_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# english_to_punjabi(\"\"\"In a quiet village nestled between rolling hills, there lived a curious girl named Lily. With her wild curls and bright green eyes, she had a knack for finding adventure in the most ordinary places. One sunny afternoon, while exploring the outskirts of her village, Lily stumbled upon an old, wrought-iron gate hidden behind a curtain of ivy.\n",
    "\n",
    "# Intrigued, she pushed the gate open, its rusty hinges creaking as if awakening from a long slumber. Beyond the gate lay a path overgrown with wildflowers, leading into a secluded garden. The air was thick with the sweet scent of blooming jasmine and honeysuckle, and the gentle hum of bees filled her ears. As she ventured further, she marveled at the vibrant colors and sounds around her.\n",
    "\n",
    "# In the heart of the garden stood a majestic tree, its branches stretching wide like welcoming arms. Beneath its shade, a weathered stone bench invited her to sit and rest. Lily approached the bench and noticed an engraved plaque that read, To those who seek, beauty awaits. Puzzled but delighted, she took a seat, allowing the tranquility of the garden to wash over her.\n",
    "\n",
    "# As she sat there, a flutter of movement caught her eye. A delicate butterfly, with wings painted in hues of blue and gold, danced around her. Entranced, Lily followed the butterfly as it led her deeper into the garden. Each step revealed more wonders: a sparkling fountain, hidden among the ferns, and a mosaic of colorful pebbles forming a path to a secret nook.\n",
    "\n",
    "# In this nook, she discovered a group of children playing, their laughter ringing out like music. They were painting stones, their hands smeared with vibrant colors. One of the children, a boy with bright red hair and a contagious smile, waved her over. Join us! Were creating magic! he exclaimed.\n",
    "\n",
    "# Lily hesitated for a moment, then approached the group. They welcomed her warmly, and soon she was painting stones with them, her imagination igniting as she transformed ordinary rocks into whimsical creatures and dazzling patterns. Time seemed to slip away as they shared stories and laughter, forging bonds that felt timeless.\n",
    "\n",
    "# As the sun began to dip below the horizon, casting a golden glow over the garden, Lily realized she needed to return home. The children understood her need to leave but invited her to return. This garden is a place of magic, the boy with red hair said. Whenever you feel lost, just follow the path of wildflowers.\n",
    "\n",
    "# With a heart full of joy and a pocket full of painted stones, Lily made her way back to the iron gate. She paused to take one last look at the hidden garden, a world of wonder and friendship that felt like a dream. As she stepped through the gate and closed it behind her, she felt a sense of promisea promise of return.\n",
    "\n",
    "# From that day on, the garden became her sanctuary. Whenever life felt overwhelming or mundane, she would escape to her secret place, paint stones with her new friends, and bask in the beauty of the hidden garden. With each visit, she learned that magic existed not just in the garden but within herself and the connections she made along the way.\n",
    "\n",
    "# Lilys adventures in the garden taught her that beauty and friendship often lie just beyond the ordinary, waiting for those brave enough to seek them out. And so, with a heart full of hope and a spirit of adventure, she continued to explore the world, one hidden garden at a time.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# punjabi_to_english(\"\"\"    ,                                      -            ,           \n",
    "\n",
    "#  ,              ,             ,                         \n",
    "\n",
    "#           -   ,                         ,                           ,        \n",
    "\n",
    "#      : \"         \"        ,             ,       -        \n",
    "\n",
    "# ,    : \"       !\"              ,                        \n",
    "\n",
    "#  ,     : \"       !\"                       ,          \n",
    "\n",
    "#                            ,                    ,       ,       \n",
    "\n",
    "#                ,         \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chatbot translate google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the persistent directory\n",
    "# current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "# persistent_directory = os.path.join(current_dir, \"db\", \"chroma_db_with_metadata\")\n",
    "persistent_directory = \".db/chroma_db_with_metadata\"\n",
    "\n",
    "# Define the embedding model\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n",
    "# Load the existing vector store with the embedding function\n",
    "db = Chroma(persist_directory=persistent_directory, embedding_function=huggingface_embeddings)\n",
    "\n",
    "# Create a retriever for querying the vector store\n",
    "# `search_type` specifies the type of search (e.g., similarity)\n",
    "# `search_kwargs` contains additional arguments for the search (e.g., number of results to return)\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "\n",
    "# Create a google model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# Contextualize question prompt\n",
    "# This system prompt helps the AI understand that it should reformulate the question\n",
    "# based on the chat history to make it a standalone question\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, just \"\n",
    "    \"reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for contextualizing questions\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a history-aware retriever\n",
    "# This uses the LLM to help reformulate the question based on chat history\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "# Answer question prompt\n",
    "# This system prompt helps the AI understand that it should provide concise answers\n",
    "# based on the retrieved context and indicates what to do if the answer is unknown\n",
    "qa_system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. Use \"\n",
    "    \"the following pieces of retrieved context to answer the \"\n",
    "    \"question. If you don't know the answer, just say that you \"\n",
    "    \"don't know. Use optimal number of sentences to answer the question. \"\n",
    "    \"Provide the source as well. \"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for answering questions\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a chain to combine documents for question answering\n",
    "# `create_stuff_documents_chain` feeds all retrieved context into the LLM\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "# Create a retrieval chain that combines the history-aware retriever and the question answering chain\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "\n",
    "# Function to simulate a continual chat punjabi to punjabi\n",
    "def continual_chat():\n",
    "    print(\"Start chatting with the AI! Type 'exit' to end the conversation.\")\n",
    "    chat_history = []  # Collect chat history here (a sequence of messages)\n",
    "\n",
    "    while True:\n",
    "        query = input(\"You: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Bye....\")\n",
    "            break\n",
    "\n",
    "        new_query = punjabi_to_english(str(query))\n",
    "        \n",
    "        print(new_query)\n",
    "\n",
    "        # Process the user's query through the retrieval chain\n",
    "        result = rag_chain.invoke({\"input\": new_query, \"chat_history\": chat_history})\n",
    "        # Display the AI's response\n",
    "        print(\"AI: for english\", result['answer'])\n",
    "        punjabi_response = english_to_punjabi(str(result['answer']))\n",
    "    \n",
    "        print(f\"AI: {punjabi_response}\")\n",
    "\n",
    "        # Update the chat history\n",
    "#         chat_history.append(HumanMessage(content=query))\n",
    "#         chat_history.append(SystemMessage(content=result[\"answer\"]))\n",
    "        chat_history.append(HumanMessage(content=query))\n",
    "        chat_history.append(AIMessage(content=result[\"answer\"]))\n",
    "#         print(chat_history)\n",
    "\n",
    "\n",
    "# Main function to start the continual chat\n",
    "if __name__ == \"__main__\":\n",
    "    continual_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade httpx httpcore\n",
    "!pip uninstall googletrans -y\n",
    "!pip install googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langdetect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "\n",
    "# Ensure consistent results\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        # Detect the language of the input text\n",
    "        language_code = detect(text)\n",
    "        return language_code\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Test the function with Punjabi text\n",
    "punjabi_text = \"  ?\"\n",
    "detected_language = detect_language(punjabi_text)\n",
    "print(f\"The detected language code is: {detected_language}\")\n",
    "\n",
    "# You can also test with English\n",
    "english_text = \"How are you?\"\n",
    "detected_language = detect_language(english_text)\n",
    "print(f\"The detected language code is: {detected_language}\")\n",
    "\n",
    "# Test with Hindi\n",
    "hindi_text = \"  ?\"\n",
    "detected_language = detect_language(hindi_text)\n",
    "print(f\"The detected language code is: {detected_language}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detect language of the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the persistent directory\n",
    "# current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "# persistent_directory = os.path.join(current_dir, \"db\", \"chroma_db_with_metadata\")\n",
    "# persistent_directory = \".db/chroma_db_with_metadata\"\n",
    "persistent_directory = \"db/chroma_db_with_metadata\"\n",
    "\n",
    "# Define the embedding model\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n",
    "# Load the existing vector store with the embedding function\n",
    "db = Chroma(persist_directory=persistent_directory, embedding_function=huggingface_embeddings)\n",
    "\n",
    "# Create a retriever for querying the vector store\n",
    "# `search_type` specifies the type of search (e.g., similarity)\n",
    "# `search_kwargs` contains additional arguments for the search (e.g., number of results to return)\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "\n",
    "# Create a google model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# Contextualize question prompt\n",
    "# This system prompt helps the AI understand that it should reformulate the question\n",
    "# based on the chat history to make it a standalone question\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, just \"\n",
    "    \"reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for contextualizing questions\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a history-aware retriever\n",
    "# This uses the LLM to help reformulate the question based on chat history\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "# Answer question prompt\n",
    "# This system prompt helps the AI understand that it should provide concise answers\n",
    "# based on the retrieved context and indicates what to do if the answer is unknown\n",
    "qa_system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. Use \"\n",
    "    \"the following pieces of retrieved context to answer the \"\n",
    "    \"question. If you don't know the answer, just say that you \"\n",
    "    \"don't know. Use optimal number of sentences to answer the question. \"\n",
    "    \"Provide the source as well. \"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for answering questions\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a chain to combine documents for question answering\n",
    "# `create_stuff_documents_chain` feeds all retrieved context into the LLM\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "# Create a retrieval chain that combines the history-aware retriever and the question answering chain\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "\n",
    "# Function to simulate a continual chat punjabi to punjabi\n",
    "def continual_chat():\n",
    "    print(\"Start chatting with the AI! Type 'exit' to end the conversation.\")\n",
    "    chat_history = []  # Collect chat history here (a sequence of messages)\n",
    "\n",
    "    while True:\n",
    "        query = input(\"You: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Bye....\")\n",
    "            break\n",
    "\n",
    "        language=detect_language(query)\n",
    "        \n",
    "        if language.lower()==\"pa\":\n",
    "            query = punjabi_to_english(str(query))\n",
    "        \n",
    "            print(query)\n",
    "        else:\n",
    "            print(query)\n",
    "\n",
    "        # Process the user's query through the retrieval chain\n",
    "        result = rag_chain.invoke({\"input\": query, \"chat_history\": chat_history})\n",
    "        # Display the AI's response\n",
    "        \n",
    "        if language.lower()==\"pa\":\n",
    "            punjabi_response = english_to_punjabi(str(result['answer']))\n",
    "    \n",
    "            print(f\"AI: {punjabi_response}\")\n",
    "        else:\n",
    "            print(\"AI:\", result['answer'])\n",
    "\n",
    "\n",
    "        # Update the chat history\n",
    "#         chat_history.append(HumanMessage(content=query))\n",
    "#         chat_history.append(SystemMessage(content=result[\"answer\"]))\n",
    "        chat_history.append(HumanMessage(content=query))\n",
    "        chat_history.append(AIMessage(content=result[\"answer\"]))\n",
    "#         print(chat_history)\n",
    "\n",
    "\n",
    "# Main function to start the continual chat\n",
    "if __name__ == \"__main__\":\n",
    "    continual_chat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dir = os.path.join('./', \"db\")\n",
    "persistent_directory = os.path.join(db_dir, \"extended_chroma_db_with_metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_vector_database(huggingface_embeddings,persistent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the persistent directory\n",
    "# current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "# persistent_directory = os.path.join(current_dir, \"db\", \"chroma_db_with_metadata\")\n",
    "# persistent_directory = \".db/chroma_db_with_metadata\"\n",
    "persistent_directory = \"db/extended_chroma_db_with_metadata\"\n",
    "\n",
    "# Define the embedding model\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "    # model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    "# )\n",
    "huggingface_embeddings=pickle.load(open(\"huggingface_embeddings.pkl\",\"rb\"))\n",
    "# Load the existing vector store with the embedding function\n",
    "db = Chroma(persist_directory=persistent_directory, embedding_function=huggingface_embeddings)\n",
    "\n",
    "# Create a retriever for querying the vector store\n",
    "# `search_type` specifies the type of search (e.g., similarity)\n",
    "# `search_kwargs` contains additional arguments for the search (e.g., number of results to return)\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "\n",
    "# Create a google model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# Contextualize question prompt\n",
    "# This system prompt helps the AI understand that it should reformulate the question\n",
    "# based on the chat history to make it a standalone question\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, just \"\n",
    "    \"reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for contextualizing questions\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a history-aware retriever\n",
    "# This uses the LLM to help reformulate the question based on chat history\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "# Answer question prompt\n",
    "# This system prompt helps the AI understand that it should provide concise answers\n",
    "# based on the retrieved context and indicates what to do if the answer is unknown\n",
    "qa_system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. Use \"\n",
    "    \"the following pieces of retrieved context to answer the \"\n",
    "    \"question. If you don't know the answer, just say that you \"\n",
    "    \"don't know. Use optimal number of sentences to answer the question. \"\n",
    "    \"Provide the source as well. \"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for answering questions\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a chain to combine documents for question answering\n",
    "# `create_stuff_documents_chain` feeds all retrieved context into the LLM\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "# Create a retrieval chain that combines the history-aware retriever and the question answering chain\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "\n",
    "# Function to simulate a continual chat punjabi to punjabi\n",
    "def continual_chat():\n",
    "    print(\"Start chatting with the AI! Type 'exit' to end the conversation.\")\n",
    "    chat_history = []  # Collect chat history here (a sequence of messages)\n",
    "\n",
    "    while True:\n",
    "        query = input(\"You: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Bye....\")\n",
    "            break\n",
    "\n",
    "        language=detect_language(query)\n",
    "        \n",
    "        if language.lower()==\"pa\":\n",
    "            query = punjabi_to_english(str(query))\n",
    "        \n",
    "            print(query)\n",
    "        else:\n",
    "            print(query)\n",
    "\n",
    "        # Process the user's query through the retrieval chain\n",
    "        result = rag_chain.invoke({\"input\": query, \"chat_history\": chat_history})\n",
    "        # Display the AI's response\n",
    "        \n",
    "        if language.lower()==\"pa\":\n",
    "            punjabi_response = english_to_punjabi(str(result['answer']))\n",
    "    \n",
    "            print(f\"AI: {punjabi_response}\")\n",
    "        else:\n",
    "            print(\"AI:\", result['answer'])\n",
    "\n",
    "\n",
    "        # Update the chat history\n",
    "#         chat_history.append(HumanMessage(content=query))\n",
    "#         chat_history.append(SystemMessage(content=result[\"answer\"]))\n",
    "        chat_history.append(HumanMessage(content=query))\n",
    "        chat_history.append(AIMessage(content=result[\"answer\"]))\n",
    "#         print(chat_history)\n",
    "\n",
    "\n",
    "# Main function to start the continual chat\n",
    "if __name__ == \"__main__\":\n",
    "    continual_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5874710,
     "sourceId": 9624403,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5874721,
     "sourceId": 9624416,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5874798,
     "sourceId": 9624519,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
