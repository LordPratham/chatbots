{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T16:54:30.118814Z",
     "iopub.status.busy": "2024-10-14T16:54:30.118436Z",
     "iopub.status.idle": "2024-10-14T16:55:33.445097Z",
     "shell.execute_reply": "2024-10-14T16:55:33.443798Z",
     "shell.execute_reply.started": "2024-10-14T16:54:30.118776Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai==0.1.8 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from -r requirement.txt (line 1)) (0.1.8)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from -r requirement.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: langchain==0.2.1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from -r requirement.txt (line 3)) (0.2.1)\n",
      "Requirement already satisfied: langchain-community==0.2.1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from -r requirement.txt (line 4)) (0.2.1)\n",
      "Requirement already satisfied: langchain-anthropic==0.1.15 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from -r requirement.txt (line 5)) (0.1.15)\n",
      "Requirement already satisfied: langchain-google-genai==1.0.5 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from -r requirement.txt (line 6)) (1.0.5)\n",
      "Requirement already satisfied: langchain-google-firestore==0.3.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from -r requirement.txt (line 7)) (0.3.0)\n",
      "Requirement already satisfied: firestore==0.0.8 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from -r requirement.txt (line 8)) (0.0.8)\n",
      "Requirement already satisfied: chromadb==0.5.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from -r requirement.txt (line 9)) (0.5.0)\n",
      "Requirement already satisfied: tiktoken==0.7.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from -r requirement.txt (line 10)) (0.7.0)\n",
      "Requirement already satisfied: sentence-transformers==3.0.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from -r requirement.txt (line 11)) (3.0.0)\n",
      "Requirement already satisfied: bs4==0.0.2 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from -r requirement.txt (line 12)) (0.0.2)\n",
      "Requirement already satisfied: firecrawl-py==0.0.13 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from -r requirement.txt (line 13)) (0.0.13)\n",
      "Requirement already satisfied: langchainhub==0.1.18 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from -r requirement.txt (line 14)) (0.1.18)\n",
      "Requirement already satisfied: wikipedia==1.4.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from -r requirement.txt (line 15)) (1.4.0)\n",
      "Requirement already satisfied: tavily-python==0.3.3 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from -r requirement.txt (line 16)) (0.3.3)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.2 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from langchain-openai==0.1.8->-r requirement.txt (line 1)) (0.2.41)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.26.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from langchain-openai==0.1.8->-r requirement.txt (line 1)) (1.51.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from langchain==0.2.1->-r requirement.txt (line 3)) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from langchain==0.2.1->-r requirement.txt (line 3)) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from langchain==0.2.1->-r requirement.txt (line 3)) (3.10.9)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from langchain==0.2.1->-r requirement.txt (line 3)) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from langchain==0.2.1->-r requirement.txt (line 3)) (0.1.133)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from langchain==0.2.1->-r requirement.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from langchain==0.2.1->-r requirement.txt (line 3)) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from langchain==0.2.1->-r requirement.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from langchain==0.2.1->-r requirement.txt (line 3)) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from langchain-community==0.2.1->-r requirement.txt (line 4)) (0.6.7)\n",
      "Requirement already satisfied: anthropic<1,>=0.28.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from langchain-anthropic==0.1.15->-r requirement.txt (line 5)) (0.36.0)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from langchain-anthropic==0.1.15->-r requirement.txt (line 5)) (0.7.1)\n",
      "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from langchain-google-genai==1.0.5->-r requirement.txt (line 6)) (0.5.4)\n",
      "Requirement already satisfied: google-cloud-firestore<3.0.0,>=2.16.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from langchain-google-firestore==0.3.0->-r requirement.txt (line 7)) (2.19.0)\n",
      "Requirement already satisfied: more-itertools<11.0.0,>=10.2.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from langchain-google-firestore==0.3.0->-r requirement.txt (line 7)) (10.5.0)\n",
      "Requirement already satisfied: firebase-admin in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from firestore==0.0.8->-r requirement.txt (line 8)) (6.5.0)\n",
      "Requirement already satisfied: iso8601 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from firestore==0.0.8->-r requirement.txt (line 8)) (2.1.0)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from chromadb==0.5.0->-r requirement.txt (line 9)) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from chromadb==0.5.0->-r requirement.txt (line 9)) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from chromadb==0.5.0->-r requirement.txt (line 9)) (0.115.0)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.0->-r requirement.txt (line 9)) (0.31.1)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from chromadb==0.5.0->-r requirement.txt (line 9)) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from chromadb==0.5.0->-r requirement.txt (line 9)) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from chromadb==0.5.0->-r requirement.txt (line 9)) (1.19.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from chromadb==0.5.0->-r requirement.txt (line 9)) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from chromadb==0.5.0->-r requirement.txt (line 9)) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from chromadb==0.5.0->-r requirement.txt (line 9)) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from chromadb==0.5.0->-r requirement.txt (line 9)) (1.27.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from chromadb==0.5.0->-r requirement.txt (line 9)) (0.20.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from chromadb==0.5.0->-r requirement.txt (line 9)) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from chromadb==0.5.0->-r requirement.txt (line 9)) (4.66.5)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from chromadb==0.5.0->-r requirement.txt (line 9)) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from chromadb==0.5.0->-r requirement.txt (line 9)) (6.4.5)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from chromadb==0.5.0->-r requirement.txt (line 9)) (1.66.2)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from chromadb==0.5.0->-r requirement.txt (line 9)) (4.2.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from chromadb==0.5.0->-r requirement.txt (line 9)) (0.12.5)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from chromadb==0.5.0->-r requirement.txt (line 9)) (31.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from chromadb==0.5.0->-r requirement.txt (line 9)) (5.0.1)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from chromadb==0.5.0->-r requirement.txt (line 9)) (3.10.7)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from tiktoken==0.7.0->-r requirement.txt (line 10)) (2024.9.11)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from sentence-transformers==3.0.0->-r requirement.txt (line 11)) (4.45.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from sentence-transformers==3.0.0->-r requirement.txt (line 11)) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from sentence-transformers==3.0.0->-r requirement.txt (line 11)) (1.5.2)\n",
      "Requirement already satisfied: scipy in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from sentence-transformers==3.0.0->-r requirement.txt (line 11)) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from sentence-transformers==3.0.0->-r requirement.txt (line 11)) (0.25.2)\n",
      "Requirement already satisfied: Pillow in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from sentence-transformers==3.0.0->-r requirement.txt (line 11)) (10.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from bs4==0.0.2->-r requirement.txt (line 12)) (4.12.3)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from langchainhub==0.1.18->-r requirement.txt (line 14)) (2.32.0.20240914)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.1->-r requirement.txt (line 3)) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.1->-r requirement.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.1->-r requirement.txt (line 3)) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.1->-r requirement.txt (line 3)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.1->-r requirement.txt (line 3)) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.1->-r requirement.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from anthropic<1,>=0.28.0->langchain-anthropic==0.1.15->-r requirement.txt (line 5)) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from anthropic<1,>=0.28.0->langchain-anthropic==0.1.15->-r requirement.txt (line 5)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from anthropic<1,>=0.28.0->langchain-anthropic==0.1.15->-r requirement.txt (line 5)) (0.28.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from anthropic<1,>=0.28.0->langchain-anthropic==0.1.15->-r requirement.txt (line 5)) (0.6.1)\n",
      "Requirement already satisfied: sniffio in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from anthropic<1,>=0.28.0->langchain-anthropic==0.1.15->-r requirement.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: packaging>=19.1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from build>=1.0.3->chromadb==0.5.0->-r requirement.txt (line 9)) (24.1)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from build>=1.0.3->chromadb==0.5.0->-r requirement.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.1->-r requirement.txt (line 4)) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.1->-r requirement.txt (line 4)) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb==0.5.0->-r requirement.txt (line 9)) (0.38.6)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-firestore<3.0.0,>=2.16.0->langchain-google-firestore==0.3.0->-r requirement.txt (line 7)) (2.21.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from google-cloud-firestore<3.0.0,>=2.16.0->langchain-google-firestore==0.3.0->-r requirement.txt (line 7)) (2.35.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from google-cloud-firestore<3.0.0,>=2.16.0->langchain-google-firestore==0.3.0->-r requirement.txt (line 7)) (2.4.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from google-cloud-firestore<3.0.0,>=2.16.0->langchain-google-firestore==0.3.0->-r requirement.txt (line 7)) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from google-cloud-firestore<3.0.0,>=2.16.0->langchain-google-firestore==0.3.0->-r requirement.txt (line 7)) (4.25.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.5->-r requirement.txt (line 6)) (0.6.4)\n",
      "Requirement already satisfied: google-api-python-client in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.5->-r requirement.txt (line 6)) (2.149.0)\n",
      "Requirement already satisfied: filelock in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers==3.0.0->-r requirement.txt (line 11)) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers==3.0.0->-r requirement.txt (line 11)) (2024.9.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r requirement.txt (line 9)) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r requirement.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r requirement.txt (line 9)) (2.9.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r requirement.txt (line 9)) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r requirement.txt (line 9)) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r requirement.txt (line 9)) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r requirement.txt (line 9)) (2.2.3)\n",
      "Requirement already satisfied: durationpy>=0.7 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r requirement.txt (line 9)) (0.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai==0.1.8->-r requirement.txt (line 1)) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.1->-r requirement.txt (line 3)) (1.0.0)\n",
      "Requirement already satisfied: coloredlogs in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb==0.5.0->-r requirement.txt (line 9)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb==0.5.0->-r requirement.txt (line 9)) (24.3.25)\n",
      "Requirement already satisfied: sympy in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb==0.5.0->-r requirement.txt (line 9)) (1.13.3)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb==0.5.0->-r requirement.txt (line 9)) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb==0.5.0->-r requirement.txt (line 9)) (8.4.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.0->-r requirement.txt (line 9)) (1.65.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.0->-r requirement.txt (line 9)) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.27.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.0->-r requirement.txt (line 9)) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.48b0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.0->-r requirement.txt (line 9)) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.48b0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.0->-r requirement.txt (line 9)) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.0->-r requirement.txt (line 9)) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.48b0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.0->-r requirement.txt (line 9)) (0.48b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.0->-r requirement.txt (line 9)) (75.1.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.0->-r requirement.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.0->-r requirement.txt (line 9)) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb==0.5.0->-r requirement.txt (line 9)) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb==0.5.0->-r requirement.txt (line 9)) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain==0.2.1->-r requirement.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain==0.2.1->-r requirement.txt (line 3)) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.2.1->-r requirement.txt (line 3)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.2.1->-r requirement.txt (line 3)) (2.10)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.1->-r requirement.txt (line 3)) (3.1.1)\n",
      "Requirement already satisfied: networkx in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers==3.0.0->-r requirement.txt (line 11)) (3.4)\n",
      "Requirement already satisfied: jinja2 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers==3.0.0->-r requirement.txt (line 11)) (3.1.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers==3.0.0->-r requirement.txt (line 11)) (0.4.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from typer>=0.9.0->chromadb==0.5.0->-r requirement.txt (line 9)) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from typer>=0.9.0->chromadb==0.5.0->-r requirement.txt (line 9)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from typer>=0.9.0->chromadb==0.5.0->-r requirement.txt (line 9)) (13.9.2)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.5.0->-r requirement.txt (line 9)) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.0->-r requirement.txt (line 9)) (0.6.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.0->-r requirement.txt (line 9)) (0.20.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.0->-r requirement.txt (line 9)) (0.24.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.0->-r requirement.txt (line 9)) (13.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from beautifulsoup4->bs4==0.0.2->-r requirement.txt (line 12)) (2.6)\n",
      "Requirement already satisfied: cachecontrol>=0.12.6 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from firebase-admin->firestore==0.0.8->-r requirement.txt (line 8)) (0.14.0)\n",
      "Requirement already satisfied: google-cloud-storage>=1.37.1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from firebase-admin->firestore==0.0.8->-r requirement.txt (line 8)) (2.18.2)\n",
      "Requirement already satisfied: pyjwt>=2.5.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from pyjwt[crypto]>=2.5.0->firebase-admin->firestore==0.0.8->-r requirement.txt (line 8)) (2.9.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers==3.0.0->-r requirement.txt (line 11)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers==3.0.0->-r requirement.txt (line 11)) (3.5.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=0.5.2 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from cachecontrol>=0.12.6->firebase-admin->firestore==0.0.8->-r requirement.txt (line 8)) (1.1.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-firestore<3.0.0,>=2.16.0->langchain-google-firestore==0.3.0->-r requirement.txt (line 7)) (1.62.3)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.5->-r requirement.txt (line 6)) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.5->-r requirement.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.5->-r requirement.txt (line 6)) (4.1.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-firestore<3.0.0,>=2.16.0->langchain-google-firestore==0.3.0->-r requirement.txt (line 7)) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-firestore<3.0.0,>=2.16.0->langchain-google-firestore==0.3.0->-r requirement.txt (line 7)) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-firestore<3.0.0,>=2.16.0->langchain-google-firestore==0.3.0->-r requirement.txt (line 7)) (4.9)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from google-cloud-storage>=1.37.1->firebase-admin->firestore==0.0.8->-r requirement.txt (line 8)) (2.7.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from google-cloud-storage>=1.37.1->firebase-admin->firestore==0.0.8->-r requirement.txt (line 8)) (1.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->anthropic<1,>=0.28.0->langchain-anthropic==0.1.15->-r requirement.txt (line 5)) (1.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.5.0->-r requirement.txt (line 9)) (3.20.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain-openai==0.1.8->-r requirement.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from pyjwt[crypto]>=2.5.0->firebase-admin->firestore==0.0.8->-r requirement.txt (line 8)) (43.0.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.5.0->-r requirement.txt (line 9)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.5.0->-r requirement.txt (line 9)) (2.18.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.1->-r requirement.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain==0.2.1->-r requirement.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.5.0->-r requirement.txt (line 9)) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers==3.0.0->-r requirement.txt (line 11)) (3.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.5.0->-r requirement.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.5.0->firebase-admin->firestore==0.0.8->-r requirement.txt (line 8)) (1.17.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.5->-r requirement.txt (line 6)) (3.1.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb==0.5.0->-r requirement.txt (line 9)) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-firestore<3.0.0,>=2.16.0->langchain-google-firestore==0.3.0->-r requirement.txt (line 7)) (0.6.1)\n",
      "Requirement already satisfied: pycparser in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.5.0->firebase-admin->firestore==0.0.8->-r requirement.txt (line 8)) (2.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T16:55:58.649332Z",
     "iopub.status.busy": "2024-10-14T16:55:58.648903Z",
     "iopub.status.idle": "2024-10-14T16:55:58.655229Z",
     "shell.execute_reply": "2024-10-14T16:55:58.654133Z",
     "shell.execute_reply.started": "2024-10-14T16:55:58.649290Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requirements done\n"
     ]
    }
   ],
   "source": [
    "print(\"requirements done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-14T17:05:16.125144Z",
     "iopub.status.busy": "2024-10-14T17:05:16.124196Z",
     "iopub.status.idle": "2024-10-14T17:05:16.143480Z",
     "shell.execute_reply": "2024-10-14T17:05:16.142608Z",
     "shell.execute_reply.started": "2024-10-14T17:05:16.125098Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# Load environment variables from .env\n",
    "load_dotenv(\".env\")\n",
    "# print(os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T16:56:03.719311Z",
     "iopub.status.busy": "2024-10-14T16:56:03.718329Z",
     "iopub.status.idle": "2024-10-14T16:56:03.723770Z",
     "shell.execute_reply": "2024-10-14T16:56:03.722735Z",
     "shell.execute_reply.started": "2024-10-14T16:56:03.719272Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# current_dir = \n",
    "file_path = \"./cleaned_txt/Wheat-Growers-Guide_cleaned.txt\"\n",
    "db_dir = os.path.join(\"./\", \"db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T16:56:06.268178Z",
     "iopub.status.busy": "2024-10-14T16:56:06.267797Z",
     "iopub.status.idle": "2024-10-14T16:56:06.280118Z",
     "shell.execute_reply": "2024-10-14T16:56:06.279222Z",
     "shell.execute_reply.started": "2024-10-14T16:56:06.268139Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wheat growers guide contents soils and climate 2 varietal choice 2 land preparation and soil conditioning 2 soil conditioning 3 tillage procedures 3 time of planting 3 seeding rates 4 irrigation requirements and scheduling 4 fertilisation 5 weed control 6 pests and diseases 6 whe at production general tips 7 centre pivot irrigation scheduling a general guide 9 chemigationfertigation calibrations guide 9 harvesting 10 2 soils and climate wheat is a temperate crop and is best grown in winter under\n",
      "18652\n"
     ]
    }
   ],
   "source": [
    "with open(file_path,\"r\") as f:\n",
    "    text=f.read()\n",
    "    print(text[:500])\n",
    "    print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T16:56:09.722988Z",
     "iopub.status.busy": "2024-10-14T16:56:09.722597Z",
     "iopub.status.idle": "2024-10-14T16:56:09.738656Z",
     "shell.execute_reply": "2024-10-14T16:56:09.737652Z",
     "shell.execute_reply.started": "2024-10-14T16:56:09.722937Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Document Chunks Information ---\n",
      "Number of document chunks: 1\n",
      "Sample chunk:\n",
      "wheat growers guide contents soils and climate 2 varietal choice 2 land preparation and soil conditioning 2 soil conditioning 3 tillage procedures 3 time of planting 3 seeding rates 4 irrigation requirements and scheduling 4 fertilisation 5 weed control 6 pests and diseases 6 whe at production general tips 7 centre pivot irrigation scheduling a general guide 9 chemigationfertigation calibrations guide 9 harvesting 10 2 soils and climate wheat is a temperate crop and is best grown in winter under irrigation with optimum day temperatures of between 15 20oc and cooler nights giving the best yields there are some varieties that may be grown in summer such as sahai but generally there is high disea se and weed pressure in summer accompanied by warmer temperatures that result in depressed yields 3tha therefore winter is the best time for growing wheat the crop is adapted to a wide range of soils the soils must be well drained with an optimum ph range of 55 65 on a calcium chloride scale wheat yields are greater in the highveld 1200 masl metres above sea level and middleveld 900 1250 masl with yield potential of 8 to 12 tha compared to the lowveld 900 masl where yields average of 45 7 tha under good management varietal choice new varieties are continuously produced for wheat production because of the threat of disease especially leaf rust and powdery mildew the varieties from seed co ideal for bread making are short sta tured disease resistant and well adapted to winter production current varieties include sc nduna white seeded sc sc sekuru red seeded sc smart red seeded and sc stallion red seeded sky red seeded select white seeded serena white seeded sc sahai is a summer variety which can be planted in mid summer around january land preparation and soil conditioning the most suitable soil for wheat is one with a good effective depth with a fine tilth to ensure seed soil contact good seed soil contact ensure good crop emergence and stand which are the basis for good yields favourable physical properties good internal drainage an optimal moisture regime chemical properties sufficient and balanced quantities of nutrients npk and other micro nutrientstrace nutrients biological properties good level of organic matter and with beneficial micro organisms the objective of soil tillage is to maintain the existing structure of soil or to improve the structure of poorly structured soils as well as addressing the three properties as mentioned above physical chemical and biological 3 soil conditioning lime can be applied if required to sweeten acidic soils to the ph optimum range lime application should be based on soil analysis prescriptions gypsum improves soil physical structure ie removes hard setting clodiness removes surface crusting and poor workability as well as supplying the soil with complimentary calcium and sulphur for good crop standing and growth tillage procedures there are several options of tillage which fall under two broad categories conservational and conventional tillage which can be adopted in wheat production the conventional tillage procedure follows the following steps deep ploughing ripping or chisel plough l iming and basal fertilizer application discing and then followed by rolling a roller can be pulled concurrently behind a disc harrow conservational tillage also known as zerominimum tillage is another cheaper and more sustainable option which farmers c an adopt time of planting the optimum time for planting winter wheat is between mid april and the last week of may and even earlier in the lowvelds sometimes planting time can be extended to mid june but not normally recommended delayed planting resul ts in a loss of about 50kghaday after may the first two weeks of may tend to give the best yields in the highveld areas adhering to the optimum planting time has some agronomic explanations and rationales early summer rain escape rains which come aft er the wheat has reached physiological maturity causes sprouting grain germination in the ear and result in down grading of the wheat due to a decline in baking qualities disease escape disease pressure especially for rust diseases normally rises when temperatures start to warm up around august and an early planted crop would have gotten a good head start without disease pressure pest escape likewise pest pressure such as aphids start to rise when temperatures start to rise an early planted crop w ill have a good head start ahead of pest pressure 4 early planting will result in early harvesting around september one of the key considerations for the adoption of double cropping is early planting and early harvesting for both summer and winter crops t he farmer will come in with his summer crop on time when wheat is planted and harvested early generally wheat takes about 125 140 days to physiological maturity depending on variety altitude and weather conditions the higher the altitude the longer the time from planting to maturity wheat critical stages such as crop establishment tillering flowering and grain filling will concide with the optimum growth conditions when the crop is early planted for instance for robust tillering ie for the pla nt to produce secondary stems 4 5 weeks after crop emergence requires very cool conditions that normally occurs in may and june while flowering 60 90 days and grain filling 90 days must not coincide with frosty conditions to avoid crop sterili ty seeding rates the optimum plant population for wheat is 220 250 plants per m2 seed rate depends on the seed size germination percentage planting conditions and planting method to achieve optimum population density a seeding rate of about 110 125 kgha when drilling and 125 135 kgha when broadcasting with a vicon spreader is recommended to ensure good crop standability and yield farmers should adhere to these optimum population densities diseases such as powdery mildew are also minimized wit h good agronomic practices irrigation requirements and scheduling since there is very little or no rainfall during winter in zimbabwe irrigation is required to achieve a high yielding wheat crop the total gross amount of water required is between 450 and 600 mm per ha ie 45 6 mega litres per ha depending on method of irrigation overhead irrigation with sprinkler or use of centre pivots and must be applied as the crop requires it the key points are the soil must be brought to field capacity to the full potential rooting depth about 12 m at planting to emerge the crop a light irrigation must be applied at the 4th or 5th day after sowing to break the crust to ensure good crop emergence 5 a light irrigation must be applied at 14 to 17 days af ter emergence to stimulate crown root development and tillering and irrigation thereafter must be applied to match crop water use on sandy soils with low water holding capacities irrigate frequently 7 to 9 day cycles with 30 35mm net on clays and sa ndy clays with good water holding capacities irrigation may be less frequent with larger amounts 10 to 14 day cycles with 40 45 mm net this is a general irrigation scheduling guide for an informed irrigation scheduling the use of a soil auger to eva luate the soil water content ahead and behind the irrigation line is a good aid to irrigation management irrigation is terminated when the neck of the earsspikeshead peduncle turn yellow ie physiological maturity crop hardening after the crop has e merged the hardening stage begins this induces crown root development as well as tillering the recommended hardening period irrigation is temporarily terminated during this stage is 10 and 14 days in light and heavy soils respectively top dressing f ertilizer and herbicide application is done after a light irrigation which follows the hardening period normally about 21 days after emergence fertilisation the fertiliser regime management in wheat like any other crop must be tailored to the soil fertility status the yield potential and the grain quality requirements as a general guide wheat requires a basal application of 300 to 500 kgha of a compound fertiliser such as 7 147 and a top dressing of 350 to 500 kg of urea or ammonium nitrate per h a both fertilizer dressings are broadcast by a vicon generally 160 190kgha of nitrogen units n 50 70 units of phosphorous p and 30 50 units of potassium k are adequate for optimum plant growth basal fertilizer need incorporation into the soil by discing and should be applied after primary tillage the top dressing is usually applied in one application between 14 21 days after emergence on heavy soils and in two applications of equal amounts at 14 and 35 days after emergence on sandy s oils top dressing should be applied after the hardening stage top dressing is essential for good leaf and general plant growth and ultimately the yield but also importantly for attaining good protein 6 levels the minimum protein level requirement for pre mium good quality wheat is 11 it is one of the considerations for grading and pricing of wheat attainment of good protein levels is also determined by varietal choice and general management application of nitrogen after flowering can also boost the grain protein content of wheat all fertility management practices must be based on proper full soil analysis recommendations by approved laboratories weed control farmers are advised to use some wheat specific post emergence herbicide which should be applied after a light irrigation which follows the hardening period 2 wace weeks after crop emergence we also recommend farmers to apply specific herbicides against volunteer crops puma super is normally sprayed when wheat is planted after a maize crop against maize volunteer plants for soya volunteers a herbicide called ally is recommended banvel and mcpa combination covers a wide spectrum of broad leaf weeds and is recommended it is important for farmers to read labels whenever they are applying herbicides pests and diseases aphids and stalk borers can attack wheat with aphids coming in earlier soon after tillering while borers can attack the plant from flowering onwards farmers must also be on the look out for fall armyworm given that wheat is one of the host crops to th e pest these pests can be controlled with appropriate pesticide sprays after scouting during the late grain filling period quelea birds may consume much grain and reduce yields significantly if not attended to a pesticide molecule called 910 anthraq uinone 50 wp bird shield has been developed which can be used as a seed dressing or as a foliar spray at soft dough stage efficacy of this pesticide molecule can be enhanced by applying with a sticker and also a rainfast period of 4 hours or more thi s pesticide molecule will act as a bird repellent this is the best and the most efficient option the other option is bird scaring using bells tins whistles discsreflectors etc by bird scaring gangs 7 diseases such as leaf rust stem rust powdery mildew fusarium head blight and take all may cause yield reduction farmers must seek professional advice on how to control these diseases the best bet is for farmers to grow resistant varieties and seed co wheat varieties such as sc select are resistant to these diseases generally two preventative fungicide sprays are recommended if farmers are located in disease prone areas and gives some form of insurance against climate change that can result in new disease pathotypes nb farmers are encouraged to scout their wheat crop for diseases pests and deficiencies and make spraying decisions early when pestdisease reaches economic threshold levels consult agrochemical companies for more information on chemicals always read chemical labels carefully use safe practices and adequate protective gear during application wheat production general tips 1 plan ahead evaluate available water resources in order to calculate wheat area based on proposed gross application irrigation equipment and infrastructure must be ready with checks made on pumping unit conveyance system pivot sprinkler condition and nozzle wear 2 soil condition and fertilisation soil sampling is always the starting point in determining the rates and types of soil conditioners and fertilisers to be used 3 start at field capacity crop emergence requires a soil profile that is at field capacity down to the full potential of the rooting depth this should be achieved by the 3 4 leaf stage at the latest this is important because wh eat roots grow downwards at a rate of 20 30 mmday and any dry layers within the profile will impede root growth and proliferation 4 establishment irrigation seed germinates happily in the presence of good soil moisture establishment irrigations need to be geared to achieve a uniform and adequate stand and this depends on planting method and uniformity of irrigation drilled seed normally requires one good irrigation to cause germination because of good soil seed contact broadcasted seed or zero tillag e fields require frequent 2 3 day intervals light irrigations 25mm to effect establishment a light irrigation is essential 4 7 days after 8 the first irrigation in soils that are prone to crusting to assist with emergence 5 ensure crown root devel opment and tillering at 3 4 leaf stage 14 17 days after the first germination irrigation crown roots and the ear begin to develop and tillers start growing water deficit adversely affect these processes yet they play an important role in yield for mation at this stage usually the top 100 150mm of the soil is dry and crown roots will not grow into dry soil it is necessary to apply a light irrigation to stimulate crown roots and tillering it is also an appropriate time to top dress the wheat wit h nitrogen fertilizer 6 initiate an irrigation schedule early and monitor the soil and crop through to maturity scheduling assist the manager to monitor crop progress and thereby ensure the best treatment possible is given to the crop assess soil and crop conditions before and after each irrigation cycle to evaluate whether or not the irrigation is recharging the soil profile to the satisfaction of the plant needs a soil auger is extremely useful in this regard an auger test ahead of the line will show h ow deep the plant is drawing water while an auger test two positions behind the line will show how effective the irrigation application is in replenishing the soil well irrigated wheat has a dark green colour soft large leaves and many tillers whilst s tressedwheat has a bluish colour hard spikey leaves which may also roll up in some varieties and a few tillers with small ears 7 crop maintenance weed disease and pest control are important in achieving a good crop 8 timing of the last irrigation ther e is no point in irrigating a yellowing crop and grains are fully formed and after hard dough stage full maturity is reached when the peduncle neck area below the earspike turns yellow irrigation applied during later grain fill or during grain dry do wn is of no value to the crop and may even reduce the quality of the grain water after ripening may cause pre harvesting sprouting germination in the ear leading to down grading of wheat due to reduced grain quality 9 keeping irrigation records it helps to plan future irrigation practices useful records include a water usage with a flow meter b energy use either electricity units or diesel litres c dates and amounts of irrigation applied 9 d evaporation and air temperature e labour centre pivot irrigation scheduling a general guide generally center pivot irrigation is the simplest method of irrigating any crop for efficiency there are factors to consider when using center pivots it is proven that a farmer gets more effective water application on a fixed center pivot as compared to a towable pivot this is largely due to the fact that there is run down time loss due to towing from one center to the other it is advisable that when using a fixed center pivot anything between a 10mm and 12 mm spray package is recommended however if it is a towable center pivot and a farmer intends to do two circles with one pivot a bigger spray package is more ideal for the pivot and this can be from 14 mm to 20 mm spray package depending on specific requirements a bigger spray package is recommended for towable center pivots to reduce the turnaround time of the center pivot to avoid moisture stress in the other circle for easy water application a farmer is advised to run their pivot in wet mode the wet mode allows the operator to program the pivot to apply the exact amount of mm required at the particular stage of growth of the crop in instances where the pivot is run in dry mode the operator will be required to calculate the percentage on the timer which corresponds with the amount of water mm that need to be applied and in most cases errors on calculation are sometimes common and a farmer will not achieve the intended spray volumes it is advisable then that farmers should ask their centre pivot service provider to program the machine to work in the wet mode chemigationfertigation calibrations guide calibration factors that need to be considered when using a centre pivot for chemigation and fertigation include the sizing of the dosing pump and its pumping rate a lways ensure you discuss with your pumps specialist before purchasing a dosing pump for correct dosing pump sizing for your applications as applications vary from case to case it is also important that your fertigation or chemigation unit is as close as p ossible to the centre pivot inlet as possible 10 generally not more than six metres below are critical factors to be considered when using a pivot for both chemigation and fertigation 1 length of the pivot to the edge of the effective wetted area 2 length of the pivot to the last tower 3 last tower travel distance in a given amount of time running at present application this point has to be verified physically by the farmer with the pivot running in wet mode at the present application rate do not rely on liter ature or your pivot control panel as other factors such as terrain eg slopegradient can affect your last tower run speed so this must to be verified 4 targeted product application rate in kgslitres per hectare 5 product concentration in kgslitres per m3 of active ingredient 6 percentage of a full circle centre pivot that will be used during the application harvesting on a large scale wheat is usually harvested by combine but it is possible to hand harvest and thresh small areas of wheat combine harve sters must be set carefully and operated according to service manuals in order to keep harvest losses to a minimum\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "\n",
    "# Check if the text file exists\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"The file {file_path} does not exist. Please check the path.\"\n",
    "    )\n",
    "\n",
    "# Read the text content from the file\n",
    "loader = TextLoader(file_path)\n",
    "documents = loader.load()\n",
    "\n",
    "# Split the document into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Display information about the split documents\n",
    "print(\"\\n--- Document Chunks Information ---\")\n",
    "print(f\"Number of document chunks: {len(docs)}\")\n",
    "print(f\"Sample chunk:\\n{docs[0].page_content}\\n\")\n",
    "\n",
    "\n",
    "# Function to create and persist vector store\n",
    "def create_vector_store(docs, embeddings, store_name):\n",
    "    persistent_directory = os.path.join(db_dir, store_name)\n",
    "    if not os.path.exists(persistent_directory):\n",
    "        print(f\"\\n--- Creating vector store {store_name} ---\")\n",
    "        Chroma.from_documents(\n",
    "            docs, embeddings, persist_directory=persistent_directory)\n",
    "        print(f\"--- Finished creating vector store {store_name} ---\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"Vector store {store_name} already exists. No need to initialize.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T16:56:14.275884Z",
     "iopub.status.busy": "2024-10-14T16:56:14.275503Z",
     "iopub.status.idle": "2024-10-14T16:56:39.380177Z",
     "shell.execute_reply": "2024-10-14T16:56:39.379060Z",
     "shell.execute_reply.started": "2024-10-14T16:56:14.275847Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using Hugging Face Transformers ---\n",
      "Vector store chroma_db_huggingface already exists. No need to initialize.\n",
      "Embedding demonstrations for OpenAI and Hugging Face completed.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "print(\"\\n--- Using Hugging Face Transformers ---\")\n",
    "# huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "#     model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    "# )\n",
    "huggingface_embeddings= pickle.load(open(\"huggingface_embeddings.pkl\",\"rb\"))\n",
    "create_vector_store(docs, huggingface_embeddings, \"chroma_db_huggingface\")\n",
    "\n",
    "print(\"Embedding demonstrations for OpenAI and Hugging Face completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T16:56:39.382667Z",
     "iopub.status.busy": "2024-10-14T16:56:39.381935Z",
     "iopub.status.idle": "2024-10-14T16:56:39.389801Z",
     "shell.execute_reply": "2024-10-14T16:56:39.388672Z",
     "shell.execute_reply.started": "2024-10-14T16:56:39.382631Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def query_vector_store(store_name, query, embedding_function):\n",
    "    persistent_directory = os.path.join(db_dir, store_name)\n",
    "    if os.path.exists(persistent_directory):\n",
    "        print(f\"\\n--- Querying the Vector Store {store_name} ---\")\n",
    "        db = Chroma(\n",
    "            persist_directory=persistent_directory,\n",
    "            embedding_function=embedding_function,\n",
    "        )\n",
    "        retriever = db.as_retriever(\n",
    "            search_type=\"similarity_score_threshold\",\n",
    "            search_kwargs={\"k\": 5, \"score_threshold\": 0.1},\n",
    "        )\n",
    "        relevant_docs = retriever.invoke(query)\n",
    "        # Display the relevant results with metadata\n",
    "        print(f\"\\n--- Relevant Documents for {store_name} ---\")\n",
    "        for i, doc in enumerate(relevant_docs, 1):\n",
    "            print(f\"Document {i}:\\n{doc.page_content}\\n\")\n",
    "            if doc.metadata:\n",
    "                print(f\"Source: {doc.metadata.get('source', 'Unknown')}\\n\")\n",
    "    else:\n",
    "        print(f\"Vector store {store_name} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T16:56:54.741021Z",
     "iopub.status.busy": "2024-10-14T16:56:54.739780Z",
     "iopub.status.idle": "2024-10-14T16:56:54.829227Z",
     "shell.execute_reply": "2024-10-14T16:56:54.828097Z",
     "shell.execute_reply.started": "2024-10-14T16:56:54.740955Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Querying the Vector Store chroma_db_huggingface ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 5 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Relevant Documents for chroma_db_huggingface ---\n",
      "Document 1:\n",
      "wheat growers guide contents soils and climate 2 varietal choice 2 land preparation and soil conditioning 2 soil conditioning 3 tillage procedures 3 time of planting 3 seeding rates 4 irrigation requirements and scheduling 4 fertilisation 5 weed control 6 pests and diseases 6 whe at production general tips 7 centre pivot irrigation scheduling a general guide 9 chemigationfertigation calibrations guide 9 harvesting 10 2 soils and climate wheat is a temperate crop and is best grown in winter under irrigation with optimum day temperatures of between 15 20oc and cooler nights giving the best yields there are some varieties that may be grown in summer such as sahai but generally there is high disea se and weed pressure in summer accompanied by warmer temperatures that result in depressed yields 3tha therefore winter is the best time for growing wheat the crop is adapted to a wide range of soils the soils must be well drained with an optimum ph range of 55 65 on a calcium chloride scale wheat yields are greater in the highveld 1200 masl metres above sea level and middleveld 900 1250 masl with yield potential of 8 to 12 tha compared to the lowveld 900 masl where yields average of 45 7 tha under good management varietal choice new varieties are continuously produced for wheat production because of the threat of disease especially leaf rust and powdery mildew the varieties from seed co ideal for bread making are short sta tured disease resistant and well adapted to winter production current varieties include sc nduna white seeded sc sc sekuru red seeded sc smart red seeded and sc stallion red seeded sky red seeded select white seeded serena white seeded sc sahai is a summer variety which can be planted in mid summer around january land preparation and soil conditioning the most suitable soil for wheat is one with a good effective depth with a fine tilth to ensure seed soil contact good seed soil contact ensure good crop emergence and stand which are the basis for good yields favourable physical properties good internal drainage an optimal moisture regime chemical properties sufficient and balanced quantities of nutrients npk and other micro nutrientstrace nutrients biological properties good level of organic matter and with beneficial micro organisms the objective of soil tillage is to maintain the existing structure of soil or to improve the structure of poorly structured soils as well as addressing the three properties as mentioned above physical chemical and biological 3 soil conditioning lime can be applied if required to sweeten acidic soils to the ph optimum range lime application should be based on soil analysis prescriptions gypsum improves soil physical structure ie removes hard setting clodiness removes surface crusting and poor workability as well as supplying the soil with complimentary calcium and sulphur for good crop standing and growth tillage procedures there are several options of tillage which fall under two broad categories conservational and conventional tillage which can be adopted in wheat production the conventional tillage procedure follows the following steps deep ploughing ripping or chisel plough l iming and basal fertilizer application discing and then followed by rolling a roller can be pulled concurrently behind a disc harrow conservational tillage also known as zerominimum tillage is another cheaper and more sustainable option which farmers c an adopt time of planting the optimum time for planting winter wheat is between mid april and the last week of may and even earlier in the lowvelds sometimes planting time can be extended to mid june but not normally recommended delayed planting resul ts in a loss of about 50kghaday after may the first two weeks of may tend to give the best yields in the highveld areas adhering to the optimum planting time has some agronomic explanations and rationales early summer rain escape rains which come aft er the wheat has reached physiological maturity causes sprouting grain germination in the ear and result in down grading of the wheat due to a decline in baking qualities disease escape disease pressure especially for rust diseases normally rises when temperatures start to warm up around august and an early planted crop would have gotten a good head start without disease pressure pest escape likewise pest pressure such as aphids start to rise when temperatures start to rise an early planted crop w ill have a good head start ahead of pest pressure 4 early planting will result in early harvesting around september one of the key considerations for the adoption of double cropping is early planting and early harvesting for both summer and winter crops t he farmer will come in with his summer crop on time when wheat is planted and harvested early generally wheat takes about 125 140 days to physiological maturity depending on variety altitude and weather conditions the higher the altitude the longer the time from planting to maturity wheat critical stages such as crop establishment tillering flowering and grain filling will concide with the optimum growth conditions when the crop is early planted for instance for robust tillering ie for the pla nt to produce secondary stems 4 5 weeks after crop emergence requires very cool conditions that normally occurs in may and june while flowering 60 90 days and grain filling 90 days must not coincide with frosty conditions to avoid crop sterili ty seeding rates the optimum plant population for wheat is 220 250 plants per m2 seed rate depends on the seed size germination percentage planting conditions and planting method to achieve optimum population density a seeding rate of about 110 125 kgha when drilling and 125 135 kgha when broadcasting with a vicon spreader is recommended to ensure good crop standability and yield farmers should adhere to these optimum population densities diseases such as powdery mildew are also minimized wit h good agronomic practices irrigation requirements and scheduling since there is very little or no rainfall during winter in zimbabwe irrigation is required to achieve a high yielding wheat crop the total gross amount of water required is between 450 and 600 mm per ha ie 45 6 mega litres per ha depending on method of irrigation overhead irrigation with sprinkler or use of centre pivots and must be applied as the crop requires it the key points are the soil must be brought to field capacity to the full potential rooting depth about 12 m at planting to emerge the crop a light irrigation must be applied at the 4th or 5th day after sowing to break the crust to ensure good crop emergence 5 a light irrigation must be applied at 14 to 17 days af ter emergence to stimulate crown root development and tillering and irrigation thereafter must be applied to match crop water use on sandy soils with low water holding capacities irrigate frequently 7 to 9 day cycles with 30 35mm net on clays and sa ndy clays with good water holding capacities irrigation may be less frequent with larger amounts 10 to 14 day cycles with 40 45 mm net this is a general irrigation scheduling guide for an informed irrigation scheduling the use of a soil auger to eva luate the soil water content ahead and behind the irrigation line is a good aid to irrigation management irrigation is terminated when the neck of the earsspikeshead peduncle turn yellow ie physiological maturity crop hardening after the crop has e merged the hardening stage begins this induces crown root development as well as tillering the recommended hardening period irrigation is temporarily terminated during this stage is 10 and 14 days in light and heavy soils respectively top dressing f ertilizer and herbicide application is done after a light irrigation which follows the hardening period normally about 21 days after emergence fertilisation the fertiliser regime management in wheat like any other crop must be tailored to the soil fertility status the yield potential and the grain quality requirements as a general guide wheat requires a basal application of 300 to 500 kgha of a compound fertiliser such as 7 147 and a top dressing of 350 to 500 kg of urea or ammonium nitrate per h a both fertilizer dressings are broadcast by a vicon generally 160 190kgha of nitrogen units n 50 70 units of phosphorous p and 30 50 units of potassium k are adequate for optimum plant growth basal fertilizer need incorporation into the soil by discing and should be applied after primary tillage the top dressing is usually applied in one application between 14 21 days after emergence on heavy soils and in two applications of equal amounts at 14 and 35 days after emergence on sandy s oils top dressing should be applied after the hardening stage top dressing is essential for good leaf and general plant growth and ultimately the yield but also importantly for attaining good protein 6 levels the minimum protein level requirement for pre mium good quality wheat is 11 it is one of the considerations for grading and pricing of wheat attainment of good protein levels is also determined by varietal choice and general management application of nitrogen after flowering can also boost the grain protein content of wheat all fertility management practices must be based on proper full soil analysis recommendations by approved laboratories weed control farmers are advised to use some wheat specific post emergence herbicide which should be applied after a light irrigation which follows the hardening period 2 wace weeks after crop emergence we also recommend farmers to apply specific herbicides against volunteer crops puma super is normally sprayed when wheat is planted after a maize crop against maize volunteer plants for soya volunteers a herbicide called ally is recommended banvel and mcpa combination covers a wide spectrum of broad leaf weeds and is recommended it is important for farmers to read labels whenever they are applying herbicides pests and diseases aphids and stalk borers can attack wheat with aphids coming in earlier soon after tillering while borers can attack the plant from flowering onwards farmers must also be on the look out for fall armyworm given that wheat is one of the host crops to th e pest these pests can be controlled with appropriate pesticide sprays after scouting during the late grain filling period quelea birds may consume much grain and reduce yields significantly if not attended to a pesticide molecule called 910 anthraq uinone 50 wp bird shield has been developed which can be used as a seed dressing or as a foliar spray at soft dough stage efficacy of this pesticide molecule can be enhanced by applying with a sticker and also a rainfast period of 4 hours or more thi s pesticide molecule will act as a bird repellent this is the best and the most efficient option the other option is bird scaring using bells tins whistles discsreflectors etc by bird scaring gangs 7 diseases such as leaf rust stem rust powdery mildew fusarium head blight and take all may cause yield reduction farmers must seek professional advice on how to control these diseases the best bet is for farmers to grow resistant varieties and seed co wheat varieties such as sc select are resistant to these diseases generally two preventative fungicide sprays are recommended if farmers are located in disease prone areas and gives some form of insurance against climate change that can result in new disease pathotypes nb farmers are encouraged to scout their wheat crop for diseases pests and deficiencies and make spraying decisions early when pestdisease reaches economic threshold levels consult agrochemical companies for more information on chemicals always read chemical labels carefully use safe practices and adequate protective gear during application wheat production general tips 1 plan ahead evaluate available water resources in order to calculate wheat area based on proposed gross application irrigation equipment and infrastructure must be ready with checks made on pumping unit conveyance system pivot sprinkler condition and nozzle wear 2 soil condition and fertilisation soil sampling is always the starting point in determining the rates and types of soil conditioners and fertilisers to be used 3 start at field capacity crop emergence requires a soil profile that is at field capacity down to the full potential of the rooting depth this should be achieved by the 3 4 leaf stage at the latest this is important because wh eat roots grow downwards at a rate of 20 30 mmday and any dry layers within the profile will impede root growth and proliferation 4 establishment irrigation seed germinates happily in the presence of good soil moisture establishment irrigations need to be geared to achieve a uniform and adequate stand and this depends on planting method and uniformity of irrigation drilled seed normally requires one good irrigation to cause germination because of good soil seed contact broadcasted seed or zero tillag e fields require frequent 2 3 day intervals light irrigations 25mm to effect establishment a light irrigation is essential 4 7 days after 8 the first irrigation in soils that are prone to crusting to assist with emergence 5 ensure crown root devel opment and tillering at 3 4 leaf stage 14 17 days after the first germination irrigation crown roots and the ear begin to develop and tillers start growing water deficit adversely affect these processes yet they play an important role in yield for mation at this stage usually the top 100 150mm of the soil is dry and crown roots will not grow into dry soil it is necessary to apply a light irrigation to stimulate crown roots and tillering it is also an appropriate time to top dress the wheat wit h nitrogen fertilizer 6 initiate an irrigation schedule early and monitor the soil and crop through to maturity scheduling assist the manager to monitor crop progress and thereby ensure the best treatment possible is given to the crop assess soil and crop conditions before and after each irrigation cycle to evaluate whether or not the irrigation is recharging the soil profile to the satisfaction of the plant needs a soil auger is extremely useful in this regard an auger test ahead of the line will show h ow deep the plant is drawing water while an auger test two positions behind the line will show how effective the irrigation application is in replenishing the soil well irrigated wheat has a dark green colour soft large leaves and many tillers whilst s tressedwheat has a bluish colour hard spikey leaves which may also roll up in some varieties and a few tillers with small ears 7 crop maintenance weed disease and pest control are important in achieving a good crop 8 timing of the last irrigation ther e is no point in irrigating a yellowing crop and grains are fully formed and after hard dough stage full maturity is reached when the peduncle neck area below the earspike turns yellow irrigation applied during later grain fill or during grain dry do wn is of no value to the crop and may even reduce the quality of the grain water after ripening may cause pre harvesting sprouting germination in the ear leading to down grading of wheat due to reduced grain quality 9 keeping irrigation records it helps to plan future irrigation practices useful records include a water usage with a flow meter b energy use either electricity units or diesel litres c dates and amounts of irrigation applied 9 d evaporation and air temperature e labour centre pivot irrigation scheduling a general guide generally center pivot irrigation is the simplest method of irrigating any crop for efficiency there are factors to consider when using center pivots it is proven that a farmer gets more effective water application on a fixed center pivot as compared to a towable pivot this is largely due to the fact that there is run down time loss due to towing from one center to the other it is advisable that when using a fixed center pivot anything between a 10mm and 12 mm spray package is recommended however if it is a towable center pivot and a farmer intends to do two circles with one pivot a bigger spray package is more ideal for the pivot and this can be from 14 mm to 20 mm spray package depending on specific requirements a bigger spray package is recommended for towable center pivots to reduce the turnaround time of the center pivot to avoid moisture stress in the other circle for easy water application a farmer is advised to run their pivot in wet mode the wet mode allows the operator to program the pivot to apply the exact amount of mm required at the particular stage of growth of the crop in instances where the pivot is run in dry mode the operator will be required to calculate the percentage on the timer which corresponds with the amount of water mm that need to be applied and in most cases errors on calculation are sometimes common and a farmer will not achieve the intended spray volumes it is advisable then that farmers should ask their centre pivot service provider to program the machine to work in the wet mode chemigationfertigation calibrations guide calibration factors that need to be considered when using a centre pivot for chemigation and fertigation include the sizing of the dosing pump and its pumping rate a lways ensure you discuss with your pumps specialist before purchasing a dosing pump for correct dosing pump sizing for your applications as applications vary from case to case it is also important that your fertigation or chemigation unit is as close as p ossible to the centre pivot inlet as possible 10 generally not more than six metres below are critical factors to be considered when using a pivot for both chemigation and fertigation 1 length of the pivot to the edge of the effective wetted area 2 length of the pivot to the last tower 3 last tower travel distance in a given amount of time running at present application this point has to be verified physically by the farmer with the pivot running in wet mode at the present application rate do not rely on liter ature or your pivot control panel as other factors such as terrain eg slopegradient can affect your last tower run speed so this must to be verified 4 targeted product application rate in kgslitres per hectare 5 product concentration in kgslitres per m3 of active ingredient 6 percentage of a full circle centre pivot that will be used during the application harvesting on a large scale wheat is usually harvested by combine but it is possible to hand harvest and thresh small areas of wheat combine harve sters must be set carefully and operated according to service manuals in order to keep harvest losses to a minimum\n",
      "\n",
      "Source: ./cleaned_txt/Wheat-Growers-Guide_cleaned.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# query=\"wheat is good in which soil?\"\n",
    "query=\"what pests can attack wheat?\"\n",
    "\n",
    "query_vector_store(\"chroma_db_huggingface\", query, huggingface_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T18:56:52.257097Z",
     "iopub.status.busy": "2024-10-14T18:56:52.256628Z",
     "iopub.status.idle": "2024-10-14T18:56:52.270926Z",
     "shell.execute_reply": "2024-10-14T18:56:52.269845Z",
     "shell.execute_reply.started": "2024-10-14T18:56:52.257055Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books directory: ./cleaned_txt\n",
      "Persistent directory: ./db/chroma_db_with_metadata\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Define the directory containing the text files and the persistent directory\n",
    "\n",
    "books_dir = './cleaned_txt'\n",
    "db_dir = os.path.join('./', \"db\")\n",
    "persistent_directory = os.path.join(db_dir, \"chroma_db_with_metadata\")\n",
    "\n",
    "print(f\"Books directory: {books_dir}\")\n",
    "print(f\"Persistent directory: {persistent_directory}\")\n",
    "\n",
    "def create_vector_database(embeddings,persistent_directory):\n",
    "    # Check if the Chroma vector store already exists\n",
    "    if not os.path.exists(persistent_directory):\n",
    "        print(\"Persistent directory does not exist. Initializing vector store...\")\n",
    "\n",
    "        # Ensure the books directory exists\n",
    "        if not os.path.exists(books_dir):\n",
    "            raise FileNotFoundError(\n",
    "                f\"The directory {books_dir} does not exist. Please check the path.\"\n",
    "            )\n",
    "\n",
    "        # List all text files in the directory\n",
    "        book_files = [f for f in os.listdir(books_dir) if f.endswith(\".txt\")]\n",
    "\n",
    "        # Read the text content from each file and store it with metadata\n",
    "        documents = []\n",
    "        for book_file in book_files:\n",
    "            file_path = os.path.join(books_dir, book_file)\n",
    "            loader = TextLoader(file_path)\n",
    "            book_docs = loader.load()\n",
    "            for doc in book_docs:\n",
    "                # Add metadata to each document indicating its source\n",
    "                doc.metadata = {\"source\": book_file}\n",
    "                documents.append(doc)\n",
    "\n",
    "        # Split the documents into chunks\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "\n",
    "        # Display information about the split documents\n",
    "        print(\"\\n--- Document Chunks Information ---\")\n",
    "        print(f\"Number of document chunks: {len(docs)}\")\n",
    "\n",
    "        # Create embeddings\n",
    "        print(\"\\n--- Creating embeddings ---\")\n",
    "        # Update to a valid embedding model if needed\n",
    "        print(\"\\n--- Finished creating embeddings ---\")\n",
    "\n",
    "        # Create the vector store and persist it\n",
    "        print(\"\\n--- Creating and persisting vector store ---\")\n",
    "        db = Chroma.from_documents(\n",
    "            docs, embeddings, persist_directory=persistent_directory)\n",
    "        print(\"\\n--- Finished creating and persisting vector store ---\")\n",
    "\n",
    "    else:\n",
    "        print(\"Vector store already exists. No need to initialize.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the object to a file\n",
    "import pickle\n",
    "with open('huggingface_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(huggingface_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T18:58:05.324023Z",
     "iopub.status.busy": "2024-10-14T18:58:05.323614Z",
     "iopub.status.idle": "2024-10-14T18:58:08.304425Z",
     "shell.execute_reply": "2024-10-14T18:58:08.303495Z",
     "shell.execute_reply.started": "2024-10-14T18:58:05.323984Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store already exists. No need to initialize.\n"
     ]
    }
   ],
   "source": [
    "huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n",
    "create_vector_database(huggingface_embeddings,persistent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T17:54:03.481185Z",
     "iopub.status.busy": "2024-10-14T17:54:03.480499Z",
     "iopub.status.idle": "2024-10-14T17:55:29.021916Z",
     "shell.execute_reply": "2024-10-14T17:55:29.020838Z",
     "shell.execute_reply.started": "2024-10-14T17:54:03.481141Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start chatting with the AI! Type 'exit' to end the conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hello!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hello!\n",
      "\n",
      "Bye....\n"
     ]
    }
   ],
   "source": [
    "# Define the persistent directory\n",
    "# current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "# persistent_directory = os.path.join(current_dir, \"db\", \"chroma_db_with_metadata\")\n",
    "persistent_directory = \"./db/chroma_db_huggingface\"\n",
    "\n",
    "# Define the embedding model\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n",
    "# Load the existing vector store with the embedding function\n",
    "db = Chroma(persist_directory=persistent_directory, embedding_function=huggingface_embeddings)\n",
    "\n",
    "# Create a retriever for querying the vector store\n",
    "# `search_type` specifies the type of search (e.g., similarity)\n",
    "# `search_kwargs` contains additional arguments for the search (e.g., number of results to return)\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "\n",
    "# Create a google model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# Contextualize question prompt\n",
    "# This system prompt helps the AI understand that it should reformulate the question\n",
    "# based on the chat history to make it a standalone question\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, just \"\n",
    "    \"reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for contextualizing questions\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a history-aware retriever\n",
    "# This uses the LLM to help reformulate the question based on chat history\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "# Answer question prompt\n",
    "# This system prompt helps the AI understand that it should provide concise answers\n",
    "# based on the retrieved context and indicates what to do if the answer is unknown\n",
    "qa_system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. Use \"\n",
    "    \"the following pieces of retrieved context to answer the \"\n",
    "    \"question. If you don't know the answer, just say that you \"\n",
    "    \"don't know. Use optimal number of sentences to answer the question. \"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for answering questions\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a chain to combine documents for question answering\n",
    "# `create_stuff_documents_chain` feeds all retrieved context into the LLM\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "# Create a retrieval chain that combines the history-aware retriever and the question answering chain\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "\n",
    "# Function to simulate a continual chat\n",
    "def continual_chat():\n",
    "    print(\"Start chatting with the AI! Type 'exit' to end the conversation.\")\n",
    "    chat_history = []  # Collect chat history here (a sequence of messages)\n",
    "    while True:\n",
    "        query = input(\"You: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Bye....\")\n",
    "            break\n",
    "        # Process the user's query through the retrieval chain\n",
    "        result = rag_chain.invoke({\"input\": query, \"chat_history\": chat_history})\n",
    "        # Display the AI's response\n",
    "        print(f\"AI: {result['answer']}\")\n",
    "        # Update the chat history\n",
    "#         chat_history.append(HumanMessage(content=query))\n",
    "#         chat_history.append(SystemMessage(content=result[\"answer\"]))\n",
    "        chat_history.append(HumanMessage(content=query))\n",
    "        chat_history.append(AIMessage(content=result[\"answer\"]))\n",
    "#         print(chat_history)\n",
    "\n",
    "\n",
    "# Main function to start the continual chat\n",
    "if __name__ == \"__main__\":\n",
    "    continual_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T19:00:44.981612Z",
     "iopub.status.busy": "2024-10-14T19:00:44.980861Z",
     "iopub.status.idle": "2024-10-14T19:11:08.206980Z",
     "shell.execute_reply": "2024-10-14T19:11:08.205850Z",
     "shell.execute_reply.started": "2024-10-14T19:00:44.981562Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start chatting with the AI! Type 'exit' to end the conversation.\n",
      "Bye....\n"
     ]
    }
   ],
   "source": [
    "# Define the persistent directory\n",
    "# current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "# persistent_directory = os.path.join(current_dir, \"db\", \"chroma_db_with_metadata\")\n",
    "persistent_directory = \".db/chroma_db_with_metadata\"\n",
    "\n",
    "# Define the embedding model\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n",
    "# Load the existing vector store with the embedding function\n",
    "db = Chroma(persist_directory=persistent_directory, embedding_function=huggingface_embeddings)\n",
    "\n",
    "# Create a retriever for querying the vector store\n",
    "# `search_type` specifies the type of search (e.g., similarity)\n",
    "# `search_kwargs` contains additional arguments for the search (e.g., number of results to return)\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "\n",
    "# Create a google model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# Contextualize question prompt\n",
    "# This system prompt helps the AI understand that it should reformulate the question\n",
    "# based on the chat history to make it a standalone question\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, just \"\n",
    "    \"reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for contextualizing questions\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a history-aware retriever\n",
    "# This uses the LLM to help reformulate the question based on chat history\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "# Answer question prompt\n",
    "# This system prompt helps the AI understand that it should provide concise answers\n",
    "# based on the retrieved context and indicates what to do if the answer is unknown\n",
    "qa_system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. Use \"\n",
    "    \"the following pieces of retrieved context to answer the \"\n",
    "    \"question. If you don't know the answer, just say that you \"\n",
    "    \"don't know. Use optimal number of sentences to answer the question. \"\n",
    "    \"Provide the source as well. \"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for answering questions\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a chain to combine documents for question answering\n",
    "# `create_stuff_documents_chain` feeds all retrieved context into the LLM\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "# Create a retrieval chain that combines the history-aware retriever and the question answering chain\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "\n",
    "# Function to simulate a continual chat\n",
    "def continual_chat():\n",
    "    print(\"Start chatting with the AI! Type 'exit' to end the conversation.\")\n",
    "    chat_history = []  # Collect chat history here (a sequence of messages)\n",
    "    while True:\n",
    "        query = input(\"You: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Bye....\")\n",
    "            break\n",
    "        # Process the user's query through the retrieval chain\n",
    "        result = rag_chain.invoke({\"input\": query, \"chat_history\": chat_history})\n",
    "        # Display the AI's response\n",
    "        print(f\"AI: {result['answer']}\")\n",
    "        # Update the chat history\n",
    "#         chat_history.append(HumanMessage(content=query))\n",
    "#         chat_history.append(SystemMessage(content=result[\"answer\"]))\n",
    "        chat_history.append(HumanMessage(content=query))\n",
    "        chat_history.append(AIMessage(content=result[\"answer\"]))\n",
    "#         print(chat_history)\n",
    "\n",
    "\n",
    "# Main function to start the continual chat\n",
    "if __name__ == \"__main__\":\n",
    "    continual_chat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Generate translations using the model\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 47\u001b[0m     generated_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Decode the generated tokens into text\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mas_target_tokenizer():\n",
      "File \u001b[0;32m~/miniconda3/envs/langchainenv/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchainenv/lib/python3.11/site-packages/transformers/generation/utils.py:2078\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2070\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2071\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2072\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2073\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2074\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2075\u001b[0m     )\n\u001b[1;32m   2077\u001b[0m     \u001b[38;5;66;03m# 13. run beam sample\u001b[39;00m\n\u001b[0;32m-> 2078\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2079\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2080\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2081\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2082\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2083\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2084\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2085\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2086\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2088\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[1;32m   2089\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2090\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2091\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2092\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2098\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2099\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/langchainenv/lib/python3.11/site-packages/transformers/generation/utils.py:3253\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3250\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m stack_model_outputs(outputs_per_sub_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget_text_config())\n\u001b[1;32m   3252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Unchanged original behavior\u001b[39;00m\n\u001b[0;32m-> 3253\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   3256\u001b[0m     cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchainenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchainenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/ai4bharat/indictrans2-indic-en-1B/66c8dda9f635b4aa632efba688496e6839364dfd/modeling_indictrans.py:1716\u001b[0m, in \u001b[0;36mIndicTransForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1711\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1712\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[1;32m   1713\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m   1714\u001b[0m         )\n\u001b[0;32m-> 1716\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1717\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1732\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1733\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   1735\u001b[0m masked_lm_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchainenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchainenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/ai4bharat/indictrans2-indic-en-1B/66c8dda9f635b4aa632efba688496e6839364dfd/modeling_indictrans.py:1613\u001b[0m, in \u001b[0;36mIndicTransModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1606\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1607\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1608\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1609\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1610\u001b[0m     )\n\u001b[1;32m   1612\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1613\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/langchainenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchainenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/ai4bharat/indictrans2-indic-en-1B/66c8dda9f635b4aa632efba688496e6839364dfd/modeling_indictrans.py:1483\u001b[0m, in \u001b[0;36mIndicTransDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m   1471\u001b[0m             create_custom_forward(decoder_layer),\n\u001b[1;32m   1472\u001b[0m             hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1480\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1481\u001b[0m         )\n\u001b[1;32m   1482\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1483\u001b[0m         layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m                \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1490\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1494\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1495\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1501\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m skip_the_layer:\n",
      "File \u001b[0;32m~/miniconda3/envs/langchainenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchainenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/ai4bharat/indictrans2-indic-en-1B/66c8dda9f635b4aa632efba688496e6839364dfd/modeling_indictrans.py:902\u001b[0m, in \u001b[0;36mIndicTransDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;66;03m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001b[39;00m\n\u001b[1;32m    895\u001b[0m cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    896\u001b[0m     past_key_value[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    897\u001b[0m )\n\u001b[1;32m    898\u001b[0m (\n\u001b[1;32m    899\u001b[0m     hidden_states,\n\u001b[1;32m    900\u001b[0m     cross_attn_weights,\n\u001b[1;32m    901\u001b[0m     cross_attn_present_key_value,\n\u001b[0;32m--> 902\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    910\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(\n\u001b[1;32m    911\u001b[0m     hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining\n\u001b[1;32m    912\u001b[0m )\n\u001b[1;32m    913\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/langchainenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchainenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/ai4bharat/indictrans2-indic-en-1B/66c8dda9f635b4aa632efba688496e6839364dfd/modeling_indictrans.py:326\u001b[0m, in \u001b[0;36mIndicTransAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    323\u001b[0m value_states \u001b[38;5;241m=\u001b[39m value_states\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39mproj_shape)\n\u001b[1;32m    325\u001b[0m src_len \u001b[38;5;241m=\u001b[39m key_states\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 326\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attn_weights\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m (bsz \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, tgt_len, src_len):\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttention weights should be of size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(bsz\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\u001b[38;5;250m \u001b[39mtgt_len,\u001b[38;5;250m \u001b[39msrc_len)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattn_weights\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    332\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from IndicTransToolkit import IndicProcessor\n",
    "\n",
    "# Define model and tokenizer for Indic to English translation\n",
    "model_name = \"ai4bharat/indictrans2-indic-en-1B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "# Initialize the IndicProcessor for preprocessing and postprocessing\n",
    "ip = IndicProcessor(inference=True)\n",
    "\n",
    "# Example input sentences in Punjabi (Gurmukhi script)\n",
    "input_sentences = [\n",
    "    \"ਤੁਸੀਂ ਕਿਵੇਂ ਹੋ?\",  # How are you?\n",
    "    \"ਅਸੀਂ ਕੱਲ੍ਹ ਇੱਕ ਨਵੀਂ ਫਿਲਮ ਦੇਖੀ।\",  # We watched a new movie yesterday.\n",
    "    \"ਮੇਰੇ ਦੋਸਤ ਨੇ ਮੈਨੂੰ ਉਸਦੇ ਜਨਮਦਿਨ 'ਤੇ ਸੱਦਿਆ ਹੈ।\",  # My friend has invited me to his birthday.\n",
    "    \"ਮੈਂ ਹਰ ਰੋਜ਼ ਪਾਰਕ ਜਾਣਦਾ ਹਾਂ।\",  # I go to the park every day.\n",
    "]\n",
    "\n",
    "# Define source and target languages\n",
    "src_lang, tgt_lang = \"pan_Guru\", \"eng_Latn\"\n",
    "\n",
    "# Preprocess the input sentences\n",
    "batch = ip.preprocess_batch(\n",
    "    input_sentences,\n",
    "    src_lang=src_lang,\n",
    "    tgt_lang=tgt_lang,\n",
    ")\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Tokenize the sentences and generate input encodings\n",
    "inputs = tokenizer(\n",
    "    batch,\n",
    "    truncation=True,\n",
    "    padding=\"longest\",\n",
    "    return_tensors=\"pt\",\n",
    "    return_attention_mask=True,\n",
    ").to(DEVICE)\n",
    "\n",
    "# Generate translations using the model\n",
    "with torch.no_grad():\n",
    "    generated_tokens = model.generate(\n",
    "        **inputs,\n",
    "        use_cache=True,\n",
    "        min_length=0,\n",
    "        max_length=256,\n",
    "        num_beams=5,\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "\n",
    "# Decode the generated tokens into text\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    generated_tokens = tokenizer.batch_decode(\n",
    "        generated_tokens.detach().cpu().tolist(),\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=True,\n",
    "    )\n",
    "\n",
    "# Postprocess the translations\n",
    "translations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "# Print the input sentences and their translations\n",
    "for input_sentence, translation in zip(input_sentences, translations):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('indictrans2-indic-en-1B-saved/tokenizer_config.json',\n",
       " 'indictrans2-indic-en-1B-saved/special_tokens_map.json',\n",
       " 'indictrans2-indic-en-1B-saved/dict.SRC.json',\n",
       " 'indictrans2-indic-en-1B-saved/dict.TGT.json',\n",
       " 'indictrans2-indic-en-1B-saved/model.SRC',\n",
       " 'indictrans2-indic-en-1B-saved/model.TGT',\n",
       " 'indictrans2-indic-en-1B-saved/added_tokens.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and tokenizer to a directory\n",
    "model.save_pretrained(\"indictrans2-indic-en-1B-saved\")\n",
    "tokenizer.save_pretrained(\"indictrans2-indic-en-1B-saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from IndicTransToolkit import IndicProcessor\n",
    "\n",
    "def translate_punjabi_to_english(punjabi_sentences):\n",
    "    \"\"\"Translates Punjabi sentences to English using the IndicTransToolkit and a pre-trained transformer model.\n",
    "\n",
    "    Args:\n",
    "        punjabi_sentences (list): A list of Punjabi sentences to be translated.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of corresponding English translations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the pre-trained model and tokenizer\n",
    "    model_name = \"ai4bharat/indictrans2-indic-en-1B\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "    # Initialize the IndicProcessor\n",
    "    ip = IndicProcessor(inference=True)\n",
    "\n",
    "    # Define source and target languages\n",
    "    src_lang, tgt_lang = \"pan_Guru\", \"eng_Latn\"\n",
    "\n",
    "    # Preprocess the input sentences\n",
    "    batch = ip.preprocess_batch(\n",
    "        punjabi_sentences,\n",
    "        src_lang=src_lang,\n",
    "        tgt_lang=tgt_lang,\n",
    "    )\n",
    "\n",
    "    # Set the device (GPU or CPU)\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Tokenize the sentences and generate input encodings\n",
    "    inputs = tokenizer(\n",
    "        batch,\n",
    "        truncation=True,\n",
    "        padding=\"longest\",\n",
    "        return_tensors=\"pt\",\n",
    "        return_attention_mask=True,\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # Generate translations using the model\n",
    "    with torch.no_grad():\n",
    "        generated_tokens = model.generate(\n",
    "            **inputs,\n",
    "            use_cache=True,\n",
    "            min_length=0,\n",
    "            max_length=256,\n",
    "            num_beams=5,\n",
    "            num_return_sequences=1,\n",
    "        )\n",
    "\n",
    "    # Decode the generated tokens into text\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        generated_tokens = tokenizer.batch_decode(\n",
    "            generated_tokens.detach().cpu().tolist(),\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True,\n",
    "        )\n",
    "\n",
    "    # Postprocess the translations\n",
    "    translations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punjabi_sentences = [\n",
    "    \"ਤੁਸੀਂ ਕਿਵੇਂ ਹੋ?\",  # How are you?\n",
    "    \"ਕਣਕ ਦੀ ਵਰਤੋਂ ਕੀ ਹੈ?\",  # We watched a new movie yesterday.\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:4109: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "english_translations = translate_punjabi_to_english(punjabi_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the use of wheat?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_translations[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## punjabi chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start chatting with the AI! Type 'exit' to end the conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:4109: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the use of wheat?\n",
      "AI: Wheat is a staple food for many people around the world. It is used to make bread, pasta, noodles, and other food products. It is also used as an ingredient in animal feed. Source: [Wikipedia](https://en.wikipedia.org/wiki/Wheat) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:4109: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is food?\n",
      "AI: Food is any substance consumed to provide nutritional support for the body. It is essential for growth, metabolism, and maintaining life. Food provides the body with energy, nutrients, and building blocks for growth and repair. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:4109: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is a pesticide?\n",
      "AI: A pesticide is a substance used to kill, repel, or control any pest. Pests can include insects, weeds, fungi, bacteria, viruses, nematodes, rodents, and other organisms that can cause harm to crops, livestock, or humans. Pesticides are widely used in agriculture, forestry, and public health to protect crops, control disease vectors, and prevent infestations. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:4109: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are farmers getting better prices for their produce?\n",
      "AI: I do not have access to real-time information, including current market prices for produce.  Therefore, I cannot answer whether farmers are getting better prices for their produce. \n",
      "\n",
      "To get the most up-to-date information, I recommend checking resources such as:\n",
      "\n",
      "* **Agricultural news websites:** These websites often report on current market trends and prices.\n",
      "* **Government agricultural agencies:** Agencies like the USDA in the US provide market data and reports.\n",
      "* **Local farmer's markets:** Talking to farmers directly can give you insight into their current experiences.\n",
      "\n",
      "Remember, market prices for produce are constantly fluctuating based on factors like supply, demand, weather conditions, and global events. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:4109: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What kind of problems do farmers face?\n",
      "AI: Farmers face a multitude of challenges, some of which are:\n",
      "\n",
      "* **Weather:** Extreme weather events like droughts, floods, and storms can severely impact crops and livestock.\n",
      "* **Market Fluctuations:** Prices for agricultural commodities can be volatile, making it difficult to plan and budget.\n",
      "* **Pests and Diseases:** Pests and diseases can damage crops and livestock, leading to reduced yields and financial losses.\n",
      "* **Input Costs:** Costs for things like seeds, fertilizer, and fuel are constantly rising, squeezing profit margins.\n",
      "* **Labor Shortages:** Finding and retaining qualified workers is becoming increasingly difficult, especially in rural areas.\n",
      "* **Climate Change:** Changing weather patterns and extreme weather events are posing new challenges for farmers.\n",
      "* **Government Regulations:** Complying with regulations can be complex and costly, adding to the challenges of farming.\n",
      "* **Competition:** Competition from large-scale agricultural operations can make it difficult for small farmers to compete.\n",
      "* **Access to Markets:** Farmers may struggle to find markets for their produce, especially if they are located in remote areas.\n",
      "* **Debt:** Many farmers carry significant debt, making them vulnerable to economic downturns.\n",
      "\n",
      "These are just some of the many challenges that farmers face. It's important to remember that farming is a complex and challenging profession that requires resilience, adaptability, and a deep understanding of agriculture. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:4109: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What kind of problems do farmers face?\n",
      "AI: Farmers face a wide range of challenges, some of which are:\n",
      "\n",
      "* **Weather:** Extreme weather events like droughts, floods, and storms can severely impact crops and livestock.\n",
      "* **Market Fluctuations:** Prices for agricultural commodities can be volatile, making it difficult to plan and budget.\n",
      "* **Pests and Diseases:** Pests and diseases can damage crops and livestock, leading to reduced yields and financial losses.\n",
      "* **Input Costs:** Costs for things like seeds, fertilizer, and fuel are constantly rising, squeezing profit margins.\n",
      "* **Labor Shortages:** Finding and retaining qualified workers is becoming increasingly difficult, especially in rural areas.\n",
      "* **Climate Change:** Changing weather patterns and extreme weather events are posing new challenges for farmers.\n",
      "* **Government Regulations:** Complying with regulations can be complex and costly, adding to the challenges of farming.\n",
      "* **Competition:** Competition from large-scale agricultural operations can make it difficult for small farmers to compete.\n",
      "* **Access to Markets:** Farmers may struggle to find markets for their produce, especially if they are located in remote areas.\n",
      "* **Debt:** Many farmers carry significant debt, making them vulnerable to economic downturns.\n",
      "\n",
      "These are just some of the many challenges that farmers face. It's important to remember that farming is a complex and challenging profession that requires resilience, adaptability, and a deep understanding of agriculture. \n",
      "\n",
      "Bye....\n"
     ]
    }
   ],
   "source": [
    "# Function to simulate a continual chat punjabi\n",
    "def continual_chat():\n",
    "    print(\"Start chatting with the AI! Type 'exit' to end the conversation.\")\n",
    "    chat_history = []  # Collect chat history here (a sequence of messages)\n",
    "    punjabi_sentences=[\"ਤੁਸੀਂ ਕਿਵੇਂ ਹੋ?\"]\n",
    "    while True:\n",
    "        query = input(\"You: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Bye....\")\n",
    "            break\n",
    "        punjabi_sentences.append(query)\n",
    "        english_translations = translate_punjabi_to_english(punjabi_sentences)\n",
    "        new_query=english_translations[-1]\n",
    "        print(new_query)\n",
    "\n",
    "        # Process the user's query through the retrieval chain\n",
    "        result = rag_chain.invoke({\"input\": new_query, \"chat_history\": chat_history})\n",
    "        # Display the AI's response\n",
    "        print(f\"AI: {result['answer']}\")\n",
    "        # Update the chat history\n",
    "#         chat_history.append(HumanMessage(content=query))\n",
    "#         chat_history.append(SystemMessage(content=result[\"answer\"]))\n",
    "        chat_history.append(HumanMessage(content=query))\n",
    "        chat_history.append(AIMessage(content=result[\"answer\"]))\n",
    "#         print(chat_history)\n",
    "\n",
    "\n",
    "# Main function to start the continual chat\n",
    "if __name__ == \"__main__\":\n",
    "    continual_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from IndicTransToolkit import IndicProcessor\n",
    "\n",
    "def translate_punjabi_to_english(punjabi_sentences):\n",
    "    \"\"\"Translates Punjabi sentences to English using the IndicTransToolkit and a pre-trained transformer model.\n",
    "\n",
    "    Args:\n",
    "        punjabi_sentences (list): A list of Punjabi sentences to be translated.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of corresponding English translations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the pre-trained model and tokenizer\n",
    "    model_name = \"ai4bharat/indictrans2-indic-en-1B\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "    # Initialize the IndicProcessor\n",
    "    ip = IndicProcessor(inference=True)\n",
    "\n",
    "    # Define source and target languages\n",
    "    src_lang, tgt_lang = \"pan_Guru\", \"eng_Latn\"\n",
    "\n",
    "    # Preprocess the input sentences\n",
    "    batch = ip.preprocess_batch(\n",
    "        punjabi_sentences,\n",
    "        src_lang=src_lang,\n",
    "        tgt_lang=tgt_lang,\n",
    "    )\n",
    "\n",
    "    # Set the device (GPU or CPU)\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Tokenize the sentences and generate input encodings\n",
    "    inputs = tokenizer(\n",
    "        batch,\n",
    "        truncation=True,\n",
    "        padding=\"longest\",\n",
    "        return_tensors=\"pt\",\n",
    "        return_attention_mask=True,\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # Generate translations using the model\n",
    "    with torch.no_grad():\n",
    "        generated_tokens = model.generate(\n",
    "            **inputs,\n",
    "            use_cache=True,\n",
    "            min_length=0,\n",
    "            max_length=256,\n",
    "            num_beams=5,\n",
    "            num_return_sequences=1,\n",
    "        )\n",
    "\n",
    "    # Decode the generated tokens into text\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        generated_tokens = tokenizer.batch_decode(\n",
    "            generated_tokens.detach().cpu().tolist(),\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True,\n",
    "        )\n",
    "\n",
    "    # Postprocess the translations\n",
    "    translations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from IndicTransToolkit import IndicProcessor\n",
    "\n",
    "def translate_english_to_punjabi(english_sentences):\n",
    "    \"\"\"Translates English sentences to Punjabi using the provided model and tokenizer.\n",
    "\n",
    "    Args:\n",
    "        english_sentences (list): A list of English sentences to be translated.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of corresponding Punjabi translations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the pre-trained model and tokenizer\n",
    "    model_name = \"ai4bharat/indictrans2-en-indic-1B\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "    # Initialize the IndicProcessor\n",
    "    ip = IndicProcessor(inference=True)\n",
    "\n",
    "    # Define source and target languages\n",
    "    src_lang, tgt_lang = \"eng_Latn\", \"pan_Guru\"\n",
    "\n",
    "    # Preprocess the input sentences\n",
    "    batch = ip.preprocess_batch(\n",
    "        english_sentences,\n",
    "        src_lang=src_lang,\n",
    "        tgt_lang=tgt_lang,\n",
    "    )\n",
    "\n",
    "    # Set the device (GPU or CPU)\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Tokenize the sentences and generate input encodings\n",
    "    inputs = tokenizer(\n",
    "        batch,\n",
    "        truncation=True,\n",
    "        padding=\"longest\",\n",
    "        return_tensors=\"pt\",\n",
    "        return_attention_mask=True,\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # Generate translations using the model\n",
    "    with torch.no_grad():\n",
    "        generated_tokens = model.generate(\n",
    "            **inputs,\n",
    "            use_cache=True,\n",
    "            min_length=0,\n",
    "            max_length=256,\n",
    "            num_beams=5,\n",
    "            num_return_sequences=1,\n",
    "        )\n",
    "\n",
    "    # Decode the generated tokens into text\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        generated_tokens = tokenizer.batch_decode(\n",
    "            generated_tokens.detach().cpu().tolist(),\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True,\n",
    "        )\n",
    "\n",
    "    # Postprocess the translations, including entity replacement\n",
    "    translations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "    return translations\n",
    "\n",
    "# Example usage\n",
    "english_sentences = [\n",
    "    \"I love eating pizza.\",\n",
    "    \"The weather is beautiful today.\",\n",
    "    \"Let's go for a walk in the park.\"\n",
    "]\n",
    "\n",
    "punjabi_translations = translate_english_to_punjabi(english_sentences)\n",
    "\n",
    "# for english_sentence, punjabi_translation in zip(english_sentences, punjabi_translations):\n",
    "#     print(f\"English: {english_sentence}\")\n",
    "#     print(f\"Punjabi: {punjabi_translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('indictrans2-en-indic-1B-saved/tokenizer_config.json',\n",
       " 'indictrans2-en-indic-1B-saved/special_tokens_map.json',\n",
       " 'indictrans2-en-indic-1B-saved/dict.SRC.json',\n",
       " 'indictrans2-en-indic-1B-saved/dict.TGT.json',\n",
       " 'indictrans2-en-indic-1B-saved/model.SRC',\n",
       " 'indictrans2-en-indic-1B-saved/model.TGT',\n",
       " 'indictrans2-en-indic-1B-saved/added_tokens.json')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and tokenizer to a directory\n",
    "model_name = \"indictrans2-en-indic-1B-saved\"\n",
    "model.save_pretrained(model_name)\n",
    "tokenizer.save_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ਮੈਨੂੰ ਪਿੱਜ਼ਾ ਖਾਣਾ ਬਹੁਤ ਪਸੰਦ ਹੈ। ',\n",
       " 'ਅੱਜ ਮੌਸਮ ਸੁੰਦਰ ਹੈ। ',\n",
       " 'ਆਓ ਪਾਰਕ ਵਿੱਚ ਸੈਰ ਕਰਨ ਲਈ ਚੱਲੀਏ। ']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punjabi_translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## punjabi to punjabi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start chatting with the AI! Type 'exit' to end the conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:4109: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What kind of problems do farmers face?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:4109: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: ਕਿਸਾਨਾਂ ਨੂੰ ਕਈ ਤਰ੍ਹਾਂ ਦੀਆਂ ਚੁਣੌਤੀਆਂ ਦਾ ਸਾਹਮਣਾ ਕਰਨਾ ਪੈਂਦਾ ਹੈ, ਜਿਸ ਵਿੱਚ ਸ਼ਾਮਲ ਹਨਃ * * * ਮੌਸਮਃ * ਸੋਕਾ, ਹਡ਼੍ਹ ਅਤੇ ਗਰਮੀ ਵਰਗੀਆਂ ਮੌਸਮ ਦੀਆਂ ਘਟਨਾਵਾਂ ਫਸਲਾਂ ਦੀ ਪੈਦਾਵਾਰ ਅਤੇ ਪਸ਼ੂਆਂ ਦੀ ਸਿਹਤ ਨੂੰ ਮਹੱਤਵਪੂਰਨ ਤੌਰ'ਤੇ ਪ੍ਰਭਾਵਤ ਕਰ ਸਕਦੀਆਂ ਹਨ। * * ਬਾਜ਼ਾਰ ਦੀ ਅਸਥਿਰਤਾਃ * * ਵਸਤਾਂ ਦੀਆਂ ਕੀਮਤਾਂ ਵਿੱਚ ਉਤਰਾਅ-ਚਡ਼੍ਹਾਅ ਕਿਸਾਨਾਂ ਲਈ ਯੋਜਨਾਬੰਦੀ ਅਤੇ ਮੁਨਾਫਾ ਕਮਾਉਣਾ ਮੁਸ਼ਕਲ ਬਣਾ ਸਕਦੇ ਹਨ। * * * ਨਿਵੇਸ਼ ਲਾਗਤਃ * * ਬੀਜਾਂ, ਖਾਦਾਂ ਅਤੇ ਹੋਰ ਨਿਵੇਸ਼ ਦੀ ਲਾਗਤ ਉੱਚੀ ਅਤੇ ਅਣਹੋਣੀ ਹੋ ਸਕਦੀ ਹੈ। * * * ਮਜ਼ਦੂਰਾਂ ਦੀ ਘਾਟਃ * * ਯੋਗ ਮਜ਼ਦੂਰਾਂ ਨੂੰ ਲੱਭਣਾ ਅਤੇ ਬਰਕਰਾਰ ਰੱਖਣਾ ਇੱਕ ਚੁਣੌਤੀ ਹੋ ਸਕਦੀ ਹੈ, ਖ਼ਾਸਕਰ ਪੀਕ ਸੀਜ਼ਨ ਦੌਰਾਨ। * * * ਨਿਯਮ ਅਤੇ ਨੀਤੀਆਂਃ * * ਕਿਸਾਨਾਂ ਨੂੰ ਨਿਯਮਾਂ ਦੇ ਇੱਕ ਗੁੰਝਲਦਾਰ ਜਾਲ ਦੀ ਪਾਲਣਾ ਕਰਨੀ ਚਾਹੀਦੀ ਹੈ, ਜੋ ਮਹਿੰਗੇ ਅਤੇ ਸਮਾਂ ਲੈਣ ਵਾਲੇ ਹੋ ਸਕਦੇ ਹਨ। * * * ਤਕਨਾਲੋਜੀ ਤੱਕ ਪਹੁੰਚਃ * * ਕਿਸਾਨ ਨਵੀਆਂ ਤਕਨੀਕਾਂ ਨੂੰ ਅਪਣਾਉਣ ਲਈ ਸੰਘਰਸ਼ ਕਰ ਸਕਦੇ ਹਨ ਜੋ ਕੁਸ਼ਲਤਾ ਅਤੇ ਜਲਵਾਯੂ ਪਰਿਵਰਤਨ ਵਿੱਚ ਸੁਧਾਰ ਕਰ ਸਕਦੀਆਂ ਹਨ। \n",
      "What schemes is the government implementing for farmers?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 34\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#         print(chat_history)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Main function to start the continual chat\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 34\u001b[0m     \u001b[43mcontinual_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 21\u001b[0m, in \u001b[0;36mcontinual_chat\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Display the AI's response\u001b[39;00m\n\u001b[1;32m     20\u001b[0m english_sentences\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m---> 21\u001b[0m punjabi_translations \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate_english_to_punjabi\u001b[49m\u001b[43m(\u001b[49m\u001b[43menglish_sentences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m punjabi_response\u001b[38;5;241m=\u001b[39mpunjabi_translations[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAI: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpunjabi_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[31], line 47\u001b[0m, in \u001b[0;36mtranslate_english_to_punjabi\u001b[0;34m(english_sentences)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Generate translations using the model\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 47\u001b[0m     generated_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Decode the generated tokens into text\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mas_target_tokenizer():\n",
      "File \u001b[0;32m~/miniconda3/envs/langchainenv/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchainenv/lib/python3.11/site-packages/transformers/generation/utils.py:2078\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2070\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2071\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2072\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2073\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2074\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2075\u001b[0m     )\n\u001b[1;32m   2077\u001b[0m     \u001b[38;5;66;03m# 13. run beam sample\u001b[39;00m\n\u001b[0;32m-> 2078\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2079\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2080\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2081\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2082\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2083\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2084\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2085\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2086\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2088\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[1;32m   2089\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2090\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2091\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2092\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2098\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2099\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/langchainenv/lib/python3.11/site-packages/transformers/generation/utils.py:3344\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3341\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m outputs\n\u001b[1;32m   3343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3344\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_temporary_reorder_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpast_key_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_idx\u001b[49m\n\u001b[1;32m   3346\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_in_generate \u001b[38;5;129;01mand\u001b[39;00m output_scores:\n\u001b[1;32m   3349\u001b[0m     beam_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m((beam_indices[beam_idx[i]] \u001b[38;5;241m+\u001b[39m (beam_idx[i],) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(beam_indices))))\n",
      "File \u001b[0;32m~/miniconda3/envs/langchainenv/lib/python3.11/site-packages/transformers/generation/utils.py:3107\u001b[0m, in \u001b[0;36mGenerationMixin._temporary_reorder_cache\u001b[0;34m(self, past_key_values, beam_idx)\u001b[0m\n\u001b[1;32m   3105\u001b[0m \u001b[38;5;66;03m# Exception 1: code path for models using the legacy cache format\u001b[39;00m\n\u001b[1;32m   3106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(past_key_values, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m-> 3107\u001b[0m     past_key_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reorder_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3108\u001b[0m \u001b[38;5;66;03m# Exception 2: models with different cache formats. These are limited to `DynamicCache` until their\u001b[39;00m\n\u001b[1;32m   3109\u001b[0m \u001b[38;5;66;03m# cache format is standardized, to avoid adding complexity to the codebase.\u001b[39;00m\n\u001b[1;32m   3110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgptbigcode\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_class:\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/ai4bharat/indictrans2-en-indic-1B/bb1e8f494be5855fa00cf845bae310dc4f22a20e/modeling_indictrans.py:1797\u001b[0m, in \u001b[0;36mIndicTransForConditionalGeneration._reorder_cache\u001b[0;34m(past_key_values, beam_idx)\u001b[0m\n\u001b[1;32m   1794\u001b[0m reordered_past \u001b[38;5;241m=\u001b[39m ()\n\u001b[1;32m   1795\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_past \u001b[38;5;129;01min\u001b[39;00m past_key_values:\n\u001b[1;32m   1796\u001b[0m     reordered_past \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1797\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m   1798\u001b[0m             past_state\u001b[38;5;241m.\u001b[39mindex_select(\u001b[38;5;241m0\u001b[39m, beam_idx) \u001b[38;5;28;01mfor\u001b[39;00m past_state \u001b[38;5;129;01min\u001b[39;00m layer_past\n\u001b[1;32m   1799\u001b[0m         ),\n\u001b[1;32m   1800\u001b[0m     )\n\u001b[1;32m   1801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reordered_past\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/ai4bharat/indictrans2-en-indic-1B/bb1e8f494be5855fa00cf845bae310dc4f22a20e/modeling_indictrans.py:1798\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1794\u001b[0m reordered_past \u001b[38;5;241m=\u001b[39m ()\n\u001b[1;32m   1795\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_past \u001b[38;5;129;01min\u001b[39;00m past_key_values:\n\u001b[1;32m   1796\u001b[0m     reordered_past \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1797\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m-> 1798\u001b[0m             \u001b[43mpast_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m past_state \u001b[38;5;129;01min\u001b[39;00m layer_past\n\u001b[1;32m   1799\u001b[0m         ),\n\u001b[1;32m   1800\u001b[0m     )\n\u001b[1;32m   1801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reordered_past\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Function to simulate a continual chat punjabi to punjabi\n",
    "def continual_chat():\n",
    "    print(\"Start chatting with the AI! Type 'exit' to end the conversation.\")\n",
    "    chat_history = []  # Collect chat history here (a sequence of messages)\n",
    "    punjabi_sentences=[\"ਤੁਸੀਂ ਕਿਵੇਂ ਹੋ?\"]\n",
    "    english_sentences=[\"How are you?\"]\n",
    "    while True:\n",
    "        query = input(\"You: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Bye....\")\n",
    "            break\n",
    "        punjabi_sentences.append(query)\n",
    "        english_translations = translate_punjabi_to_english(punjabi_sentences)\n",
    "        new_query=english_translations[-1]\n",
    "        print(new_query)\n",
    "\n",
    "        # Process the user's query through the retrieval chain\n",
    "        result = rag_chain.invoke({\"input\": new_query, \"chat_history\": chat_history})\n",
    "        # Display the AI's response\n",
    "        print(\"AI: for english\", result[\"response\"])\n",
    "        english_sentences.append(str(result['answer']))\n",
    "        punjabi_translations = translate_english_to_punjabi(english_sentences)\n",
    "        punjabi_response=punjabi_translations[-1]\n",
    "        print(f\"AI: {punjabi_response}\")\n",
    "        # Update the chat history\n",
    "#         chat_history.append(HumanMessage(content=query))\n",
    "#         chat_history.append(SystemMessage(content=result[\"answer\"]))\n",
    "        chat_history.append(HumanMessage(content=query))\n",
    "        chat_history.append(AIMessage(content=result[\"answer\"]))\n",
    "#         print(chat_history)\n",
    "\n",
    "\n",
    "# Main function to start the continual chat\n",
    "if __name__ == \"__main__\":\n",
    "    continual_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1728943335.764612 1960528 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deep-translator\n",
      "  Using cached deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from deep-translator) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from deep-translator) (2.32.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2024.8.30)\n",
      "Using cached deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
      "Installing collected packages: deep-translator\n",
      "Successfully installed deep-translator-1.11.4\n"
     ]
    }
   ],
   "source": [
    "!pip install deep-translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punjabi Translation: ਹੈਲੋ ਤੁਸੀ ਕਿਵੇਂ ਹੋ?\n",
      "English Translation: Farmers face a variety of challenges, including * * * Weather * Weather events such as drought, heat and heat can significantly affect crop yields and livestock health. * * Market Volatility * * Fluctuations in commodity prices can make planning and profitability difficult for farmers. * * * Investment Cost * * The cost of seeds, fertilizers and other inputs can be high and unpredictable. * * * Labor shortage * * Finding and retaining qualified workers can be a challenge, especially during peak seasons. * * * Regulations and Policies * * Farmers must comply with a complex web of regulations, which can be costly and time-consuming. * * * Access to Technology * * Farmers may struggle to adopt new technologies that can improve efficiency and climate change.\n"
     ]
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# Example usage: English to Punjabi\n",
    "english_text = \"Hello, how are you?\"\n",
    "punjabi_translation = GoogleTranslator(source='en', target='pa').translate(english_text)\n",
    "print(\"Punjabi Translation:\", punjabi_translation)\n",
    "\n",
    "# Example usage: Punjabi to English\n",
    "punjabi_text = \"ਕਿਸਾਨਾਂ ਨੂੰ ਕਈ ਤਰ੍ਹਾਂ ਦੀਆਂ ਚੁਣੌਤੀਆਂ ਦਾ ਸਾਹਮਣਾ ਕਰਨਾ ਪੈਂਦਾ ਹੈ, ਜਿਸ ਵਿੱਚ ਸ਼ਾਮਲ ਹਨਃ * * * ਮੌਸਮਃ * ਸੋਕਾ, ਹਡ਼੍ਹ ਅਤੇ ਗਰਮੀ ਵਰਗੀਆਂ ਮੌਸਮ ਦੀਆਂ ਘਟਨਾਵਾਂ ਫਸਲਾਂ ਦੀ ਪੈਦਾਵਾਰ ਅਤੇ ਪਸ਼ੂਆਂ ਦੀ ਸਿਹਤ ਨੂੰ ਮਹੱਤਵਪੂਰਨ ਤੌਰ'ਤੇ ਪ੍ਰਭਾਵਤ ਕਰ ਸਕਦੀਆਂ ਹਨ। * * ਬਾਜ਼ਾਰ ਦੀ ਅਸਥਿਰਤਾਃ * * ਵਸਤਾਂ ਦੀਆਂ ਕੀਮਤਾਂ ਵਿੱਚ ਉਤਰਾਅ-ਚਡ਼੍ਹਾਅ ਕਿਸਾਨਾਂ ਲਈ ਯੋਜਨਾਬੰਦੀ ਅਤੇ ਮੁਨਾਫਾ ਕਮਾਉਣਾ ਮੁਸ਼ਕਲ ਬਣਾ ਸਕਦੇ ਹਨ। * * * ਨਿਵੇਸ਼ ਲਾਗਤਃ * * ਬੀਜਾਂ, ਖਾਦਾਂ ਅਤੇ ਹੋਰ ਨਿਵੇਸ਼ ਦੀ ਲਾਗਤ ਉੱਚੀ ਅਤੇ ਅਣਹੋਣੀ ਹੋ ਸਕਦੀ ਹੈ। * * * ਮਜ਼ਦੂਰਾਂ ਦੀ ਘਾਟਃ * * ਯੋਗ ਮਜ਼ਦੂਰਾਂ ਨੂੰ ਲੱਭਣਾ ਅਤੇ ਬਰਕਰਾਰ ਰੱਖਣਾ ਇੱਕ ਚੁਣੌਤੀ ਹੋ ਸਕਦੀ ਹੈ, ਖ਼ਾਸਕਰ ਪੀਕ ਸੀਜ਼ਨ ਦੌਰਾਨ। * * * ਨਿਯਮ ਅਤੇ ਨੀਤੀਆਂਃ * * ਕਿਸਾਨਾਂ ਨੂੰ ਨਿਯਮਾਂ ਦੇ ਇੱਕ ਗੁੰਝਲਦਾਰ ਜਾਲ ਦੀ ਪਾਲਣਾ ਕਰਨੀ ਚਾਹੀਦੀ ਹੈ, ਜੋ ਮਹਿੰਗੇ ਅਤੇ ਸਮਾਂ ਲੈਣ ਵਾਲੇ ਹੋ ਸਕਦੇ ਹਨ। * * * ਤਕਨਾਲੋਜੀ ਤੱਕ ਪਹੁੰਚਃ * * ਕਿਸਾਨ ਨਵੀਆਂ ਤਕਨੀਕਾਂ ਨੂੰ ਅਪਣਾਉਣ ਲਈ ਸੰਘਰਸ਼ ਕਰ ਸਕਦੇ ਹਨ ਜੋ ਕੁਸ਼ਲਤਾ ਅਤੇ ਜਲਵਾਯੂ ਪਰਿਵਰਤਨ ਵਿੱਚ ਸੁਧਾਰ ਕਰ ਸਕਦੀਆਂ ਹਨ। \"\n",
    "english_translation = GoogleTranslator(source='pa', target='en').translate(punjabi_text)\n",
    "print(\"English Translation:\", english_translation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "def english_to_punjabi(english_text):\n",
    "    return GoogleTranslator(source='en', target='pa').translate(english_text)\n",
    "\n",
    "def punjabi_to_english(punjabi_text):\n",
    "    return GoogleTranslator(source='pa', target='en').translate(punjabi_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# english_to_punjabi(\"\"\"In a quiet village nestled between rolling hills, there lived a curious girl named Lily. With her wild curls and bright green eyes, she had a knack for finding adventure in the most ordinary places. One sunny afternoon, while exploring the outskirts of her village, Lily stumbled upon an old, wrought-iron gate hidden behind a curtain of ivy.\n",
    "\n",
    "# Intrigued, she pushed the gate open, its rusty hinges creaking as if awakening from a long slumber. Beyond the gate lay a path overgrown with wildflowers, leading into a secluded garden. The air was thick with the sweet scent of blooming jasmine and honeysuckle, and the gentle hum of bees filled her ears. As she ventured further, she marveled at the vibrant colors and sounds around her.\n",
    "\n",
    "# In the heart of the garden stood a majestic tree, its branches stretching wide like welcoming arms. Beneath its shade, a weathered stone bench invited her to sit and rest. Lily approached the bench and noticed an engraved plaque that read, “To those who seek, beauty awaits.” Puzzled but delighted, she took a seat, allowing the tranquility of the garden to wash over her.\n",
    "\n",
    "# As she sat there, a flutter of movement caught her eye. A delicate butterfly, with wings painted in hues of blue and gold, danced around her. Entranced, Lily followed the butterfly as it led her deeper into the garden. Each step revealed more wonders: a sparkling fountain, hidden among the ferns, and a mosaic of colorful pebbles forming a path to a secret nook.\n",
    "\n",
    "# In this nook, she discovered a group of children playing, their laughter ringing out like music. They were painting stones, their hands smeared with vibrant colors. One of the children, a boy with bright red hair and a contagious smile, waved her over. “Join us! We’re creating magic!” he exclaimed.\n",
    "\n",
    "# Lily hesitated for a moment, then approached the group. They welcomed her warmly, and soon she was painting stones with them, her imagination igniting as she transformed ordinary rocks into whimsical creatures and dazzling patterns. Time seemed to slip away as they shared stories and laughter, forging bonds that felt timeless.\n",
    "\n",
    "# As the sun began to dip below the horizon, casting a golden glow over the garden, Lily realized she needed to return home. The children understood her need to leave but invited her to return. “This garden is a place of magic,” the boy with red hair said. “Whenever you feel lost, just follow the path of wildflowers.”\n",
    "\n",
    "# With a heart full of joy and a pocket full of painted stones, Lily made her way back to the iron gate. She paused to take one last look at the hidden garden, a world of wonder and friendship that felt like a dream. As she stepped through the gate and closed it behind her, she felt a sense of promise—a promise of return.\n",
    "\n",
    "# From that day on, the garden became her sanctuary. Whenever life felt overwhelming or mundane, she would escape to her secret place, paint stones with her new friends, and bask in the beauty of the hidden garden. With each visit, she learned that magic existed not just in the garden but within herself and the connections she made along the way.\n",
    "\n",
    "# Lily’s adventures in the garden taught her that beauty and friendship often lie just beyond the ordinary, waiting for those brave enough to seek them out. And so, with a heart full of hope and a spirit of adventure, she continued to explore the world, one hidden garden at a time.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once upon a time, there lived a girl named Simran in a small house in the village. Simran was very beautiful and laborious. She used to work in the fields of her village every day and would come back in the afternoon and listen to the stories of her grandparents. His grandmother always told him old stories, which were similar to his mother\\'s stories.\\n\\nOne day, Simran hears from her grandmother that there is a magical forest outside the village, where everything is possible. In the middle of the forest is a magical lake, which fulfills people\\'s tragic wishes. Curiosity awakened in Simran\\'s heart. She thought she wanted to explore this forest.\\n\\nSimran chose the day and left early in the morning. Walking through the forest, he saw beautiful birds, colorful flowers and tall trees. He realized that it was indeed an enchanted forest. As she approached the lake, she saw that the water of the lake was bright and had something unique in it. She dips her feet into the water of the lake and touches the water, and her desires begin.\\n\\nSimran asked for her first wish: \"I want the people of my village to be happy.\" The water in the lake started to sparkle, and Simran realized that magic was happening. The next moment, he was heartened to see the people of his village laughing and playing.\\n\\nThen, he made a second wish: \"May I have a student to teach!\" The lake presented a beautiful book in front of him. He opened that book, and found in it much knowledge and learning. Simran inspired the children of his village to read with the help of that book.\\n\\nFinally, Simran makes a third wish: \"I get time to spend with grandma!\" The water of the lake also fulfilled his wish. Simran\\'s grandmother fondly tells him about the lake, and the two share their memories together.\\n\\nSimran finally thought that the true effect of magic lies in the support and love of people. He shared this knowledge with the people of his village, and the whole village planned to celebrate together. This magical journey becomes a climax for Simran, and he learns that true happiness comes only with companions, friends and love.\\n\\nHer magical journey made Simran understand that when we give happiness to someone, we also get happiness in our own heart.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# punjabi_to_english(\"\"\"ਇੱਕ ਵਾਰੀ ਦੀ ਗੱਲ ਹੈ, ਪਿੰਡ ਦੇ ਇੱਕ ਛੋਟੇ ਘਰ ਵਿਚ ਇੱਕ ਕੁੜੀ ਰਹਿੰਦੀ ਸੀ ਜਿਸਦਾ ਨਾਮ ਸੀ ਸਿਮਰਨ। ਸਿਮਰਨ ਬਹੁਤ ਸੁੰਦਰ ਅਤੇ ਮਿਹਨਤੀ ਸੀ। ਉਹ ਹਰ ਰੋਜ ਆਪਣੇ ਪਿੰਡ ਦੇ ਖੇਤਾਂ ਵਿਚ ਕੰਮ ਕਰਦੀ ਅਤੇ ਦੁਪਹਿਰ ਨੂੰ ਵਾਪਸ ਆ ਕੇ ਆਪਣੇ ਦਾਦੀ-ਨਾਨੀ ਦੀਆਂ ਗੱਲਾਂ ਸੁਣਦੀ। ਉਸ ਦੀ ਦਾਦੀ ਹਮੇਸ਼ਾ ਉਸਨੂੰ ਪੁਰਾਣੀਆਂ ਕਹਾਣੀਆਂ ਸੁਣਾਉਂਦੀ ਸੀ, ਜੋ ਕਿ ਉਸਦੀ ਮਾਂ ਦੀਆਂ ਕਹਾਣੀਆਂ ਨਾਲ ਮਿਲਦੀਆਂ ਜੁਲਦੀਆਂ ਹੁੰਦੀਆਂ ਸਨ।\n",
    "\n",
    "# ਇੱਕ ਦਿਨ, ਸਿਮਰਨ ਨੇ ਆਪਣੀ ਦਾਦੀ ਤੋਂ ਸੁਣਿਆ ਕਿ ਪਿੰਡ ਦੇ ਬਾਹਰ ਇੱਕ ਜਾਦੂਈ ਜੰਗਲ ਹੈ, ਜਿਸ ਵਿੱਚ ਸਭ ਕੁਝ ਸੰਭਵ ਹੈ। ਜੰਗਲ ਦੇ ਵਿਚਕਾਰ ਇੱਕ ਜਾਦੂਈ ਝੀਲ ਹੈ, ਜੋ ਲੋਕਾਂ ਦੀਆਂ ਦੁਖਦਾਈਆਂ ਇੱਛਾਵਾਂ ਨੂੰ ਪੂਰਾ ਕਰਦੀ ਹੈ। ਸਿਮਰਨ ਦੇ ਦਿਲ ਵਿਚ ਜਿਗਿਆਸਾ ਜਾਗੀ। ਉਸਨੇ ਸੋਚਿਆ ਕਿ ਉਹ ਇਸ ਜੰਗਲ ਨੂੰ ਖੋਜਣਾ ਚਾਹੁੰਦੀ ਹੈ।\n",
    "\n",
    "# ਸਿਮਰਨ ਨੇ ਦਿਨ ਚੁਣਿਆ ਅਤੇ ਸਵੇਰੇ ਸਵੇਰੇ ਨਿਕਲੀ। ਜੰਗਲ ਵਿਚ ਚਲਦੇ-ਚਲਦੇ ਉਸਨੇ ਸੁੰਦਰ ਪੱਖੀਆਂ, ਰੰਗੀਨ ਫੁੱਲ ਅਤੇ ਉੱਚੀਆਂ ਦਰਖਤਾਂ ਨੂੰ ਦੇਖਿਆ। ਉਸ ਨੂੰ ਸਮਝ ਆ ਗਿਆ ਕਿ ਇਹ ਸੱਚਮੁਚ ਇੱਕ ਜਾਦੂਈ ਜੰਗਲ ਹੈ। ਜਦੋਂ ਉਹ ਝੀਲ ਦੇ ਨੇੜੇ ਪਹੁੰਚੀ, ਉਸਨੇ ਵੇਖਿਆ ਕਿ ਝੀਲ ਦਾ ਪਾਣੀ ਚਮਕਦਾਰ ਹੈ ਅਤੇ ਇਸ ਵਿਚ ਕੁਝ ਵਿਲੱਖਣ ਹਨ। ਉਹ ਝੀਲ ਦੇ ਪਾਣੀ ਵਿਚ ਆਪਣੇ ਪੈਰ ਮਾਰ ਕੇ ਪਾਣੀ ਨੂੰ ਛੂਹਦੀ ਹੈ, ਅਤੇ ਉਸ ਦੀਆਂ ਇੱਛਾਵਾਂ ਦਾ ਆਰੰਭ ਹੁੰਦਾ ਹੈ।\n",
    "\n",
    "# ਸਿਮਰਨ ਨੇ ਆਪਣੀ ਪਹਿਲੀ ਇੱਛਾ ਮੰਗੀ: \"ਮੈਂ ਚਾਹੁੰਦੀ ਹਾਂ ਕਿ ਮੇਰੇ ਪਿੰਡ ਦੇ ਲੋਕ ਖੁਸ਼ ਰਹਿਣ।\" ਝੀਲ ਦੇ ਪਾਣੀ ਨੇ ਚਮਕਣਾ ਸ਼ੁਰੂ ਕਰ ਦਿੱਤਾ, ਅਤੇ ਸਿਮਰਨ ਨੂੰ ਅਹਿਸਾਸ ਹੋਇਆ ਕਿ ਇਹ ਜਾਦੂ ਹੋ ਰਿਹਾ ਹੈ। ਅਗਲੇ ਪਲ, ਉਸ ਦੇ ਪਿੰਡ ਦੇ ਲੋਕਾਂ ਨੂੰ ਹੱਸਦੇ-ਖੇਡਦੇ ਦੇਖ ਕੇ ਉਸ ਦਾ ਦਿਲ ਖੁਸ਼ ਹੋ ਗਿਆ।\n",
    "\n",
    "# ਫਿਰ, ਉਸਨੇ ਦੂਜੀ ਇੱਛਾ ਮੰਗੀ: \"ਮੈਨੂੰ ਸਿੱਖਿਆ ਦੇਣ ਵਾਲਾ ਇੱਕ ਵਿਦਿਆਰਥੀ ਮਿਲ ਜਾਵੇ!\" ਝੀਲ ਨੇ ਇੱਕ ਸੁੰਦਰ ਕਿਤਾਬ ਉਸਦੇ ਸਾਹਮਣੇ ਪੇਸ਼ ਕੀਤੀ। ਉਸਨੇ ਉਸ ਕਿਤਾਬ ਨੂੰ ਖੋਲ੍ਹਿਆ, ਅਤੇ ਉਸ ਵਿਚ ਬਹੁਤ ਸਾਰੇ ਗਿਆਨ ਅਤੇ ਸਿੱਖਿਆ ਮਿਲੀ। ਸਿਮਰਨ ਨੇ ਉਸ ਕਿਤਾਬ ਦੇ ਸਹਾਰੇ ਆਪਣੇ ਪਿੰਡ ਦੇ ਬੱਚਿਆਂ ਨੂੰ ਪੜ੍ਹਨ ਲਈ ਪ੍ਰੇਰਿਤ ਕੀਤਾ।\n",
    "\n",
    "# ਆਖਿਰ ਵਿਚ, ਸਿਮਰਨ ਨੇ ਤੀਜੀ ਇੱਛਾ ਮੰਗੀ: \"ਮੈਨੂੰ ਦਾਦੀ ਦੇ ਸਾਥ ਬਿਟਾਉਣ ਲਈ ਸਮਾਂ ਮਿਲੇ!\" ਝੀਲ ਦੇ ਪਾਣੀ ਨੇ ਉਸ ਨੂੰ ਇਹ ਚਾਹੁਣਾ ਵੀ ਪੂਰਾ ਕੀਤਾ। ਸਿਮਰਨ ਦੇ ਦਾਦੀ ਨੇ ਉਸਨੂੰ ਬਹੁਤ ਪਿਆਰ ਨਾਲ ਝੀਲ ਦੇ ਬਾਰੇ ਦੱਸਿਆ, ਅਤੇ ਦੋਹਾਂ ਨੇ ਮਿਲ ਕੇ ਆਪਣੀਆਂ ਯਾਦਾਂ ਨੂੰ ਸਾਂਝਾ ਕੀਤਾ।\n",
    "\n",
    "# ਸਿਮਰਨ ਨੇ ਅਖੀਰ ਦੇ ਵਿੱਚ ਸੋਚਿਆ ਕਿ ਜਾਦੂ ਦਾ ਸੱਚਾ ਪ੍ਰਭਾਵ ਲੋਕਾਂ ਦੇ ਸਹਾਰੇ ਅਤੇ ਪ੍ਰੇਮ ਵਿੱਚ ਹੈ। ਉਸਨੇ ਇਹੀ ਸਿੱਖਿਆ ਆਪਣੇ ਪਿੰਡ ਦੇ ਲੋਕਾਂ ਨਾਲ ਸਾਂਝੀ ਕੀਤੀ, ਅਤੇ ਸਾਰੇ ਪਿੰਡ ਨੇ ਮਿਲ ਕੇ ਖੁਸ਼ੀਆਂ ਮਨਾਉਣ ਦੀ ਯੋਜਨਾ ਬਣਾਈ। ਇਹ ਜਾਦੂਈ ਯਾਤਰਾ ਸਿਮਰਨ ਲਈ ਇੱਕ ਸਿਖਰ ਹੋ ਗਈ, ਅਤੇ ਉਸਨੇ ਸਿੱਖਿਆ ਕਿ ਸੱਚੀ ਖੁਸ਼ੀ ਦੋਸ਼ੀਆਂ, ਦੋਸਤਾਂ ਅਤੇ ਪ੍ਰੇਮ ਨਾਲ ਹੀ ਮਿਲਦੀ ਹੈ।\n",
    "\n",
    "# ਉਸ ਦੀ ਜਾਦੂਈ ਯਾਤਰਾ ਨੇ ਸਿਮਰਨ ਨੂੰ ਸਮਝਾਇਆ ਕਿ ਜਦੋਂ ਅਸੀਂ ਕਿਸੇ ਨੂੰ ਖੁਸ਼ੀ ਦਿੰਦੇ ਹਾਂ, ਤਾਂ ਸਾਡੇ ਆਪਣੇ ਦਿਲ ਵਿਚ ਵੀ ਖੁਸ਼ੀ ਹੁੰਦੀ ਹੈ।\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chatbot translate google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start chatting with the AI! Type 'exit' to end the conversation.\n",
      "What are pesticides, and their uses?\n",
      "AI: for english Pesticides are substances that are used to kill or control pests, which can include insects, weeds, fungi, bacteria, viruses, and rodents. They are used in agriculture, forestry, public health, and other areas to protect crops, livestock, and humans from pests. Pesticides can be applied in a variety of ways, including spraying, dusting, and fumigation. They can be made from synthetic chemicals, natural products, or a combination of both.  \n",
      "\n",
      "Pesticides are used for a variety of purposes, including:\n",
      "\n",
      "* **Protecting crops from pests:** Pesticides are used to control insects, weeds, and diseases that can damage crops and reduce yields.\n",
      "* **Controlling pests in homes and gardens:** Pesticides are used to kill insects, rodents, and other pests that can infest homes and gardens.\n",
      "* **Protecting livestock from pests:** Pesticides are used to control insects, ticks, and other pests that can harm livestock.\n",
      "* **Controlling disease vectors:** Pesticides are used to control mosquitoes, flies, and other insects that can transmit diseases to humans.\n",
      "* **Preserving wood:** Pesticides are used to protect wood from insects and fungi.\n",
      "\n",
      "While pesticides can be beneficial, they can also have negative impacts on the environment and human health. It is important to use pesticides safely and responsibly to minimize these risks.\n",
      "\n",
      "**Source:**  This information is based on general knowledge about pesticides. \n",
      "\n",
      "AI: ਕੀਟਨਾਸ਼ਕ ਉਹ ਪਦਾਰਥ ਹੁੰਦੇ ਹਨ ਜੋ ਕੀੜਿਆਂ ਨੂੰ ਮਾਰਨ ਜਾਂ ਕੰਟਰੋਲ ਕਰਨ ਲਈ ਵਰਤੇ ਜਾਂਦੇ ਹਨ, ਜਿਸ ਵਿੱਚ ਕੀੜੇ, ਨਦੀਨ, ਉੱਲੀ, ਬੈਕਟੀਰੀਆ, ਵਾਇਰਸ ਅਤੇ ਚੂਹੇ ਸ਼ਾਮਲ ਹੋ ਸਕਦੇ ਹਨ। ਇਹਨਾਂ ਦੀ ਵਰਤੋਂ ਫਸਲਾਂ, ਪਸ਼ੂਆਂ ਅਤੇ ਮਨੁੱਖਾਂ ਨੂੰ ਕੀੜਿਆਂ ਤੋਂ ਬਚਾਉਣ ਲਈ ਖੇਤੀਬਾੜੀ, ਜੰਗਲਾਤ, ਜਨਤਕ ਸਿਹਤ ਅਤੇ ਹੋਰ ਖੇਤਰਾਂ ਵਿੱਚ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਕੀਟਨਾਸ਼ਕਾਂ ਨੂੰ ਵੱਖ-ਵੱਖ ਤਰੀਕਿਆਂ ਨਾਲ ਲਾਗੂ ਕੀਤਾ ਜਾ ਸਕਦਾ ਹੈ, ਜਿਵੇਂ ਕਿ ਛਿੜਕਾਅ, ਧੂੜ ਅਤੇ ਧੁੰਦ। ਉਹ ਸਿੰਥੈਟਿਕ ਰਸਾਇਣਾਂ, ਕੁਦਰਤੀ ਉਤਪਾਦਾਂ, ਜਾਂ ਦੋਵਾਂ ਦੇ ਸੁਮੇਲ ਤੋਂ ਬਣਾਏ ਜਾ ਸਕਦੇ ਹਨ।  \n",
      "\n",
      "ਕੀਟਨਾਸ਼ਕਾਂ ਦੀ ਵਰਤੋਂ ਕਈ ਤਰ੍ਹਾਂ ਦੇ ਉਦੇਸ਼ਾਂ ਲਈ ਕੀਤੀ ਜਾਂਦੀ ਹੈ, ਜਿਸ ਵਿੱਚ ਸ਼ਾਮਲ ਹਨ:\n",
      "\n",
      "* **ਫਸਲਾਂ ਨੂੰ ਕੀੜਿਆਂ ਤੋਂ ਬਚਾਉਣਾ:** ਕੀਟਨਾਸ਼ਕਾਂ ਦੀ ਵਰਤੋਂ ਕੀੜੇ-ਮਕੌੜਿਆਂ, ਨਦੀਨਾਂ ਅਤੇ ਬਿਮਾਰੀਆਂ ਨੂੰ ਕੰਟਰੋਲ ਕਰਨ ਲਈ ਕੀਤੀ ਜਾਂਦੀ ਹੈ ਜੋ ਫਸਲਾਂ ਨੂੰ ਨੁਕਸਾਨ ਪਹੁੰਚਾ ਸਕਦੀਆਂ ਹਨ ਅਤੇ ਝਾੜ ਘਟਾ ਸਕਦੀਆਂ ਹਨ।\n",
      "* **ਘਰਾਂ ਅਤੇ ਬਗੀਚਿਆਂ ਵਿੱਚ ਕੀੜਿਆਂ ਨੂੰ ਨਿਯੰਤਰਿਤ ਕਰਨਾ:** ਕੀਟਨਾਸ਼ਕਾਂ ਦੀ ਵਰਤੋਂ ਕੀੜਿਆਂ, ਚੂਹਿਆਂ ਅਤੇ ਹੋਰ ਕੀੜਿਆਂ ਨੂੰ ਮਾਰਨ ਲਈ ਕੀਤੀ ਜਾਂਦੀ ਹੈ ਜੋ ਘਰਾਂ ਅਤੇ ਬਗੀਚਿਆਂ ਨੂੰ ਸੰਕਰਮਿਤ ਕਰ ਸਕਦੇ ਹਨ।\n",
      "* **ਪਸ਼ੂਆਂ ਨੂੰ ਕੀੜਿਆਂ ਤੋਂ ਬਚਾਉਣਾ:** ਕੀਟਨਾਸ਼ਕਾਂ ਦੀ ਵਰਤੋਂ ਕੀੜਿਆਂ, ਟਿੱਕਾਂ ਅਤੇ ਹੋਰ ਕੀੜਿਆਂ ਨੂੰ ਕੰਟਰੋਲ ਕਰਨ ਲਈ ਕੀਤੀ ਜਾਂਦੀ ਹੈ ਜੋ ਪਸ਼ੂਆਂ ਨੂੰ ਨੁਕਸਾਨ ਪਹੁੰਚਾ ਸਕਦੇ ਹਨ।\n",
      "* **ਰੋਗਾਂ ਨੂੰ ਕੰਟਰੋਲ ਕਰਨ ਵਾਲੇ ਵੈਕਟਰ:** ਕੀਟਨਾਸ਼ਕਾਂ ਦੀ ਵਰਤੋਂ ਮੱਛਰਾਂ, ਮੱਖੀਆਂ ਅਤੇ ਹੋਰ ਕੀੜਿਆਂ ਨੂੰ ਕੰਟਰੋਲ ਕਰਨ ਲਈ ਕੀਤੀ ਜਾਂਦੀ ਹੈ ਜੋ ਮਨੁੱਖਾਂ ਨੂੰ ਬਿਮਾਰੀਆਂ ਦਾ ਸੰਚਾਰ ਕਰ ਸਕਦੇ ਹਨ।\n",
      "* **ਲੱਕੜ ਨੂੰ ਸੁਰੱਖਿਅਤ ਕਰਨਾ:** ਕੀਟਨਾਸ਼ਕਾਂ ਦੀ ਵਰਤੋਂ ਲੱਕੜ ਨੂੰ ਕੀੜਿਆਂ ਅਤੇ ਉੱਲੀ ਤੋਂ ਬਚਾਉਣ ਲਈ ਕੀਤੀ ਜਾਂਦੀ ਹੈ।\n",
      "\n",
      "ਜਦੋਂ ਕਿ ਕੀਟਨਾਸ਼ਕ ਲਾਭਦਾਇਕ ਹੋ ਸਕਦੇ ਹਨ, ਉਹ ਵਾਤਾਵਰਣ ਅਤੇ ਮਨੁੱਖੀ ਸਿਹਤ 'ਤੇ ਮਾੜੇ ਪ੍ਰਭਾਵ ਵੀ ਪਾ ਸਕਦੇ ਹਨ। ਇਹਨਾਂ ਖਤਰਿਆਂ ਨੂੰ ਘੱਟ ਤੋਂ ਘੱਟ ਕਰਨ ਲਈ ਕੀਟਨਾਸ਼ਕਾਂ ਦੀ ਸੁਰੱਖਿਅਤ ਅਤੇ ਜ਼ਿੰਮੇਵਾਰੀ ਨਾਲ ਵਰਤੋਂ ਕਰਨਾ ਮਹੱਤਵਪੂਰਨ ਹੈ।\n",
      "\n",
      "**ਸਰੋਤ:** ਇਹ ਜਾਣਕਾਰੀ ਕੀਟਨਾਸ਼ਕਾਂ ਬਾਰੇ ਆਮ ਜਾਣਕਾਰੀ 'ਤੇ ਆਧਾਰਿਤ ਹੈ।\n",
      "What variety is used with wheat?\n",
      "AI: for english I need more information to answer your question.  \"Variety\" can refer to many things when it comes to wheat.  Please clarify what you are asking about:\n",
      "\n",
      "* **Wheat variety:** Are you asking about a specific type of wheat, like durum or red spring wheat?\n",
      "* **Variety of use:** Are you asking about how wheat is used, like for bread, pasta, or animal feed?\n",
      "* **Variety of growing conditions:** Are you asking about the different climates or soil types where wheat is grown?\n",
      "\n",
      "Once you provide more context, I can give you a more specific answer. \n",
      "\n",
      "AI: ਮੈਨੂੰ ਤੁਹਾਡੇ ਸਵਾਲ ਦਾ ਜਵਾਬ ਦੇਣ ਲਈ ਹੋਰ ਜਾਣਕਾਰੀ ਦੀ ਲੋੜ ਹੈ।  ਜਦੋਂ ਕਣਕ ਦੀ ਗੱਲ ਆਉਂਦੀ ਹੈ ਤਾਂ \"ਵਿਭਿੰਨਤਾ\" ਬਹੁਤ ਸਾਰੀਆਂ ਚੀਜ਼ਾਂ ਦਾ ਹਵਾਲਾ ਦੇ ਸਕਦੀ ਹੈ।  ਕਿਰਪਾ ਕਰਕੇ ਸਪਸ਼ਟ ਕਰੋ ਕਿ ਤੁਸੀਂ ਕਿਸ ਬਾਰੇ ਪੁੱਛ ਰਹੇ ਹੋ:\n",
      "\n",
      "* **ਕਣਕ ਦੀ ਕਿਸਮ:** ਕੀ ਤੁਸੀਂ ਕਿਸੇ ਖਾਸ ਕਿਸਮ ਦੀ ਕਣਕ ਬਾਰੇ ਪੁੱਛ ਰਹੇ ਹੋ, ਜਿਵੇਂ ਕਿ ਡੁਰਮ ਜਾਂ ਲਾਲ ਸਪਰਿੰਗ ਕਣਕ?\n",
      "* **ਵਰਤਣ ਦੀਆਂ ਕਿਸਮਾਂ:** ਕੀ ਤੁਸੀਂ ਇਸ ਬਾਰੇ ਪੁੱਛ ਰਹੇ ਹੋ ਕਿ ਕਣਕ ਦੀ ਵਰਤੋਂ ਕਿਵੇਂ ਕੀਤੀ ਜਾਂਦੀ ਹੈ, ਜਿਵੇਂ ਕਿ ਰੋਟੀ, ਪਾਸਤਾ, ਜਾਂ ਪਸ਼ੂ ਚਾਰੇ ਲਈ?\n",
      "* **ਵਧਣ ਦੀਆਂ ਸਥਿਤੀਆਂ ਦੀਆਂ ਕਿਸਮਾਂ:** ਕੀ ਤੁਸੀਂ ਵੱਖੋ-ਵੱਖਰੇ ਮੌਸਮ ਜਾਂ ਮਿੱਟੀ ਦੀਆਂ ਕਿਸਮਾਂ ਬਾਰੇ ਪੁੱਛ ਰਹੇ ਹੋ ਜਿੱਥੇ ਕਣਕ ਉਗਾਈ ਜਾਂਦੀ ਹੈ?\n",
      "\n",
      "ਇੱਕ ਵਾਰ ਜਦੋਂ ਤੁਸੀਂ ਵਧੇਰੇ ਸੰਦਰਭ ਪ੍ਰਦਾਨ ਕਰਦੇ ਹੋ, ਤਾਂ ਮੈਂ ਤੁਹਾਨੂੰ ਇੱਕ ਹੋਰ ਖਾਸ ਜਵਾਬ ਦੇ ਸਕਦਾ ਹਾਂ।\n",
      "How to produce more produce on the same land?\n",
      "AI: for english Increasing produce on the same land, also known as **yield optimization**, involves a combination of strategies:\n",
      "\n",
      "**1. Soil Health & Management:**\n",
      "\n",
      "* **Improve Soil Fertility:** Use organic matter (compost, manure) to increase soil health, nutrient retention, and water-holding capacity.\n",
      "* **Optimize Nutrient Management:** Conduct soil tests to understand nutrient needs and apply fertilizers strategically.\n",
      "* **Promote Beneficial Microbes:** Use cover crops, compost tea, or inoculants to enhance microbial activity, improving soil structure and nutrient availability.\n",
      "* **Control Pests & Diseases:** Employ integrated pest management (IPM) strategies, including biological control, crop rotation, and resistant varieties, to minimize losses.\n",
      "\n",
      "**2. Water Management:**\n",
      "\n",
      "* **Efficient Irrigation:** Use drip irrigation or other water-saving methods to deliver water directly to plant roots.\n",
      "* **Water Conservation:** Collect rainwater, use mulches to reduce evaporation, and practice water-wise gardening techniques.\n",
      "* **Improve Water Retention:** Enhance soil structure through organic matter and cover crops to increase water holding capacity.\n",
      "\n",
      "**3. Plant Selection & Management:**\n",
      "\n",
      "* **Choose High-Yielding Varieties:** Select varieties known for their productivity and suitability to your climate and growing conditions.\n",
      "* **Optimal Planting Density:** Adjust plant spacing to maximize light and nutrient access for optimal growth.\n",
      "* **Intercropping & Companion Planting:** Combine different crops to enhance growth, pest control, and resource utilization.\n",
      "* **Crop Rotation:** Alternate crops to break disease cycles, improve soil health, and reduce pest pressure.\n",
      "\n",
      "**4.  Advanced Techniques:**\n",
      "\n",
      "* **Vertical Gardening:** Utilize vertical space for growing, maximizing area for cultivation.\n",
      "* **Hydroponics & Aquaponics:** Explore water-based growing systems for higher yields and resource efficiency.\n",
      "* **Precision Agriculture:** Use data-driven technologies to optimize fertilizer application, irrigation, and pest control.\n",
      "\n",
      "**5.  Sustainability:**\n",
      "\n",
      "* **Reduce Waste:** Minimize food waste through proper storage, processing, and consumption.\n",
      "* **Support Local Food Systems:** Strengthen local food networks to reduce transportation costs and environmental impact.\n",
      "\n",
      "**Remember:** The best approach depends on your specific location, crops, and resources. Consulting with local agricultural experts and research institutions can provide valuable guidance and support. \n",
      "\n",
      "AI: ਉਸੇ ਜ਼ਮੀਨ 'ਤੇ ਪੈਦਾਵਾਰ ਨੂੰ ਵਧਾਉਣਾ, ਜਿਸਨੂੰ **ਉਪਜ ਅਨੁਕੂਲਨ** ਵੀ ਕਿਹਾ ਜਾਂਦਾ ਹੈ, ਵਿੱਚ ਰਣਨੀਤੀਆਂ ਦਾ ਸੁਮੇਲ ਸ਼ਾਮਲ ਹੁੰਦਾ ਹੈ:\n",
      "\n",
      "**1। ਮਿੱਟੀ ਦੀ ਸਿਹਤ ਅਤੇ ਪ੍ਰਬੰਧਨ:**\n",
      "\n",
      "* **ਮਿੱਟੀ ਦੀ ਉਪਜਾਊ ਸ਼ਕਤੀ ਵਿੱਚ ਸੁਧਾਰ ਕਰੋ:** ਮਿੱਟੀ ਦੀ ਸਿਹਤ, ਪੌਸ਼ਟਿਕ ਤੱਤਾਂ ਦੀ ਸੰਭਾਲ, ਅਤੇ ਪਾਣੀ ਰੱਖਣ ਦੀ ਸਮਰੱਥਾ ਨੂੰ ਵਧਾਉਣ ਲਈ ਜੈਵਿਕ ਪਦਾਰਥ (ਖਾਦ, ਖਾਦ) ਦੀ ਵਰਤੋਂ ਕਰੋ।\n",
      "* **ਪੋਸ਼ਟਿਕ ਤੱਤ ਪ੍ਰਬੰਧਨ ਨੂੰ ਅਨੁਕੂਲ ਬਣਾਓ:** ਪੌਸ਼ਟਿਕ ਤੱਤਾਂ ਦੀਆਂ ਲੋੜਾਂ ਨੂੰ ਸਮਝਣ ਲਈ ਮਿੱਟੀ ਦੀ ਜਾਂਚ ਕਰੋ ਅਤੇ ਖਾਦਾਂ ਨੂੰ ਰਣਨੀਤਕ ਤੌਰ 'ਤੇ ਲਾਗੂ ਕਰੋ।\n",
      "* **ਲਾਹੇਵੰਦ ਰੋਗਾਣੂਆਂ ਨੂੰ ਉਤਸ਼ਾਹਿਤ ਕਰੋ:** ਮਾਈਕ੍ਰੋਬਾਇਲ ਗਤੀਵਿਧੀ ਨੂੰ ਵਧਾਉਣ, ਮਿੱਟੀ ਦੀ ਬਣਤਰ ਅਤੇ ਪੌਸ਼ਟਿਕ ਤੱਤਾਂ ਦੀ ਉਪਲਬਧਤਾ ਨੂੰ ਬਿਹਤਰ ਬਣਾਉਣ ਲਈ ਢੱਕਣ ਵਾਲੀਆਂ ਫਸਲਾਂ, ਖਾਦ ਚਾਹ, ਜਾਂ ਟੀਕਾਕਰਨ ਦੀ ਵਰਤੋਂ ਕਰੋ।\n",
      "* **ਕੀੜਿਆਂ ਅਤੇ ਬਿਮਾਰੀਆਂ ਨੂੰ ਕੰਟਰੋਲ ਕਰੋ:** ਨੁਕਸਾਨ ਨੂੰ ਘੱਟ ਤੋਂ ਘੱਟ ਕਰਨ ਲਈ ਜੈਵਿਕ ਨਿਯੰਤਰਣ, ਫਸਲ ਰੋਟੇਸ਼ਨ ਅਤੇ ਰੋਧਕ ਕਿਸਮਾਂ ਸਮੇਤ ਏਕੀਕ੍ਰਿਤ ਕੀਟ ਪ੍ਰਬੰਧਨ (IPM) ਰਣਨੀਤੀਆਂ ਨੂੰ ਲਾਗੂ ਕਰੋ।\n",
      "\n",
      "**2. ਜਲ ਪ੍ਰਬੰਧਨ:**\n",
      "\n",
      "* **ਕੁਸ਼ਲ ਸਿੰਚਾਈ:** ਸਿੱਧੇ ਪੌਦਿਆਂ ਦੀਆਂ ਜੜ੍ਹਾਂ ਤੱਕ ਪਾਣੀ ਪਹੁੰਚਾਉਣ ਲਈ ਤੁਪਕਾ ਸਿੰਚਾਈ ਜਾਂ ਪਾਣੀ ਬਚਾਉਣ ਦੇ ਹੋਰ ਤਰੀਕਿਆਂ ਦੀ ਵਰਤੋਂ ਕਰੋ।\n",
      "* **ਪਾਣੀ ਦੀ ਸੰਭਾਲ:** ਬਰਸਾਤੀ ਪਾਣੀ ਨੂੰ ਇਕੱਠਾ ਕਰੋ, ਵਾਸ਼ਪੀਕਰਨ ਨੂੰ ਘਟਾਉਣ ਲਈ ਮਲਚਾਂ ਦੀ ਵਰਤੋਂ ਕਰੋ, ਅਤੇ ਪਾਣੀ ਅਨੁਸਾਰ ਬਾਗਬਾਨੀ ਤਕਨੀਕਾਂ ਦਾ ਅਭਿਆਸ ਕਰੋ।\n",
      "* **ਪਾਣੀ ਧਾਰਨ ਵਿੱਚ ਸੁਧਾਰ ਕਰੋ:** ਜੈਵਿਕ ਪਦਾਰਥਾਂ ਰਾਹੀਂ ਮਿੱਟੀ ਦੀ ਬਣਤਰ ਨੂੰ ਵਧਾਓ ਅਤੇ ਪਾਣੀ ਰੱਖਣ ਦੀ ਸਮਰੱਥਾ ਨੂੰ ਵਧਾਉਣ ਲਈ ਫਸਲਾਂ ਨੂੰ ਢੱਕੋ।\n",
      "\n",
      "**3. ਪੌਦਿਆਂ ਦੀ ਚੋਣ ਅਤੇ ਪ੍ਰਬੰਧਨ:**\n",
      "\n",
      "* **ਉੱਚ-ਉਪਜ ਵਾਲੀਆਂ ਕਿਸਮਾਂ ਦੀ ਚੋਣ ਕਰੋ:** ਉਹਨਾਂ ਕਿਸਮਾਂ ਦੀ ਚੋਣ ਕਰੋ ਜੋ ਉਹਨਾਂ ਦੀ ਉਤਪਾਦਕਤਾ ਅਤੇ ਤੁਹਾਡੇ ਮੌਸਮ ਅਤੇ ਵਧ ਰਹੀ ਸਥਿਤੀਆਂ ਲਈ ਅਨੁਕੂਲਤਾ ਲਈ ਜਾਣੀਆਂ ਜਾਂਦੀਆਂ ਹਨ।\n",
      "* **ਅਨੁਕੂਲ ਪੌਦਿਆਂ ਦੀ ਘਣਤਾ:** ਅਨੁਕੂਲ ਵਿਕਾਸ ਲਈ ਰੋਸ਼ਨੀ ਅਤੇ ਪੌਸ਼ਟਿਕ ਤੱਤਾਂ ਦੀ ਪਹੁੰਚ ਨੂੰ ਵੱਧ ਤੋਂ ਵੱਧ ਕਰਨ ਲਈ ਪੌਦਿਆਂ ਦੀ ਦੂਰੀ ਨੂੰ ਵਿਵਸਥਿਤ ਕਰੋ।\n",
      "* **ਅੰਤਰਫਸਲੀ ਅਤੇ ਸਾਥੀ ਲਾਉਣਾ:** ਵਿਕਾਸ, ਕੀਟ ਕੰਟਰੋਲ, ਅਤੇ ਸਰੋਤ ਦੀ ਵਰਤੋਂ ਨੂੰ ਵਧਾਉਣ ਲਈ ਵੱਖ-ਵੱਖ ਫਸਲਾਂ ਨੂੰ ਜੋੜੋ।\n",
      "* **ਫਸਲ ਰੋਟੇਸ਼ਨ:** ਬਿਮਾਰੀਆਂ ਦੇ ਚੱਕਰ ਨੂੰ ਤੋੜਨ, ਮਿੱਟੀ ਦੀ ਸਿਹਤ ਵਿੱਚ ਸੁਧਾਰ ਕਰਨ ਅਤੇ ਕੀੜਿਆਂ ਦੇ ਦਬਾਅ ਨੂੰ ਘਟਾਉਣ ਲਈ ਵਿਕਲਪਕ ਫਸਲਾਂ।\n",
      "\n",
      "**4.  ਉੱਨਤ ਤਕਨੀਕਾਂ:**\n",
      "\n",
      "* **ਵਰਟੀਕਲ ਗਾਰਡਨਿੰਗ:** ਵਧਣ ਲਈ ਲੰਬਕਾਰੀ ਥਾਂ ਦੀ ਵਰਤੋਂ ਕਰੋ, ਕਾਸ਼ਤ ਲਈ ਖੇਤਰ ਨੂੰ ਵੱਧ ਤੋਂ ਵੱਧ ਕਰੋ।\n",
      "* **ਹਾਈਡ੍ਰੋਪੋਨਿਕਸ ਅਤੇ ਐਕਵਾਪੋਨਿਕਸ:** ਉੱਚ ਉਪਜ ਅਤੇ ਸਰੋਤ ਕੁਸ਼ਲਤਾ ਲਈ ਪਾਣੀ-ਅਧਾਰਤ ਵਧ ਰਹੀ ਪ੍ਰਣਾਲੀਆਂ ਦੀ ਪੜਚੋਲ ਕਰੋ।\n",
      "* **ਸ਼ੁੱਧ ਖੇਤੀ:** ਖਾਦ ਦੀ ਵਰਤੋਂ, ਸਿੰਚਾਈ, ਅਤੇ ਕੀਟ ਨਿਯੰਤਰਣ ਨੂੰ ਅਨੁਕੂਲ ਬਣਾਉਣ ਲਈ ਡੇਟਾ-ਸੰਚਾਲਿਤ ਤਕਨਾਲੋਜੀਆਂ ਦੀ ਵਰਤੋਂ ਕਰੋ।\n",
      "\n",
      "**5.  ਸਥਿਰਤਾ:**\n",
      "\n",
      "* **ਕੂੜੇ ਨੂੰ ਘਟਾਓ:** ਸਹੀ ਸਟੋਰੇਜ, ਪ੍ਰੋਸੈਸਿੰਗ ਅਤੇ ਖਪਤ ਦੁਆਰਾ ਭੋਜਨ ਦੀ ਰਹਿੰਦ-ਖੂੰਹਦ ਨੂੰ ਘੱਟ ਤੋਂ ਘੱਟ ਕਰੋ।\n",
      "* **ਸਥਾਨਕ ਭੋਜਨ ਪ੍ਰਣਾਲੀਆਂ ਦਾ ਸਮਰਥਨ ਕਰੋ:** ਆਵਾਜਾਈ ਦੇ ਖਰਚਿਆਂ ਅਤੇ ਵਾਤਾਵਰਣ ਦੇ ਪ੍ਰਭਾਵ ਨੂੰ ਘਟਾਉਣ ਲਈ ਸਥਾਨਕ ਭੋਜਨ ਨੈਟਵਰਕ ਨੂੰ ਮਜ਼ਬੂਤ ​​ਕਰੋ।\n",
      "\n",
      "**ਯਾਦ ਰੱਖੋ:** ਸਭ ਤੋਂ ਵਧੀਆ ਪਹੁੰਚ ਤੁਹਾਡੇ ਖਾਸ ਸਥਾਨ, ਫਸਲਾਂ ਅਤੇ ਸਰੋਤਾਂ 'ਤੇ ਨਿਰਭਰ ਕਰਦੀ ਹੈ। ਸਥਾਨਕ ਖੇਤੀਬਾੜੀ ਮਾਹਿਰਾਂ ਅਤੇ ਖੋਜ ਸੰਸਥਾਵਾਂ ਨਾਲ ਸਲਾਹ ਮਸ਼ਵਰਾ ਕੀਮਤੀ ਮਾਰਗਦਰਸ਼ਨ ਅਤੇ ਸਹਾਇਤਾ ਪ੍ਰਦਾਨ ਕਰ ਸਕਦਾ ਹੈ।\n",
      "Bye....\n"
     ]
    }
   ],
   "source": [
    "# Define the persistent directory\n",
    "# current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "# persistent_directory = os.path.join(current_dir, \"db\", \"chroma_db_with_metadata\")\n",
    "persistent_directory = \".db/chroma_db_with_metadata\"\n",
    "\n",
    "# Define the embedding model\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n",
    "# Load the existing vector store with the embedding function\n",
    "db = Chroma(persist_directory=persistent_directory, embedding_function=huggingface_embeddings)\n",
    "\n",
    "# Create a retriever for querying the vector store\n",
    "# `search_type` specifies the type of search (e.g., similarity)\n",
    "# `search_kwargs` contains additional arguments for the search (e.g., number of results to return)\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "\n",
    "# Create a google model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# Contextualize question prompt\n",
    "# This system prompt helps the AI understand that it should reformulate the question\n",
    "# based on the chat history to make it a standalone question\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, just \"\n",
    "    \"reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for contextualizing questions\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a history-aware retriever\n",
    "# This uses the LLM to help reformulate the question based on chat history\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "# Answer question prompt\n",
    "# This system prompt helps the AI understand that it should provide concise answers\n",
    "# based on the retrieved context and indicates what to do if the answer is unknown\n",
    "qa_system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. Use \"\n",
    "    \"the following pieces of retrieved context to answer the \"\n",
    "    \"question. If you don't know the answer, just say that you \"\n",
    "    \"don't know. Use optimal number of sentences to answer the question. \"\n",
    "    \"Provide the source as well. \"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for answering questions\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a chain to combine documents for question answering\n",
    "# `create_stuff_documents_chain` feeds all retrieved context into the LLM\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "# Create a retrieval chain that combines the history-aware retriever and the question answering chain\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "\n",
    "# Function to simulate a continual chat punjabi to punjabi\n",
    "def continual_chat():\n",
    "    print(\"Start chatting with the AI! Type 'exit' to end the conversation.\")\n",
    "    chat_history = []  # Collect chat history here (a sequence of messages)\n",
    "\n",
    "    while True:\n",
    "        query = input(\"You: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Bye....\")\n",
    "            break\n",
    "\n",
    "        new_query = punjabi_to_english(str(query))\n",
    "        \n",
    "        print(new_query)\n",
    "\n",
    "        # Process the user's query through the retrieval chain\n",
    "        result = rag_chain.invoke({\"input\": new_query, \"chat_history\": chat_history})\n",
    "        # Display the AI's response\n",
    "        print(\"AI: for english\", result['answer'])\n",
    "        punjabi_response = english_to_punjabi(str(result['answer']))\n",
    "    \n",
    "        print(f\"AI: {punjabi_response}\")\n",
    "\n",
    "        # Update the chat history\n",
    "#         chat_history.append(HumanMessage(content=query))\n",
    "#         chat_history.append(SystemMessage(content=result[\"answer\"]))\n",
    "        chat_history.append(HumanMessage(content=query))\n",
    "        chat_history.append(AIMessage(content=result[\"answer\"]))\n",
    "#         print(chat_history)\n",
    "\n",
    "\n",
    "# Main function to start the continual chat\n",
    "if __name__ == \"__main__\":\n",
    "    continual_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1728945266.303337 1960528 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: httpx in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (0.27.2)\n",
      "Requirement already satisfied: httpcore in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (1.0.6)\n",
      "Requirement already satisfied: anyio in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from httpx) (4.6.0)\n",
      "Requirement already satisfied: certifi in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from httpx) (2024.8.30)\n",
      "Requirement already satisfied: idna in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from httpx) (2.10)\n",
      "Requirement already satisfied: sniffio in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from httpx) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from httpcore) (0.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1728945268.993585 1960528 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: googletrans 4.0.0rc1\n",
      "Uninstalling googletrans-4.0.0rc1:\n",
      "  Successfully uninstalled googletrans-4.0.0rc1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1728945270.755544 1960528 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googletrans==4.0.0-rc1\n",
      "  Using cached googletrans-4.0.0rc1-py3-none-any.whl\n",
      "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
      "  Using cached httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: certifi in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.8.30)\n",
      "Requirement already satisfied: hstspreload in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.10.1)\n",
      "Requirement already satisfied: sniffio in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
      "Requirement already satisfied: chardet==3.* in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
      "Requirement already satisfied: idna==2.* in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
      "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Using cached httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Using cached h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: h2==3.* in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
      "Using cached httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "Using cached httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "Using cached h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "Installing collected packages: h11, httpcore, httpx, googletrans\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.14.0\n",
      "    Uninstalling h11-0.14.0:\n",
      "      Successfully uninstalled h11-0.14.0\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 1.0.6\n",
      "    Uninstalling httpcore-1.0.6:\n",
      "      Successfully uninstalled httpcore-1.0.6\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.27.2\n",
      "    Uninstalling httpx-0.27.2:\n",
      "      Successfully uninstalled httpx-0.27.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langsmith 0.1.133 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\n",
      "anthropic 0.36.0 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\n",
      "openai 1.51.2 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed googletrans-4.0.0rc1 h11-0.9.0 httpcore-0.9.1 httpx-0.13.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade httpx httpcore\n",
    "!pip uninstall googletrans -y\n",
    "!pip install googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733070814.264047  557492 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (1.0.9)\n",
      "Requirement already satisfied: six in /Users/pratham/miniconda3/envs/langchainenv/lib/python3.11/site-packages (from langdetect) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The detected language code is: pa\n",
      "The detected language code is: en\n",
      "The detected language code is: hi\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "\n",
    "# Ensure consistent results\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        # Detect the language of the input text\n",
    "        language_code = detect(text)\n",
    "        return language_code\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Test the function with Punjabi text\n",
    "punjabi_text = \"ਤੁਸੀਂ ਕਿਵੇਂ ਹੋ?\"\n",
    "detected_language = detect_language(punjabi_text)\n",
    "print(f\"The detected language code is: {detected_language}\")\n",
    "\n",
    "# You can also test with English\n",
    "english_text = \"How are you?\"\n",
    "detected_language = detect_language(english_text)\n",
    "print(f\"The detected language code is: {detected_language}\")\n",
    "\n",
    "# Test with Hindi\n",
    "hindi_text = \"आप कैसे हैं?\"\n",
    "detected_language = detect_language(hindi_text)\n",
    "print(f\"The detected language code is: {detected_language}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detect language of the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start chatting with the AI! Type 'exit' to end the conversation.\n",
      "what is rice?\n",
      "AI: Rice is a type of grain that is a staple food for many people around the world. It is a grass species originally domesticated in the Asian subcontinent and is now cultivated in many parts of the world.  It is the most widely consumed grain in the world.  It is a good source of carbohydrates and is often eaten with other foods, such as vegetables, meat, and fish.\n",
      "\n",
      "Source:  Farmers Handbook on Basic Agriculture \n",
      "\n",
      "who is joginder singh?\n",
      "AI: Joginder Singh is a professor from Punjab Agricultural University, mentioned in the provided text as having offered valuable suggestions for the study. \n",
      "\n",
      "please tell me more about him.\n",
      "AI: Unfortunately, the provided text only mentions Joginder Singh as a professor from Punjab Agricultural University who contributed to the study. There is no further information about him, such as his specific area of expertise or any publications. \n",
      "\n",
      "To learn more about Joginder Singh, you would need to search for him using additional resources like:\n",
      "\n",
      "* **Punjab Agricultural University website:** Check their faculty directory or research publications.\n",
      "* **Academic databases:** Search for publications or research projects related to agriculture in Punjab, where his name might be mentioned. \n",
      "* **Google Scholar:** Search for publications using his name and \"Punjab Agricultural University.\" \n",
      "\n",
      "Bye....\n"
     ]
    }
   ],
   "source": [
    "# Define the persistent directory\n",
    "# current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "# persistent_directory = os.path.join(current_dir, \"db\", \"chroma_db_with_metadata\")\n",
    "# persistent_directory = \".db/chroma_db_with_metadata\"\n",
    "persistent_directory = \"db/chroma_db_with_metadata\"\n",
    "\n",
    "# Define the embedding model\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n",
    "# Load the existing vector store with the embedding function\n",
    "db = Chroma(persist_directory=persistent_directory, embedding_function=huggingface_embeddings)\n",
    "\n",
    "# Create a retriever for querying the vector store\n",
    "# `search_type` specifies the type of search (e.g., similarity)\n",
    "# `search_kwargs` contains additional arguments for the search (e.g., number of results to return)\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "\n",
    "# Create a google model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# Contextualize question prompt\n",
    "# This system prompt helps the AI understand that it should reformulate the question\n",
    "# based on the chat history to make it a standalone question\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, just \"\n",
    "    \"reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for contextualizing questions\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a history-aware retriever\n",
    "# This uses the LLM to help reformulate the question based on chat history\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "# Answer question prompt\n",
    "# This system prompt helps the AI understand that it should provide concise answers\n",
    "# based on the retrieved context and indicates what to do if the answer is unknown\n",
    "qa_system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. Use \"\n",
    "    \"the following pieces of retrieved context to answer the \"\n",
    "    \"question. If you don't know the answer, just say that you \"\n",
    "    \"don't know. Use optimal number of sentences to answer the question. \"\n",
    "    \"Provide the source as well. \"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for answering questions\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a chain to combine documents for question answering\n",
    "# `create_stuff_documents_chain` feeds all retrieved context into the LLM\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "# Create a retrieval chain that combines the history-aware retriever and the question answering chain\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "\n",
    "# Function to simulate a continual chat punjabi to punjabi\n",
    "def continual_chat():\n",
    "    print(\"Start chatting with the AI! Type 'exit' to end the conversation.\")\n",
    "    chat_history = []  # Collect chat history here (a sequence of messages)\n",
    "\n",
    "    while True:\n",
    "        query = input(\"You: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Bye....\")\n",
    "            break\n",
    "\n",
    "        language=detect_language(query)\n",
    "        \n",
    "        if language.lower()==\"pa\":\n",
    "            query = punjabi_to_english(str(query))\n",
    "        \n",
    "            print(query)\n",
    "        else:\n",
    "            print(query)\n",
    "\n",
    "        # Process the user's query through the retrieval chain\n",
    "        result = rag_chain.invoke({\"input\": query, \"chat_history\": chat_history})\n",
    "        # Display the AI's response\n",
    "        \n",
    "        if language.lower()==\"pa\":\n",
    "            punjabi_response = english_to_punjabi(str(result['answer']))\n",
    "    \n",
    "            print(f\"AI: {punjabi_response}\")\n",
    "        else:\n",
    "            print(\"AI:\", result['answer'])\n",
    "\n",
    "\n",
    "        # Update the chat history\n",
    "#         chat_history.append(HumanMessage(content=query))\n",
    "#         chat_history.append(SystemMessage(content=result[\"answer\"]))\n",
    "        chat_history.append(HumanMessage(content=query))\n",
    "        chat_history.append(AIMessage(content=result[\"answer\"]))\n",
    "#         print(chat_history)\n",
    "\n",
    "\n",
    "# Main function to start the continual chat\n",
    "if __name__ == \"__main__\":\n",
    "    continual_chat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dir = os.path.join('./', \"db\")\n",
    "persistent_directory = os.path.join(db_dir, \"extended_chroma_db_with_metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store already exists. No need to initialize.\n"
     ]
    }
   ],
   "source": [
    "create_vector_database(huggingface_embeddings,persistent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start chatting with the AI! Type 'exit' to end the conversation.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'detect_language' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 126\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m#         print(chat_history)\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Main function to start the continual chat\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 126\u001b[0m     \u001b[43mcontinual_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 95\u001b[0m, in \u001b[0;36mcontinual_chat\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBye....\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m language\u001b[38;5;241m=\u001b[39m\u001b[43mdetect_language\u001b[49m(query)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m language\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpa\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     98\u001b[0m     query \u001b[38;5;241m=\u001b[39m punjabi_to_english(\u001b[38;5;28mstr\u001b[39m(query))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'detect_language' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the persistent directory\n",
    "# current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "# persistent_directory = os.path.join(current_dir, \"db\", \"chroma_db_with_metadata\")\n",
    "# persistent_directory = \".db/chroma_db_with_metadata\"\n",
    "persistent_directory = \"db/extended_chroma_db_with_metadata\"\n",
    "\n",
    "# Define the embedding model\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "    # model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    "# )\n",
    "huggingface_embeddings=pickle.load(open(\"huggingface_embeddings.pkl\",\"rb\"))\n",
    "# Load the existing vector store with the embedding function\n",
    "db = Chroma(persist_directory=persistent_directory, embedding_function=huggingface_embeddings)\n",
    "\n",
    "# Create a retriever for querying the vector store\n",
    "# `search_type` specifies the type of search (e.g., similarity)\n",
    "# `search_kwargs` contains additional arguments for the search (e.g., number of results to return)\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "\n",
    "# Create a google model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# Contextualize question prompt\n",
    "# This system prompt helps the AI understand that it should reformulate the question\n",
    "# based on the chat history to make it a standalone question\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, just \"\n",
    "    \"reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for contextualizing questions\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a history-aware retriever\n",
    "# This uses the LLM to help reformulate the question based on chat history\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "# Answer question prompt\n",
    "# This system prompt helps the AI understand that it should provide concise answers\n",
    "# based on the retrieved context and indicates what to do if the answer is unknown\n",
    "qa_system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. Use \"\n",
    "    \"the following pieces of retrieved context to answer the \"\n",
    "    \"question. If you don't know the answer, just say that you \"\n",
    "    \"don't know. Use optimal number of sentences to answer the question. \"\n",
    "    \"Provide the source as well. \"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for answering questions\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a chain to combine documents for question answering\n",
    "# `create_stuff_documents_chain` feeds all retrieved context into the LLM\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "# Create a retrieval chain that combines the history-aware retriever and the question answering chain\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "\n",
    "# Function to simulate a continual chat punjabi to punjabi\n",
    "def continual_chat():\n",
    "    print(\"Start chatting with the AI! Type 'exit' to end the conversation.\")\n",
    "    chat_history = []  # Collect chat history here (a sequence of messages)\n",
    "\n",
    "    while True:\n",
    "        query = input(\"You: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Bye....\")\n",
    "            break\n",
    "\n",
    "        language=detect_language(query)\n",
    "        \n",
    "        if language.lower()==\"pa\":\n",
    "            query = punjabi_to_english(str(query))\n",
    "        \n",
    "            print(query)\n",
    "        else:\n",
    "            print(query)\n",
    "\n",
    "        # Process the user's query through the retrieval chain\n",
    "        result = rag_chain.invoke({\"input\": query, \"chat_history\": chat_history})\n",
    "        # Display the AI's response\n",
    "        \n",
    "        if language.lower()==\"pa\":\n",
    "            punjabi_response = english_to_punjabi(str(result['answer']))\n",
    "    \n",
    "            print(f\"AI: {punjabi_response}\")\n",
    "        else:\n",
    "            print(\"AI:\", result['answer'])\n",
    "\n",
    "\n",
    "        # Update the chat history\n",
    "#         chat_history.append(HumanMessage(content=query))\n",
    "#         chat_history.append(SystemMessage(content=result[\"answer\"]))\n",
    "        chat_history.append(HumanMessage(content=query))\n",
    "        chat_history.append(AIMessage(content=result[\"answer\"]))\n",
    "#         print(chat_history)\n",
    "\n",
    "\n",
    "# Main function to start the continual chat\n",
    "if __name__ == \"__main__\":\n",
    "    continual_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5874710,
     "sourceId": 9624403,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5874721,
     "sourceId": 9624416,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5874798,
     "sourceId": 9624519,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "langchainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
